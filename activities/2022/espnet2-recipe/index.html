<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>WAVLab | ESPnet Recipe Instructions</title>
<meta name="description" content="Webpage of Watanabe's Audio and Voice (WAV) Lab
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://raw.githubusercontent.com/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="/assets/img/favicon.png">

<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/activities/2022/espnet2-recipe/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

  <script src="/assets/js/theme.js"></script>
  <!-- Load DarkMode JS -->
<script src="/assets/js/dark_mode.js"></script>






    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       WAVLab
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              About
              
            </a>
          </li>
          <!-- Blog -->
          <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              Activities
              
            </a>
          </li>
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/members/">
                Members
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                Publications
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/open_source">
                Open-source
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/courses/">
                Courses
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/sponsors/">
                Sponsors
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/info/">
                Info
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/positions/">
                Positions
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/speech_lunch">
                Speech Lunch
                
              </a>
          </li>
          
          
          
          
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      

<div class="post">

  <header class="post-header">
    <h1 class="post-title">ESPnet Recipe Instructions</h1>
    <p class="post-meta">January 1, 2022</p>
  </header>

  <article class="post-content">
    <h2 id="0-installation">0. Installation</h2>

<p>For PSC usage and kaldi/espnet installation, please refer to <a href="/activities/2022/psc-usage/">this wiki</a>.</p>

<h2 id="1-introduction">1. Introduction</h2>

<p>In this section, we will provide an overview of one the core parts of ESPnet, the recipes, and introduce their format.</p>

<h3 id="11-what-is-a-recipe-">1.1. What is a recipe ?</h3>
<p>First you need to define the speech task that you want to perform and the corpus that you want to use for this task. Let’s call our task “<strong><em>task</em></strong>” and our corpus “<strong><em>corpus</em></strong>”. As an exemple, we can have task = asr(Automatic Speech Recognition) and corpus = librispeech.</p>

<blockquote>
  <blockquote>
    <p><strong>A recipe is a folder containing all the scripts to download and prepare the data of <em>corpus</em>, train a <em>task</em> model on this prepared data, and evaluate it’s performances.</strong></p>
  </blockquote>
</blockquote>

<p>The different stages of the recipe should be easily executable with bash instructions shared for all recipes detailed later in this wiki. 
In ESPnet2, recipes that train models on the same task share most parts of their codes, using calls to shared scripts.</p>

<h3 id="12-what-is-kaldi-style-">1.2. What is Kaldi-style ?</h3>

<p>ESPnet2 recipes follows Kaldi-style for their recipes.
Kaldi is a toolkit for speech recognition written in C++. Kaldi is intended for use by speech recognition researchers.</p>

<p>To create a recipe, we only have to focus on one of Kaldi’s top-level directories : <strong>egs</strong>.
egs stands for ‘examples’ and contains the recipes for a lot of corpora.</p>

<p><img src="/assets/img/espnet2-structure.png" width="600" height="300" /></p>

<p>ESPnet follows the same architecture than Kaldi so you will find the directories in ESPnet. The folder for ESPnet2 examples is <code class="language-plaintext highlighter-rouge">egs2/</code>.</p>

<h3 id="13-espnet2">1.3. ESPnet2</h3>

<p>ESPnet2 is a newer version of ESPnet. Contrary to Kaldi, it provides shared bash files for recipes to enable generic stages and states during the process. For instance, if there are 2 asr recipes, one on Librispeech corpus, and the other on aishell corpus, the directories <code class="language-plaintext highlighter-rouge">egs2/Librispeech/asr/</code> and <code class="language-plaintext highlighter-rouge">egs2/aishell/asr/</code> will call the generic <code class="language-plaintext highlighter-rouge">asr.sh</code> file.</p>

<h2 id="2-main-steps">2. Main steps</h2>

<h3 id="21-shared-files-and-folders">2.1. Shared files and folders</h3>

<p>Most of the files and folders are shared with all ESPnet2 recipes. You can just copy them into your recipe’s folder and use symbolic links (command : <code class="language-plaintext highlighter-rouge">ln -s {source-filename} {symbolic-filename}</code>). In the following, we will point out the specific files that you need to modify for your recipe.</p>

<h3 id="22-important-files-to-write">2.2. Important files to write</h3>

<h4 id="221-call-the-generic-asrsh--runsh">2.2.1. Call the generic asr.sh : <em>run.sh</em></h4>

<p>You have to write <code class="language-plaintext highlighter-rouge">corpus/task/run.sh</code>file, for instance <a href="https://github.com/espnet/espnet/blob/master/egs2/aishell/asr1/run.sh"><code class="language-plaintext highlighter-rouge">aishell/asr/run.sh</code></a>. 
The role of this file is to call the generic <em>task</em> file, for instance the generic <em>asr.sh</em> file with specific arguments of your recipe.
After few lines defining variables, your file should look like this :</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./asr.sh                                               \
    --lang zh                                          \
    --audio_format wav                                 \
    --feats_type raw                                   \
    --token_type char                                  \
    --use_lm ${use_lm}                                 \
    --use_word_lm ${use_wordlm}                        \
    --lm_config "${lm_config}"                         \
    --asr_config "${asr_config}"                       \
    --inference_config "${inference_config}"           \
    --train_set "${train_set}"                         \
    --valid_set "${valid_set}"                         \
    --test_sets "${test_sets}"                         
</code></pre></div></div>

<p>As all preparation and training stages are performed through the generic file (here <code class="language-plaintext highlighter-rouge">asr.sh</code>), the <code class="language-plaintext highlighter-rouge">run.sh</code> file is a short file.
For more details you can have a look at any recipe’s <code class="language-plaintext highlighter-rouge">run.sh</code> file (<a href="https://github.com/espnet/espnet/blob/master/egs2/aishell/asr1/run.sh">aishell</a>, <a href="https://github.com/espnet/espnet/blob/master/egs2/commonvoice/asr1/run.sh">commonvoice</a> …).</p>

<h4 id="222-prepare-the-data--localdatash">2.2.2. Prepare the data : <em>local/data.sh</em></h4>

<p>This will probably be your first and most complicated task. As each recipe comes with its own data, there is no generic file for this part.
The file should handle data download and preparation. Starting from no data, you should get a folder like this after executing the <code class="language-plaintext highlighter-rouge">local/data.sh</code> file. We used the <a href="https://github.com/DanBerrebbi/espnet/tree/dan_aishell4_branch/egs2/TEMPLATE">template</a> of ESPnet repo in this section.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>data/
  train/
    - text     # The transcription
    - wav.scp  # Wave file path
    - utt2spk  # A file mapping utterance-id to speaker-id
    - spk2utt  # A file mapping speaker-id to utterance-id
    - segments # [Option] Specifying start and end time of each utterance
  dev/
    ...
  test/
    ...
</code></pre></div></div>

<ul>
  <li>Directory structure
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  data/
    train/
      - text     # The transcription
      - wav.scp  # Wave file path
      - utt2spk  # A file mapping utterance-id to speaker-id
      - spk2utt  # A file mapping speaker-id to utterance-id
      - segments # [Option] Specifying start and end time of each utterance
    dev/
      ...
    test/
      ...
</code></pre></div>    </div>
  </li>
  <li><code class="language-plaintext highlighter-rouge">text</code> format
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  uttidA &lt;transcription&gt;
  uttidB &lt;transcription&gt;
  ...
</code></pre></div>    </div>
  </li>
  <li><code class="language-plaintext highlighter-rouge">wav.scp</code> format
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  uttidA /path/to/uttidA.wav
  uttidB /path/to/uttidB.wav
  ...
</code></pre></div>    </div>
  </li>
  <li><code class="language-plaintext highlighter-rouge">utt2spk</code> format
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  uttidA speakerA
  uttidB speakerB
  uttidC speakerA
  uttidD speakerB
  ...
</code></pre></div>    </div>
  </li>
  <li><code class="language-plaintext highlighter-rouge">spk2utt</code> format
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  speakerA uttidA uttidC ...
  speakerB uttidB uttidD ...
  ...
</code></pre></div>    </div>

    <p>Note that <code class="language-plaintext highlighter-rouge">spk2utt</code> file can be generated by <code class="language-plaintext highlighter-rouge">utt2spk</code>, and <code class="language-plaintext highlighter-rouge">utt2spk</code> can be generated by <code class="language-plaintext highlighter-rouge">spk2utt</code>, so it’s enough to create either one of them.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  utils/utt2spk_to_spk2utt.pl data/train/utt2spk <span class="o">&gt;</span> data/train/spk2utt
  utils/spk2utt_to_utt2spk.pl data/train/spk2utt <span class="o">&gt;</span> data/train/utt2spk
</code></pre></div>    </div>

    <p>If your corpus doesn’t include speaker information, give the same speaker id as the utterance id to satisfy the directory format, otherwise give the same speaker id for all utterances (Actually we don’t use speaker information for asr recipe now).</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  uttidA uttidA
  uttidB uttidB
  ...
</code></pre></div>    </div>
  </li>
  <li>
    <p>[Option] <code class="language-plaintext highlighter-rouge">segments</code> format</p>

    <p>If the audio data is originally long recording, about &gt; ~1 hour, and each audio file includes multiple utterances in each section, you need to create <code class="language-plaintext highlighter-rouge">segments</code> file to specify the start time and end time of each utterance. The format is <code class="language-plaintext highlighter-rouge">&lt;utterance_id&gt; &lt;wav_id&gt; &lt;start_time&gt; &lt;end_time&gt;</code>.</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  sw02001-A_000098-001156 sw02001-A 0.98 11.56
  ...
</code></pre></div>    </div>

    <p>Note that if using <code class="language-plaintext highlighter-rouge">segments</code>, <code class="language-plaintext highlighter-rouge">wav.scp</code> has <code class="language-plaintext highlighter-rouge">&lt;wav_id&gt;</code> which corresponds to the <code class="language-plaintext highlighter-rouge">segments</code> instead of <code class="language-plaintext highlighter-rouge">utterance_id</code>.</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  sw02001-A /path/to/sw02001-A.wav
  ...
</code></pre></div>    </div>
  </li>
</ul>

<h2 id="3-shared-files-description">3. Shared files description</h2>

<p>As the shared task files (<a href="https://github.com/espnet/espnet/blob/master/egs2/TEMPLATE/asr1/asr.sh"><code class="language-plaintext highlighter-rouge">asr.sh</code></a>, <a href="https://github.com/espnet/espnet/blob/master/egs2/TEMPLATE/tts1/tts.sh"><code class="language-plaintext highlighter-rouge">tts.sh</code></a> …) handle most of the important steps in ESPnet2, it is important to know how they are built. The shared files are built with stages.</p>

<h3 id="31-asrsh">3.1. <code class="language-plaintext highlighter-rouge">asr.sh</code></h3>

<p><a href="https://github.com/espnet/espnet/blob/master/egs2/TEMPLATE/asr1/asr.sh"><code class="language-plaintext highlighter-rouge">asr.sh</code></a> contains 15 stages. 
Overview :</p>
<ul>
  <li><a href="https://github.com/espnet/espnet/blob/master/egs2/TEMPLATE/asr1/asr.sh#L417-L688">stage 1 to stage 5</a> : data preparation stages
    <ul>
      <li><a href="https://github.com/espnet/espnet/blob/master/egs2/TEMPLATE/asr1/asr.sh#L418-L422">stage 1</a> : call to your own data.sh file</li>
      <li><a href="https://github.com/espnet/espnet/blob/master/egs2/TEMPLATE/asr1/asr.sh#L424-L444">stage 2</a> : speed perturbation modification of inputs</li>
      <li><a href="https://github.com/espnet/espnet/blob/master/egs2/TEMPLATE/asr1/asr.sh#L446-L548">stage 3</a> : create a dump folder, segment audio files, change the audio-format and sampling rate if needed. This step enables to get a common format for files which enable combining different corpora at training or inference time.</li>
      <li><a href="https://github.com/espnet/espnet/blob/master/egs2/TEMPLATE/asr1/asr.sh#L549-L612">stage 4</a> : remove short and long utterances</li>
      <li><a href="https://github.com/espnet/espnet/blob/master/egs2/TEMPLATE/asr1/asr.sh#L613-L683">stage 5</a> : generate a token list (can be word level, character level or bpe level)</li>
    </ul>
  </li>
  <li><a href="https://github.com/espnet/espnet/blob/master/egs2/TEMPLATE/asr1/asr.sh#L693-L868">stage 6 to stage 8</a> : Language Model stages
    <ul>
      <li><a href="https://github.com/espnet/espnet/blob/master/egs2/TEMPLATE/asr1/asr.sh#L693-L770">stage 6</a> : preparing LM training</li>
      <li><a href="https://github.com/espnet/espnet/blob/master/egs2/TEMPLATE/asr1/asr.sh#L771-L845">stage 7</a> : train the LM (needs GPU)</li>
      <li><a href="https://github.com/espnet/espnet/blob/master/egs2/TEMPLATE/asr1/asr.sh#L847-L863">stage 8</a> : calculates <a href="https://en.wikipedia.org/wiki/Perplexity">perplexity</a></li>
    </ul>
  </li>
  <li><a href="https://github.com/espnet/espnet/blob/master/egs2/TEMPLATE/asr1/asr.sh#L870-L1093">stage 9 to stage 11</a> : ASR training steps
    <ul>
      <li><a href="https://github.com/espnet/espnet/blob/master/egs2/TEMPLATE/asr1/asr.sh#L873-L881">stage 9</a> : training an ngram model to compare it to our asr model</li>
      <li><a href="https://github.com/espnet/espnet/blob/master/egs2/TEMPLATE/asr1/asr.sh#L884-L983">stage 10</a> : preparing asr training</li>
      <li><a href="https://github.com/espnet/espnet/blob/master/egs2/TEMPLATE/asr1/asr.sh#L985-L1093">stage 11</a> : asr training (needs GPU)</li>
    </ul>
  </li>
  <li><a href="https://github.com/espnet/espnet/blob/master/egs2/TEMPLATE/asr1/asr.sh#L1131-L1338">stage 12 to stage 13</a> : Evaluation stages : decoding (stage 12) and scoring (stage 13)</li>
  <li><a href="https://github.com/espnet/espnet/blob/master/egs2/TEMPLATE/asr1/asr.sh#L1345-L1434">stage 14 to stage 15</a> : model uploading steps, upload your trained model through those two final steps</li>
</ul>

<h3 id="32-diarsh">3.2. <code class="language-plaintext highlighter-rouge">diar.sh</code></h3>

<h3 id="33-enhsh">3.3. <code class="language-plaintext highlighter-rouge">enh.sh</code></h3>

<h3 id="34-ttssh">3.4. <code class="language-plaintext highlighter-rouge">tts.sh</code></h3>

<h3 id="35-stsh">3.5. <code class="language-plaintext highlighter-rouge">st.sh</code></h3>

<h2 id="4-log-files--tips-wip">4. Log files / TIPS (WIP)</h2>

  </article>

  

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2025   WAV Lab.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
