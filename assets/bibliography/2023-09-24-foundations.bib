@article{gregor2015draw,
  title={DRAW: A recurrent neural network for image generation},
  author={Gregor, Karol and Danihelka, Ivo and Graves, Alex and Rezende, Danilo Jimenez and Wierstra, Daan},
  journal={arXiv preprint, arXiv:1502.04623},
  year={2015},
  url={https://arxiv.org/pdf/1502.04623.pdf}
}


@InProceedings{pmlr-v202-radford23a,
  title = 	 {Robust Speech Recognition via Large-Scale Weak Supervision},
  author =       {Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and Mcleavey, Christine and Sutskever, Ilya},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {28492--28518},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/radford23a/radford23a.pdf},
  url = 	 {https://proceedings.mlr.press/v202/radford23a.html},
  abstract = 	 {We study the capabilities of speech processing systems trained simply to predict large amounts of transcripts of audio on the internet. When scaled to 680,000 hours of multilingual and multitask supervision, the resulting models generalize well to standard benchmarks and are often competitive with prior fully supervised results without the need for any dataset specific fine-tuning. When compared to humans, the models approach their accuracy and robustness. We are releasing models and inference code to serve as a foundation for further work on robust speech processing.}
}

@INPROCEEDINGS{liUniversal,

  author={Li, Xinjian and Dalmia, Siddharth and Li, Juncheng and Lee, Matthew and Littell, Patrick and Yao, Jiali and Anastasopoulos, Antonios and Mortensen, David R. and Neubig, Graham and Black, Alan W and Metze, Florian},

  booktitle={ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 

  title={Universal Phone Recognition with a Multilingual Allophone System}, 

  year={2020},

  volume={},

  number={},

  pages={8249-8253},

  doi={10.1109/ICASSP40776.2020.9054362}}


@article{zhang2023google,
  title={Google usm: Scaling automatic speech recognition beyond 100 languages},
  author={Zhang, Yu and Han, Wei and Qin, James and Wang, Yongqiang and Bapna, Ankur and Chen, Zhehuai and Chen, Nanxin and Li, Bo and Axelrod, Vera and Wang, Gary and others},
  journal={arXiv preprint arXiv:2303.01037},
  year={2023}
}

@article{barrault2023seamlessm4t,
  title={SeamlessM4T-Massively Multilingual \& Multimodal Machine Translation},
  author={Barrault, Lo{\"\i}c and Chung, Yu-An and Meglioli, Mariano Cora and Dale, David and Dong, Ning and Duquenne, Paul-Ambroise and Elsahar, Hady and Gong, Hongyu and Heffernan, Kevin and Hoffman, John and others},
  journal={arXiv preprint arXiv:2308.11596},
  year={2023}
}

@article{pratap2023scaling,
  title={Scaling speech technology to 1,000+ languages},
  author={Pratap, Vineel and Tjandra, Andros and Shi, Bowen and Tomasello, Paden and Babu, Arun and Kundu, Sayani and Elkahky, Ali and Ni, Zhaoheng and Vyas, Apoorv and Fazel-Zarandi, Maryam and others},
  journal={arXiv preprint arXiv:2305.13516},
  year={2023}
}

@inproceedings{peng23d_interspeech,
  author={Puyuan Peng and Brian Yan and Shinji Watanabe and David Harwath},
  title={Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization},
  year=2023,
  booktitle={Proc. INTERSPEECH 2023},
  pages={396--400},
  doi={10.21437/Interspeech.2023-2032}
}

@article{shi2023ml,
  title={ML-SUPERB: Multilingual Speech Universal PERformance Benchmark},
  author={Shi, Jiatong and Berrebbi, Dan and Chen, William and Chung, Ho-Lam and Hu, En-Pei and Huang, Wei Ping and Chang, Xuankai and Li, Shang-Wen and Mohamed, Abdelrahman and Lee, Hung-yi and others},
  journal={arXiv preprint arXiv:2305.10615},
  year={2023}
}


@article{chen2022wavlm,
  title={Wavlm: Large-scale self-supervised pre-training for full stack speech processing},
  author={Chen, Sanyuan and Wang, Chengyi and Chen, Zhengyang and Wu, Yu and Liu, Shujie and Chen, Zhuo and Li, Jinyu and Kanda, Naoyuki and Yoshioka, Takuya and Xiao, Xiong and others},
  journal={IEEE Journal of Selected Topics in Signal Processing},
  volume={16},
  number={6},
  pages={1505--1518},
  year={2022},
  publisher={IEEE}
}

@article{hsu2021hubert,
  title={Hubert: Self-supervised speech representation learning by masked prediction of hidden units},
  author={Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={29},
  pages={3451--3460},
  year={2021},
  publisher={IEEE}
}
