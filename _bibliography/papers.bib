---
@string{interspeech = {Proceedings of Interspeech}}
@string{ICASSP = {Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}}
@string{SLT = {Proceedings of IEEE Spoken Language Technology Workshop (SLT)}}
@string{ACL = {Proceedings of the Annual Meeting of the Association for Computational Linguistics}}
@string{ACLFindings = {Proceedings of Findings of the Annual Meeting of the Association for Computational Linguistics}}
@string{EACL = {Proceedings of the Conference of the European Chapter of the Association for Computational Linguistics}}
@string{NAACL = {Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies}}
@string{TASLP = {IEEE/ACM Transactions on Audio, Speech, and Language Processing}}
@string{IWSLT = {Proceedings of the 18th International Conference on Spoken Language Translation (IWSLT)}}
@string{VCC = {Voice Conversion Challenge}}
@string{ASRU = {IEEE Automatic Speech Recogiton and Understanding Workshop (ASRU)}}
@string{WASPAA = {IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)}}
@string{APSIPA = {Asia Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)}}
@string{ICML = {Proceedings of the International Conference on Machine Learning (ICML)}}

@inproceedings{li2022aclfindings,
  abbr={Linguistic},
  abbr_publisher={ACL},
  title={Zero-shot Learning for Grapheme to Phoneme Conversion with Language Ensemble},
  author={Xinjian Li and Florian Metze and David R Mortensen and Shinji Watanabe and Alan Black},
  booktitle=ACLFindings,
  year={2022}
}

@inproceedings{tsai2022acl,
  abbr={SE&VC&ST},
  abbr_publisher={ACL},
  title={SUPERB-SG: Enhanced Speech processing Universal PERformance Benchmark for Semantic and Generative Capabilities},
  author={Hsiang-Sheng Tsai and Heng-Jui Chang and Wen-Chin Huang and Zili Huang and Kushal Lakhotia and  Shu-wen Yang and  Shuyan Dong and  Andy T. Liu and  Cheng-I Lai and  Jiatong Shi and  Xuankai Chang and  Phil Hall and  Hsuan-Jui Chen and  Shang-Wen Li and  Shinji Watanabe and  Abdelrahman Mohamed and Hung-yi Lee},
  booktitle=ACL,
  year={2022}
}

@article{subramanian2022deep,
  title={Deep learning based multi-source localization with source splitting and its effectiveness in multi-talker speech recognition},
  author={Subramanian, Aswin Shanmugam and Weng, Chao and Watanabe, Shinji and Yu, Meng and Yu, Dong},
  journal={Computer Speech \& Language},
  volume={75},
  pages={101360},
  year={2022},
  publisher={Elsevier}
}

@article{park2022review,
  title={A review of speaker diarization: Recent advances with deep learning},
  author={Park, Tae Jin and Kanda, Naoyuki and Dimitriadis, Dimitrios and Han, Kyu J and Watanabe, Shinji and Narayanan, Shrikanth},
  journal={Computer Speech \& Language},
  volume={72},
  pages={101317},
  year={2022},
  publisher={Elsevier}
}

@article{huang2022joint,
  title={Joint speaker diarization and speech recognition based on region proposal networks},
  author={Huang, Zili and Delcroix, Marc and Garcia, Leibny Paola and Watanabe, Shinji and Raj, Desh and Khudanpur, Sanjeev},
  journal={Computer Speech \& Language},
  volume={72},
  pages={101316},
  year={2022},
  publisher={Elsevier}
}

@article{hussein2022arabic,
  title={Arabic speech recognition by end-to-end, modular systems and human},
  author={Hussein, Amir and Watanabe, Shinji and Ali, Ahmed},
  journal={Computer Speech \& Language},
  volume={71},
  pages={101272},
  year={2022},
  publisher={Elsevier}
}


@inproceedings{lu2022icassp,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={TOWARDS LOW-DISTORTION MULTI-CHANNEL SPEECH ENHANCEMENT: THE ESPNET-SE SUBMISSION TO THE L3DAS22 CHALLENGE},
  author={Jen-Ju Lu and Samuele Cornell and Xuankai Chang and Wangyou Zhang and Chenda Li and Zhaoheng Ni and Zhong-Qiu Wang and Shinji Watanabe},
  booktitle=ICASSP,
  year={2022}
}

@inproceedings{lu2022icassp,
  abbr={Multimodal},
  abbr_publisher={ICASSP},
  title={THE FIRST MULTIMODAL INFORMATION BASED SPEECH PROCESSING (MISP) CHALLENGE: DATA, TASKS, BASELINES AND RESULTS},
  author={Hang Chen and Hengshun Zhou and Jun Du and Chin-Hui Lee and Jingdong Chen and Shinji Watanabe and Sabato Marco Siniscalchi and Odette Scharenborg and Di-Yuan Liu and Bao-Cai Yin and Jia Pan and Jian-Qing Gao and Cong Liu},
  booktitle=ICASSP,
  year={2022}
}

@inproceedings{motoi2022icassp,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={NON-AUTOREGRESSIVE END-TO-END AUTOMATIC SPEECH RECOGNITION INCORPORATING DOWNSTREAM NATURAL LANGUAGE PROCESSING},
  author={Motoi Omachi and Yuya Fujita and Shinji Watanabe and Tianzi Wang},
  booktitle=ICASSP,
  year={2022}
}

@inproceedings{takeshi2022icassp,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={AN EXPLORATION OF HUBERT WITH LARGE NUMBER OF CLUSTER UNITS AND MODEL ASSESSMENT USING BAYESIAN INFORMATION CRITERION},
  author={Takashi Maekaku and Xuankai Chang and Yuya Fujita and Shinji Watanabe},
  booktitle=ICASSP,
  year={2022}
}

@inproceedings{zili2022icassp,
  abbr={SE},
  abbr_publisher={ICASSP},
  title={INVESTIGATING SELF-SUPERVISED LEARNING FOR SPEECH ENHANCEMENT AND SEPARATION},
  author={Zili Huang and Shinji Watanabe and Shu-wen Yang and Paola Garcia and Sanjeev Khudanpur},
  booktitle=ICASSP,
  year={2022}
}

@inproceedings{yenju2022icassp,
  abbr={SE},
  abbr_publisher={ICASSP},
  title={CONDITIONAL DIFFUSION PROBABILISTIC MODEL FOR SPEECH ENHANCEMENT},
  author={Yen-Ju Lu and Zhong-Qiu Wang and Shinji Watanabe and Alexander Richard and Cheng Yu and Yu Tsao},
  booktitle=ICASSP,
  year={2022}
}

@inproceedings{keqi2022icassp,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={IMPROVING NON-AUTOREGRESSIVE END-TO-END SPEECH RECOGNITION WITH PRE-TRAINED ACOUSTIC AND LANGUAGE MODELS},
  author={Keqi Deng and Zehui Yang and Shinji Watanabe and Yosuke Higuchi and Gaofeng Cheng and Pengyuan Zhang},
  booktitle=ICASSP,
  year={2022}
}

@inproceedings{jingpan2022icassp,
  abbr={ASR},
  abbr_publisher={ICASSP},
  author={Jing Pan and Tao Lei and Kwangyoun Kim and Kyu Han and Shinji Watanabe},
  title={SRU++: PIONEERING FAST RECURRENCE WITH ATTENTION FOR SPEECH RECOGNITION},
  booktitle=ICASSP,
  year={2022}
}

@inproceedings{taketomo2022icassp,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Integrating multiple ASR systems into NLP backend with attention fusion},
  author={Takatomo Kano and Atsunori Ogawa and Marc Delcroix and Shinji Watanabe},
  booktitle=ICASSP,
  year={2022}
}

@inproceedings{siddhant2022icassp,
  abbr={SLU},
  abbr_publisher={ICASSP},
  title={ESPNET-SLU: ADVANCING SPOKEN LANGUAGE UNDERSTANDING THROUGH ESPNET},
  author={Siddhant Arora and Siddharth Dalmia and Pavel Denisov and Xuankai Chang and Yushi Ueda and Yifan Peng and Yuekai Zhang and Sujay Kumar and Karthik Ganesan and Brian Yan and Ngoc Thang Vu and Alan W Black and Shinji Watanabe},
  booktitle=ICASSP,
  year={2022}
}

@inproceedings{brian2022icassp,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={JOINT MODELING OF CODE-SWITCHED AND MONOLINGUAL ASR VIA CONDITIONAL FACTORIZATION},
  author={Brian Yan and Chunlei Zhang and Meng Yu and Shi-Xiong Zhang and Siddharth Dalmia and Dan Berrebbi and Chao Weng and Shinji Watanabe and Dong Yu},
  booktitle=ICASSP,
  year={2022}
}

@inproceedings{xuankai2022icassp,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={EXTENDED GRAPH TEMPORAL CLASSIFICATION FOR MULTI-SPEAKER END-TO-END ASR},
  author={Xuankai Chang and Niko Moritz and Takaaki Hori and Shinji Watanabe and Jonathan Le Roux},
  booktitle=ICASSP,
  year={2022}
}

@inproceedings{niko2022icassp,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Sequence Transduction with Graph-based Supervision},
  author={Niko Moritz and Takaaki Hori and Shinji Watanabe and Jonathan Le Roux},
  booktitle=ICASSP,
  year={2022}
}

@inproceedings{emiru2022icassp,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={RUN-AND-BACK STITCH SEARCH: NOVEL BLOCK SYNCHRONOUS DECODING FOR STREAMING ENCODER-DECODER ASR},
  author={Emiru Tsunoo and Chaitanya Narisetty and Michael Hentschel and Yosuke Kashiwagi and Shinji Watanabe},
  booktitle=ICASSP,
  year={2022}
}

@inproceedings{whenchin2022icassp,
  abbr={VC},
  abbr_publisher={ICASSP},
  title={S3PRL-VC: OPEN-SOURCE VOICE CONVERSION FRAMEWORK WITH SELF-SUPERVISED SPEECH REPRESENTATIONS},
  author={Wen-Chin Huang and Shu-wen Yang and Tomoki Hayashi and Hung-yi Lee and Shinji Watanabe and Tomoki Toda},
  booktitle=ICASSP,
  year={2022}
}


@inproceedings{chaitanya2022icassp,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={JOINT SPEECH RECOGNITION AND AUDIO CAPTIONING},
  author={Chaitanya Narisetty and Emiru Tsunoo and Xuankai Chang and Yosuke Kashiwagi and Michael Hentschel and Shinji Watanabe},
  booktitle=ICASSP,
  year={2022}
}

@inproceedings{shota2022icassp,
  abbr={SD},
  abbr_publisher={ICASSP},
  title={MULTI-CHANNEL END-TO-END NEURAL DIARIZATION WITH DISTRIBUTED MICROPHONES},
  author={Shota Horiguchi and Yuki Takashima and Paola Garcia and Shinji Watanabe and Yohei Kawaguchi},
  booktitle=ICASSP,
  year={2022}
}

@inproceedings{yaoyuan2022icassp,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={TORCHAUDIO: BUILDING BLOCKS FOR AUDIO AND SPEECH PROCESSING},
  author={Yao-Yuan Yang and Moto Hira and Zhaoheng Ni and Artyom Astafurov and Caroline Chen and Christian Puhrsch and David Pollack and Dmitriy Genzel and Donny Greenberg and Edward Yang and Jason Lian and Jeff Hwang and Ji Chen and Peter Goldsborough and Sean Narenthiran and Shinji Watanabe and Soumith Chintala and Vincent Quenneville-Bélair},
  booktitle=ICASSP,
  year={2022}
}

@inproceedings{chunlei2022icassp,
  abbr={SD},
  abbr_publisher={ICASSP},
  title={Towards End-to-End Speaker Diarization with Generalized Neural Speaker Clustering},
  author={Chunlei Zhang and Jiatong Shi and Chao Weng and Meng Yu and Dong Yu},
  booktitle=ICASSP,
  year={2022}
}


@inproceedings{tao2022icassp,
  abbr={Music},
  abbr_publisher={ICASSP},
  title={TRAINING STRATEGIES FOR AUTOMATIC SONG WRITING: A UNIFIED FRAMEWORK PERSPECTIVE},
  author={Tao Qian and Jiatong Shi and Shuai Guo and Peter Wu and Qin Jin},
  booktitle=ICASSP,
  year={2022}
}


@article{SHI2022101327,
  abbr={SE+ASR},
  abbr_publisher={CSL},
  title = {An investigation of neural uncertainty estimation for target speaker extraction equipped RNN transducer},
  journal = {Computer Speech & Language},
  volume = {73},
  pages = {101327},
  year = {2022},
  issn = {0885-2308},
  doi = {https://doi.org/10.1016/j.csl.2021.101327},
  url = {https://www.sciencedirect.com/science/article/pii/S0885230821001200},
  author = {Jiatong Shi and Chunlei Zhang and Chao Weng and Shinji Watanabe and Meng Yu and Dong Yu},
  keywords = {Target-speaker speech recognition, Target-speaker speech extraction, Uncertainty estimation},
  abstract = {Target-speaker speech recognition aims to recognize the speech of an enrolled speaker from an environment with background noise and interfering speakers. This study presents a joint framework that combines time-domain target speaker extraction and recurrent neural network transducer (RNN-T) for speech recognition. To alleviate the adverse effects of residual noise and artifacts introduced by the target speaker extraction module to the speech recognition back-end, we explore to training the target speaker extraction and RNN-T jointly. We find a multi-stage training strategy that pre-trains and fine-tunes each module before joint training is crucial in stabilizing the training process. In addition, we propose a novel neural uncertainty estimation that leverages useful information from the target speaker extraction module to further improve the back-end speech recognizer (i.e., speaker identity uncertainty and speech enhancement uncertainty). Compared to a recognizer with target speech extraction front-end, our experiments show that joint-training and the neural uncertainty module reduce 7% and 17% relative character error rate (CER) on multi-talker simulation data, respectively. The multi-condition experiments indicate that our method can reduce 9% relative CER in the noisy condition without losing performance in the clean condition. We also observe consistent improvements in further evaluation of real-world data based on vehicular speech.}
}

@inproceedings{huang_asru2021,
  abbr={ASR+TTS},
  abbr_publisher={ASRU},
  title={On Prosody Modeling for ASR+TTS based Voice Conversion},
  author={Wen-Chin Huang and Tomoki Hayashi and Xinjian Li and Shinji Watanabe and Tomoki Toda},
  booktitle=ASRU,
  year={2021}
}

@inproceedings{kano_asru2021,
  abbr={SLU},
  abbr_publisher={ASRU},
  title={Attention-based Multi-hypothesis Fusion for Speech Summarization},
  author={Takatomo Kano and Atsunori Ogawa and Marc Delcroix and Shinji Watanabe},
  booktitle=ASRU,
  year={2021}
}

@inproceedings{inaguma_asru2021,
  abbr={ST},
  abbr_publisher={ASRU},
  title={Fast-MD: Fast Multi-Decoder End-to-End Speech Translation with Non-Autoregressive Hidden Intermediates},
  author={Hirofumi Inaguma and Siddharth Dalmia and Brian Yan and Shinji Watanabe},
  booktitle=ASRU,
  year={2021}
}

@inproceedings{horiguchi_asru2021,
  abbr={SD},
  abbr_publisher={ASRU},
  title={Towards Neural Diarization for Unlimited Numbers of Speakers using Global and Local Attractors},
  author={Shota Horiguchi and Shinji Watanabe and Paola Garcia and Yawen Xue and Yuki Takashima and Yohei Kawaguchi},
  booktitle=ASRU,
  year={2021}
}

@inproceedings{boyer_asru2021,
  abbr={ASR},
  abbr_publisher={ASRU},
  title={A Study of Transducer based End-to-end ASR with ESPNet: Architecture, Auxiliary Loss and Decoding Strategies},
  author={Florian Boyer and Yusuke Shinohara and Takaaki Ishii and Hirofumi Inaguma and Shinji Watanabe},
  booktitle=ASRU,
  year={2021}
}

@inproceedings{higuchi_asru2021,
  abbr={ASR},
  abbr_publisher={ASRU},
  title={A Comparative Study on Non-autoregressive Modelings for Speech-to-text Generation},
  author={Yosuke Higuchi and Nanxin Chen and Yuya Fujita and Hirofumi Inaguma and Tatsuya Komatsu and Jaesong Lee and Jumon Nozaki and Tianzi Wang and Shinji Watanabe},
  booktitle=ASRU,
  year={2021}
}

@inproceedings{rao_asru2021,
  abbr={SE},
  abbr_publisher={ASRU},
  title={ConferencingSpeech Challenge: Towards Far-field Multi-channel Speech Enhancement for Video Conferencing},
  author={Wei Rao and Yihui Fu and Yanxin Hu and Xin Xu and Yvkai Jv and Jiangyu Han and Zhongjie Jiang and Lei Xie and Yannan Wang and Shinji Watanabe and Zheng-Hua Tan and Hui Bu and Tao Yu and Shidong Shang},
  booktitle=ASRU,
  year={2021}
}

@inproceedings{wu_asru2021,
  abbr={ASR+TTS},
  abbr_publisher={ASRU},
  title={Cross-lingual Transfer for Speech Processing using Acoustic Language Similarity},
  author={Peter Wu and Jiatong Shi and Yifan Zhong and Shinji Watanabe and Alan Black},
  booktitle=ASRU,
  year={2021}
}

@inproceedings{chang_asru2021,
  abbr={ASR},
  abbr_publisher={ASRU},
  title={An Exploration of Self-supervised Pretrained Representations for End-to-end Speech Recognition},
  author={Xuankai Chang and Takashi Maekaku and Pengcheng Guo and Jing Shi and Yen-Ju Lu and Aswin Shanmugam Subramanian and Tianzi Wang and Shu-wen Yang and Yu Tsao and Hung-yi Lee and Shinji Watanabe},
  booktitle=ASRU,
  year={2021}
}

@inproceedings{wu_apsipa2021,
  abbr={VC},
  abbr_publisher={APSIPA},
  title={Understanding the Tradeoffs in Client-side Privacy for Downstream Speech Tasks},
  author={Peter Wu and Paul Pu Liang and Jiatong Shi and Ruslan Salakhutdinov and Shinji Watanabe and Louis-Philippe Morency},
  booktitle=APSIPA,
  year={2021}
}

@inproceedings{inaguma2021iwslt,
  abbr={ST},
  abbr_publisher={IWSLT},
  title={{ESP}net-{ST} {IWSLT} 2021 Offline Speech Translation System},
  author={Inaguma, Hirofumi and Yan, Brian and Dalmia, Siddharth and Guo, Pengcheng and Shi, Jiatong and Duh, Kevin and Watanabe, Shinji},
  booktitle=IWSLT,
  pages={100--109},
  year={2021}
}

@inproceedings{chen2021giga,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={GigaSpeech: An Evolving, Multi-domain ASR Corpus with 10,000 Hours of Transcribed Audio},
  author={Chen, Guoguo and Chai, Shuzhou and Wang, Guanbo and Du, Jiayu and Zhang, Wei-Qiang and Weng, Chao and Su, Dan and Povey, Daniel and Trmal, Jan and Zhang, Junbo and Jin, Mingjie and Khudanpur, Sanjeev and Watanabe, Shinji and Zhao, Shuaijiang and Zou, Wei and Li, Xiangang and Yao, Xuchen and Wang, Yongqing and You, Zhao and Yan, Zhiyong},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{komatsu2021chains,
  abbr={AED},
  abbr_publisher={Interspeech},
  title={Acoustic Event Detection with Classifier Chains},
  author={Komatsu, Tatsuya and Watanabe, Shinji and Miyazaki, Koichi and Hayashi, Tomoki},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{guo2021combine,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Multi-Speaker ASR Combining Non-Autoregressive Conformer CTC and Conditional Speaker Chain},
  author={Guo, Pengcheng and Chang, Xuankai and Watanabe, Shinji and Xie, Lei},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{kim2021transducer,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Multi-mode Transformer Transducer with Stochastic Future Context},
  author={Kim, Kwangyoun and Wu, Felix and Sridhar, Prashant and Han, Kyu and Watanabe, Shinji},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{yan2021allophone,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Differentiable Allophone Graphs for Language Universal Speech Recognition},
  author={Yan, Brian and Dalmia, Siddharth and Mortensen, David R. and Metze, Florian and Watanabe, Shinji},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{maciejewski2021verification,
  abbr={SE},
  abbr_publisher={Interspeech},
  title={Speaker Verification-Based Evaluation of Single-Channel Speech Separation},
  author={Maciejewski, Matthew and Watanabe, Shinji and Khudanpur, Sanjeev},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{neill2021financial,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={SPGISpeech: 5,000 hours of transcribed financial audio for fully formatted end-to-end speech recognition},
  author={O'Neill, Patrick and Lavrukhin, Vitaly and Majumdar, Somshubra and Noroozi, Vahid and Zhang, Yuekai and Kuchaiev, Oleksii and Balam, Jagadeesh and Dovzhenko, Yuliya and Freyberg, Keenan and Shulman, Michael and Ginsburg, Boris and Watanabe, Shinji and Kucsko, Georg},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{yang2021superb,
  abbr={ASR&SD&SLU&ER},
  abbr_publisher={Interspeech},
  title={SUPERB: Speech processing Universal PERformance Benchmark},
  author={Yang, Shu-wen and Chi, Po-Han and Chuang, Yung-Sung and Lai, Cheng-I and Lakhotia, Kushal and Y., Yist and T., Andy and Shi, Jiatong and Chang, Xuankai and Lin, Guan-Ting and Huang, Tzu-Hsien and Tseng, Wei-Cheng and Lee, Ko-tik and Liu, Da-Rong and Huang, Zili and Dong, Shuyan and Li, Shang-Wen and Watanabe, Shinji and Mohamed, Abdelrahman and Lee, Hung-yi},
  booktitle=interspeech,
  year={2021},
  arxiv={2105.01051}
}

@inproceedings{shon2021sentiment,
  abbr={SSA},
  abbr_publisher={Interspeech},
  title={Leveraging Pre-trained Language Model for Speech Sentiment Analysis},
  author={Shon, Suwon and Brusco, Pablo and Pan, Jing and Han, Kyu and Watanabe, Shinji},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{wong2021E2EASR,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Streaming End-to-End ASR based on Blockwise Non-Autoregressive Models},
  author={Wang, Tianzi and Fujita, Yuya and Chang, Xuankai and Watanabe, Shinji},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{arora2021SLU,
  abbr={SLU},
  abbr_publisher={Interspeech},
  title={Rethinking End-to-End Evaluation of Decomposable Tasks: A Case Study on Spoken Language Understanding},
  author={Arora, Siddhant and Ostapenko, Alissa and Viswanathan, Vijay and Dalmia, Siddharth and Metze, Florian and Watanabe, Shinji and Black, Alan W.},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{meekaku2021ZeroSpeech,
  abbr={ASR & SpeDialog},
  abbr_publisher={Interspeech},
  title={Speech Representation Learning Combining Conformer CPC with Deep Cluster for the ZeroSpeech Challenge 2021},
  author={Maekaku, Takashi and Chang, Xuankai and Fujita, Yuya and Chen, Li-Wei and Watanabe, Shinji and Rudnicky, Alexander},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{lee2021CTC,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Layer Pruning on Demand with Intermediate CTC},
  author={Lee, Jaesong and Kang, Jingu and Watanabe, Shinji},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{fujita2021insertion,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Toward Streaming ASR with Non-autoregressive Insertion-based Model},
  author={Fujita, Yuya and Wang, Tianzi and Watanabe, Shinji and Omachi, Motoi},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{zmolikova2021weaksupervision,
  abbr={SE&ASR},
  abbr_publisher={Interspeech},
  title={Auxiliary loss function for target speech extraction and recognition with weak supervision based on speaker characteristics},
  author={Zmolikova, Katerina and Delcroix, Marc and Raj, Desh and Watanabe, Shinji and Honza Černocký, Jan},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{tsunoo2021DataAug,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Data Augmentation Methods for End-to-end Speech Recognition on Distant-talk Scenarios},
  author={Tsunoo, Emiru and Shibata, Kentaro and Narisetty, Chaitanya and Kashiwagi, Yosuke and Watanabe, Shinji},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{he2021TSVAD,
  abbr={SD},
  abbr_publisher={Interspeech},
  title={Target-Speaker Voice Activity Detection with Improved I-Vector Estimation for Unknown Number of Speaker},
  author={He, Mao-Kui and Raj, Desh and Huang, Zili and Du, Jun and Chen, Zhuo and Watanabe, Shinji},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{watanabe2021espnet,
  abbr={SE&ASR&ST},
  abbr_publisher={DSLW},
  title={The 2020 ESPnet update: new features, broadened applications, performance improvements, and future plans},
  author={Shinji Watanabe and Florian Boyer and Xuankai Chang and Pengcheng Guo and Tomoki Hayashi and Yosuke Higuchi and Takaaki Hori and Wen-Chin Huang and Hirofumi Inaguma and Naoyuki Kamo and Shigeki Karita and Chenda Li and Jing Shi and Aswin Shanmugam Subramanian and Wangyou Zhang},
  booktitle={Proceedings of 2021 IEEE Data Science and Learning Workshop},
  year={2021},
  organization={IEEE}
}

@inproceedings{li2021dual,
  abbr={SE},
  abbr_publisher={SLT},
  title={Dual-path RNN for long recording speech separation},
  author={Li, Chenda and Luo, Yi and Han, Cong and Li, Jinyu and Yoshioka, Takuya and Zhou, Tianyan and Delcroix, Marc and Kinoshita, Keisuke and Boeddeker, Christoph and Qian, Yanmin and Watanabe, Shinji and Chen, Zhuo},
  booktitle=SLT,
  pages={865--872},
  year={2021},
  organization={IEEE}
}

@inproceedings{takashima2021end,
  abbr={SD},
  abbr_publisher={SLT},
  title={End-to-End Speaker Diarization Conditioned on Speech Activity and Overlap Detection},
  author={Takashima, Yuki and Fujita, Yusuke and Watanabe, Shinji and Horiguchi, Shota and Garc{\'\i}a, Paola and Nagamatsu, Kenji},
  booktitle=SLT,
  pages={849--856},
  year={2021},
  organization={IEEE}
}

@inproceedings{tsunoo2021streaming,
  abbr={ASR},
  abbr_publisher={SLT},
  title={Streaming Transformer ASR with blockwise synchronous beam search},
  author={Tsunoo, Emiru and Kashiwagi, Yosuke and Watanabe, Shinji},
  booktitle=SLT,
  pages={22--29},
  year={2021},
  organization={IEEE}
}

@inproceedings{wang2021sequential,
  abbr={SE},
  abbr_publisher={SLT},
  title={Sequential multi-frame neural beamforming for speech separation and enhancement},
  author={Wang, Zhong-Qiu and Erdogan, Hakan and Wisdom, Scott and Wilson, Kevin and Raj, Desh and Watanabe, Shinji and Chen, Zhuo and Hershey, John R},
  booktitle=SLT,
  pages={905--911},
  year={2021},
  organization={IEEE}
}

@inproceedings{raj2021dover,
  abbr={SD},
  abbr_publisher={SLT},
  title={DOVER-Lap: A Method for Combining Overlap-aware Diarization Outputs},
  author={Raj, Desh and Garcia-Perera, Leibny Paola and Huang, Zili and Watanabe, Shinji and Povey, Daniel and Stolcke, Andreas and Khudanpur, Sanjeev},
  booktitle=SLT,
  pages={881--888},
  year={2021},
  organization={IEEE}
}

@inproceedings{raj2021integration,
  abbr={SE&SE&ASR},
  abbr_publisher={SLT},
  title={Integration of speech separation, diarization, and recognition for multi-speaker meetings: System description, comparison, and analysis},
  author={Raj, Desh and Denisov, Pavel and Chen, Zhuo and Erdogan, Hakan and Huang, Zili and He, Maokui and Watanabe, Shinji and Du, Jun and Yoshioka, Takuya and Luo, Yi and others},
  booktitle=SLT,
  pages={897--904},
  year={2021},
  organization={IEEE}
}

@inproceedings{xue2021online,
  abbr={SD},
  abbr_publisher={SLT},
  title={Online end-to-end neural diarization with speaker-tracing buffer},
  author={Xue, Yawen and Horiguchi, Shota and Fujita, Yusuke and Watanabe, Shinji and Garc{\'\i}a, Paola and Nagamatsu, Kenji},
  booktitle=SLT,
  pages={841--848},
  year={2021},
  organization={IEEE}
}

@inproceedings{shi2021highland,
  abbr={ST},
  abbr_publisher={AmericasNLP},
  title={Highland Puebla Nahuatl Speech Translation Corpus for Endangered Language Documentation},
  author={Shi, Jiatong and Amith, Jonathan D and Chang, Xuankai and Dalmia, Siddharth and Yan, Brian and Watanabe, Shinji},
  booktitle={Proceedings of the First Workshop on Natural Language Processing for Indigenous Languages of the Americas},
  pages={53--63},
  year={2021}
}

@inproceedings{amith2021end,
  abbr={ASR},
  abbr_publisher={AmericasNLP},
  title={End-to-End Automatic Speech Recognition: Its Impact on the Workflowin Documenting Yolox{\'o}chitl Mixtec},
  author={Amith, Jonathan D and Shi, Jiatong and Garc{\'\i}a, Rey Castillo},
  booktitle={Proceedings of the First Workshop on Natural Language Processing for Indigenous Languages of the Americas},
  pages={64--80},
  year={2021}
}

@inproceedings{omachi2021end,
  abbr={ASR},
  abbr_publisher={NAACL},
  title={End-to-end ASR to jointly predict transcriptions and linguistic annotations},
  author={Omachi, Motoi and Fujita, Yuya and Watanabe, Shinji and Wiesner, Matthew},
  booktitle=NAACL,
  pages={1861--1871},
  year={2021}
}

@inproceedings{dalmia2021searchable,
  abbr={ST},
  abbr_publisher={NAACL},
  title={Searchable Hidden Intermediates for End-to-End Models of Decomposable Sequence Tasks},
  author={Dalmia, Siddharth and Yan, Brian and Raunak, Vikas and Metze, Florian and Watanabe, Shinji},
  booktitle=NAACL,
  pages={1882--1896},
  year={2021}
}

@inproceedings{inaguma2021source,
  abbr={ST},
  abbr_publisher={NAACL},
  title={Source and Target Bidirectional Knowledge Distillation for End-to-end Speech Translation},
  author={Inaguma, Hirofumi and Kawahara, Tatsuya and Watanabe, Shinji},
  booktitle=NAACL,
  pages={1872--1881},
  year={2021}
}

@inproceedings{shi2021leveraging,
  abbr={ASR},
  abbr_publisher={EACL},
  title={Leveraging End-to-End ASR for Endangered Language Documentation: An Empirical Study on Yol{\'o}xochitl Mixtec},
  author={Shi, Jiatong and Amith, Jonathan D and Garc{\'\i}a, Rey Castillo and Sierra, Esteban Guadalupe and Duh, Kevin and Watanabe, Shinji},
  booktitle=EACL,
  pages={1134--1145},
  year={2021}
}


@inproceedings{xue2021Online,
  abbr={SD},
  abbr_publisher={Interspeech},
  title={Online Streaming End-to-End Neural Diarization Handling Overlapping Speech and Flexible Numbers of Speakers},
  author={Xue, Yawen and Horiguchi, Shota and Fujita, Yusuke and Takashima, Yuki and Watanabe, Shinji and Paola Garcia Perera, Leibny and Namagatsu, Kenji},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{takashima2021SemiSup,
  abbr={SD},
  abbr_publisher={Interspeech},
  title={Semi-Supervised Training with Pseudo-Labeling for End-to-End Neural Diarization},
  author={Takashima, Yuki and Fujita, Yusuke and Horiguchi, Shota and Watanabe, Shinji and Paola, Leibny and Nagamatsu, Kenji},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{han2021Cont,
  abbr={SE},
  abbr_publisher={Interspeech},
  title={Continuous speech separation using speaker inventory for long recording},
  author={Han, Cong and Luo, Yi and Li, Chenda and Zhou, Tianyan and Kinoshita, Keisuke and Watanabe, Shinji and Delcroix, Marc and Erdogan, Hakan and Hershey, John and Mesgarani, Nima and Chen, Zhuo},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{maiti2021end,
  abbr={SD},
  abbr_publisher={ICASSP},
  title={End-To-End Diarization for Variable Number of Speakers with Local-Global Networks and Discriminative Speaker Embeddings},
  author={Maiti, Soumi and Erdogan, Hakan and Wilson, Kevin and Wisdom, Scott and Watanabe, Shinji and Hershey, John R},
  booktitle=ICASSP,
  pages={7183--7187},
  year={2021},
  organization={IEEE}
}

@inproceedings{li2021dual,
  abbr={SE},
  abbr_publisher={ICASSP},
  title={Dual-Path Modeling for Long Recording Speech Separation in Meetings},
  author={Li, Chenda and Chen, Zhuo and Luo, Yi and Han, Cong and Zhou, Tianyan and Kinoshita, Keisuke and Delcroix, Marc and Watanabe, Shinji and Qian, Yanmin},
  booktitle=ICASSP,
  year={2021},
  organization={IEEE}
}

@inproceedings{guo2021recent,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Recent developments on espnet toolkit boosted by conformer},
  author={Guo, Pengcheng and Boyer, Florian and Chang, Xuankai and Hayashi, Tomoki and Higuchi, Yosuke and Inaguma, Hirofumi and Kamo, Naoyuki and Li, Chenda and Garcia-Romero, Daniel and Shi, Jiatong and others},
  booktitle=ICASSP,
  pages={5874--5878},
  year={2021},
  organization={IEEE}
}

@inproceedings{zhang2021end,
  abbr={SE&ASR},
  abbr_publisher={ICASSP},
  title={End-to-end dereverberation, beamforming, and speech recognition with improved numerical stability and advanced frontend},
  author={Zhang, Wangyou and Boeddeker, Christoph and Watanabe, Shinji and Nakatani, Tomohiro and Delcroix, Marc and Kinoshita, Keisuke and Ochiai, Tsubasa and Kamo, Naoyuki and Haeb-Umbach, Reinhold and Qian, Yanmin},
  booktitle=ICASSP,
  pages={6898--6902},
  year={2021},
  organization={IEEE}
}

@inproceedings{horiguchi2021end,
  abbr={SD},
  abbr_publisher={ICASSP},
  title={End-to-end speaker diarization as post-processing},
  author={Horiguchi, Shota and Garc{\'\i}a, Paola and Fujita, Yusuke and Watanabe, Shinji and Nagamatsu, Kenji},
  booktitle=ICASSP,
  pages={7188--7192},
  year={2021},
  organization={IEEE}
}

@inproceedings{higuchi2021improved,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Improved Mask-CTC for Non-Autoregressive End-to-End ASR},
  author={Higuchi, Yosuke and Inaguma, Hirofumi and Watanabe, Shinji and Ogawa, Tetsuji and Kobayashi, Tetsunori},
  booktitle=ICASSP,
  pages={8363--8367},
  year={2021},
  organization={IEEE}
}

@inproceedings{lee2021intermediate,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Intermediate Loss Regularization for CTC-Based Speech Recognition},
  author={Lee, Jaesong and Watanabe, Shinji},
  booktitle=ICASSP,
  pages={6224--6228},
  year={2021},
  organization={IEEE}
}

@inproceedings{inaguma2021orthros,
  abbr={ST},
  abbr_publisher={ICASSP},
  title={Orthros: Non-autoregressive end-to-end speech translation with dual-decoder},
  author={Inaguma, Hirofumi and Higuchi, Yosuke and Duh, Kevin and Kawahara, Tatsuya and Watanabe, Shinji},
  booktitle=ICASSP,
  pages={7503--7507},
  year={2021},
  organization={IEEE}
}

@inproceedings{subramanian2021directional,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Directional ASR: A new paradigm for E2E multi-speaker speech recognition with source localization},
  author={Subramanian, Aswin Shanmugam and Weng, Chao and Watanabe, Shinji and Yu, Meng and Xu, Yong and Zhang, Shi-Xiong and Yu, Dong},
  booktitle=ICASSP,
  pages={8433--8437},
  year={2021},
  organization={IEEE}
}

@inproceedings{baskar2021eat,
  abbr={ASR&TTS},
  abbr_publisher={ICASSP},
  title={Eat: Enhanced ASR-TTS for Self-Supervised Speech Recognition},
  author={Baskar, Murali Karthick and Burget, Luk{\'a}{\v{s}} and Watanabe, Shinji and Astudillo, Ramon Fernandez and others},
  booktitle=ICASSP,
  pages={6753--6757},
  year={2021},
  organization={IEEE}
}

@inproceedings{kashiwagi2021gaussian,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Gaussian Kernelized Self-Attention for Long Sequence Data and its Application to CTC-Based Speech Recognition},
  author={Kashiwagi, Yosuke and Tsunoo, Emiru and Watanabe, Shinji},
  booktitle=ICASSP,
  pages={6214--6218},
  year={2021},
  organization={IEEE}
}

@inproceedings{shi2021improving,
  abbr={SE&ASR},
  abbr_publisher={ICASSP},
  title={Improving RNN Transducer with Target Speaker Extraction and Neural Uncertainty Estimation},
  author={Shi, Jiatong and Zhang, Chunlei and Weng, Chao and Watanabe, Shinji and Yu, Meng and Yu, Dong},
  booktitle=ICASSP,
  pages={6908--6912},
  year={2021},
  organization={IEEE}
}

@inproceedings{maciejewski2021training,
  abbr={SE},
  abbr_publisher={ICASSP},
  title={Training Noisy Single-Channel Speech Separation with Noisy Oracle Sources: A Large Gap and a Small Step},
  author={Maciejewski, Matthew and Shi, Jing and Watanabe, Shinji and Khudanpur, Sanjeev},
  booktitle=ICASSP,
  pages={5774--5778},
  year={2021},
  organization={IEEE}
}

@inproceedings{shi2021sequence,
  abbr={Music},
  abbr_publisher={ICASSP},
  title={Sequence-To-Sequence Singing Voice Synthesis With Perceptual Entropy Loss},
  author={Shi, Jiatong and Guo, Shuai and Huo, Nan and Zhang, Yuekai and Jin, Qin},
  booktitle=ICASSP,
  pages={76--80},
  year={2021},
  organization={IEEE}
}


@inproceedings{hayashi2020espnet,
  abbr={TTS},
  abbr_publisher={ICASSP},
  title={{Espnet-TTS}: Unified, reproducible, and integratable open source end-to-end text-to-speech toolkit},
  author={Hayashi, Tomoki and Yamamoto, Ryuichi and Inoue, Katsuki and Yoshimura, Takenori and Watanabe, Shinji and Toda, Tomoki and Takeda, Kazuya and Zhang, Yu and Tan, Xu},
  booktitle=ICASSP,
  pages={7654--7658},
  year={2020},
  organization={IEEE},
  code={https://github.com/espnet/espnet},
}

@inproceedings{inaguma-etal-2020-espnet,
    abbr={ST},
    abbr_publisher={ACL},
    title = "{ESP}net-{ST}: All-in-One Speech Translation Toolkit",
    author = "Inaguma, Hirofumi  and
      Kiyono, Shun  and
      Duh, Kevin  and
      Karita, Shigeki  and
      Yalta, Nelson  and
      Hayashi, Tomoki  and
      Watanabe, Shinji",
    booktitle = ACL,
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-demos.34",
    pages = "302--311",
    code={https://github.com/espnet/espnet},
}
@inproceedings{li2020espnet,
  abbr={SE},
  abbr_publisher={SLT},
  title={{ESPnet-SE}: End-to-End Speech Enhancement and Separation Toolkit Designed for {ASR} Integration},
  author={Chenda Li and Jing Shi and Wangyou Zhang and Aswin Shanmugam Subramanian and Xuankai Chang and Naoyuki Kamo and Moto Hira and Tomoki Hayashi and Christoph Boeddeker and Zhuo Chen and Shinji Watanabe},
  booktitle=SLT,
  pages={785--792},
  year={2021},
  organization={IEEE},
  code={https://github.com/espnet/espnet},
}

@article{huh2020augmentation,
  abbr={SR},
  abbr_publisher={NeurIPS},
  title={Augmentation adversarial training for self-supervised speaker recognition},
  author={Huh, Jaesung and Heo, Hee Soo and Kang, Jingu and Watanabe, Shinji and Chung, Joon Son},
  arxiv={2007.12085},
  year={2020}
}
@article{miyazaki2020conformer,
  abbr={SED},
  abbr_publisher={DCASE},
  title={Conformer-based sound event detection with semi-supervised learning and data augmentation},
  author={Miyazaki, Koichi and Komatsu, Tatsuya and Hayashi, Tomoki and Watanabe, Shinji and Toda, Tomoki and Takeda, Kazuya},
  html={http://dcase.community/documents/workshop2020/proceedings/DCASE2020Workshop_Miyazaki_92.pdf},
  volume={1},
  pages={4},
  year={2020}
}

@article{arora2020jhu,
  abbr={ASR},
  abbr_publisher={CHiME},
  title={The JHU multi-microphone multi-speaker ASR system for the CHiME-6 challenge},
  author={Arora, Ashish and Raj, Desh and Subramanian, Aswin Shanmugam and Li, Ke and Ben-Yair, Bar and Maciejewski, Matthew and {\.Z}elasko, Piotr and Garcia, Paola and Watanabe, Shinji and Khudanpur, Sanjeev},
  arxiv={2006.07898},
  year={2020}
}
@inproceedings{chang2020end,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={End-to-end multi-speaker speech recognition with transformer},
  author={Chang, Xuankai and Zhang, Wangyou and Qian, Yanmin and Le Roux, Jonathan and Watanabe, Shinji},
  html={https://ieeexplore.ieee.org/abstract/document/9054029},
  pages={6134--6138},
  year={2020}
}
@inproceedings{inoue2020semi,
  abbr={TTS},
  abbr_publisher={ICASSP},
  title={Semi-supervised speaker adaptation for end-to-end speech synthesis with pretrained models},
  author={Inoue, Katsuki and Hara, Sunao and Abe, Masanobu and Hayashi, Tomoki and Yamamoto, Ryuichi and Watanabe, Shinji},
  html={https://ieeexplore.ieee.org/abstract/document/9053371},
  pages={7634--7638},
  year={2020}
}
@inproceedings{yoshimura2020end,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={End-to-end automatic speech recognition integrated with ctc-based voice activity detection},
  author={Yoshimura, Takenori and Hayashi, Tomoki and Takeda, Kazuya and Watanabe, Shinji},
  arxiv={https://ieeexplore.ieee.org/abstract/document/9054358},
  pages={6999--7003},
  year={2020}
}
}
@inproceedings{fujita2020attention,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Attention-based asr with lightweight and dynamic convolutions},
  author={Fujita, Yuya and Subramanian, Aswin Shanmugam and Omachi, Motoi and Watanabe, Shinji},
  arxiv={https://ieeexplore.ieee.org/abstract/document/9053887},
  pages={7034--7038},
  year={2020},
  code={https://github.com/espnet/espnet}
}
@inproceedings{li2020practical,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={A practical two-stage training strategy for multi-stream end-to-end speech recognition},
  author={Li, Ruizhi and Sell, Gregory and Wang, Xiaofei and Watanabe, Shinji and Hermansky, Hynek},
  arxiv={1910.10671},
  pages={7014--7018},
  year={2020}
}
@inproceedings{huang2020speaker,
  abbr={SD},
  abbr_publisher={ICASSP},
  title={Speaker diarization with region proposal network},
  author={Huang, Zili and Watanabe, Shinji and Fujita, Yusuke and Garc{\'\i}a, Paola and Shao, Yiwen and Povey, Daniel and Khudanpur, Sanjeev},
  html={https://ieeexplore.ieee.org/abstract/document/9053760},
  arxiv={2002.06220},
  pages={6514--6518},
  year={2020}
}
@inproceedings{miyazaki2020weakly,
  abbr={SED},
  abbr_publisher={ICASSP},
  title={Weakly-supervised sound event detection with self-attention},
  author={Miyazaki, Koichi and Komatsu, Tatsuya and Hayashi, Tomoki and Watanabe, Shinji and Toda, Tomoki and Takeda, Kazuya},
  html={https://ieeexplore.ieee.org/abstract/document/9053609},
  pages={66--70},
  year={2020},
  code={https://github.com/espnet/espnet}
}
@inproceedings{subramanian2020far,
  abbr={SE},
  abbr_publisher={ICASSP},
  title={Far-field location guided target speech extraction using end-to-end speech recognition objectives},
  html={https://ieeexplore.ieee.org/document/9053692},
  author={Subramanian, Aswin Shanmugam and Weng, Chao and Yu, Meng and Zhang, Shi-Xiong and Xu, Yong and Watanabe, Shinji and Yu, Dong},
  pages={7299--7303},
  year={2020}
}
@incollection{shinozaki2020automated,
  abbr={ASR},
  abbr_publisher={Deep Neural Evolution},
  title={Automated Development of DNN Based Spoken Language Systems Using Evolutionary Algorithms},
  author={Shinozaki, Takahiro and Watanabe, Shinji and Duh, Kevin},
  html={https://link.springer.com/chapter/10.1007/978-981-15-3685-4_4},
  pages={97--129},
  year={2020}
}
@article{huang2020sequence,
  abbr={ASR&TTS},
  abbr_publisher={VCC},
  title={The sequence-to-sequence baseline for the voice conversion challenge 2020: Cascading asr and tts},
  author={Huang, Wen-Chin and Hayashi, Tomoki and Watanabe, Shinji and Toda, Tomoki},
  arxiv={2010.02434},
  year={2020},
  code={https://github.com/espnet/espnet/tree/master/egs/vcc20}
}
@article{shi2020sequence,
  abbr={SE&ASR},
  abbr_publisher={NeurIPS},
  title={Sequence to multi-sequence learning via conditional chain mapping for mixture signals},
  author={Shi, Jing and Chang, Xuankai and Guo, Pengcheng and Watanabe, Shinji and Fujita, Yusuke and Xu, Jiaming and Xu, Bo and Xie, Lei},
  arxiv={2006.14150},
  year={2020},
  code={https://demotoshow.github.io/}
}
@inproceedings{chang2020end,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={End-to-End ASR with Adaptive Span Self-Attention.},
  author={Chang, Xuankai and Subramanian, Aswin Shanmugam and Guo, Pengcheng and Watanabe, Shinji and Fujita, Yuya and Omachi, Motoi},
  arxiv={http://www.interspeech2020.org/uploadfile/pdf/Thu-1-2-4.pdf},
  pages={3595--3599},
  year={2020}
}
@article{cho2020learning,
  abbr={TTS},
  abbr_publisher={Interspeech},
  title={Learning speaker embedding from text-to-speech},
  author={Cho, Jaejin and Zelasko, Piotr and Villalba, Jes{\'u}s and Watanabe, Shinji and Dehak, Najim},
  arxiv={2010.11221},
  year={2020},
  code={https://github.com/JaejinCho/espnet spkidtts.git}
}
@article{shi2020speaker,
  abbr={SE},
  abbr_publisher={Interspeech},
  title={Speaker-conditional chain model for speech separation and extraction},
  author={Shi, Jing and Xu, Jiaming and Fujita, Yusuke and Watanabe, Shinji and Xu, Bo},
  arxiv={2006.14149},
  year={2020}
}
@article{fujita2020insertion,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Insertion-based modeling for end-to-end automatic speech recognition},
  author={Fujita, Yuya and Watanabe, Shinji and Omachi, Motoi and Chan, Xuankai},
  arxiv={2005.13211},
  year={2020}
}
@article{horiguchi2020end,
  abbr={SD},
  abbr_publisher={Interspeech},
  title={End-to-end speaker diarization for an unknown number of speakers with encoder-decoder based attractors},
  author={Horiguchi, Shota and Fujita, Yusuke and Watanabe, Shinji and Xue, Yawen and Nagamatsu, Kenji},
  arxiv={2005.09921},
  year={2020},
  code={https://github.com/hitachi-speech/EEND}
}
@article{zhang2020end,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={End-to-end far-field speech recognition with unified dereverberation and beamforming},
  author={Zhang, Wangyou and Subramanian, Aswin Shanmugam and Chang, Xuankai and Watanabe, Shinji and Qian, Yanmin},
  arxiv={2005.10479},
  year={2020},
  code={https://github.com/Emrys365/espnet/blob/wsj1_mix_spatialized/egs/wsj1_mix_spatialized/asr1/}
}
@article{higuchi2020mask,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Mask CTC: Non-autoregressive end-to-end ASR with CTC and mask predict},
  author={Higuchi, Yosuke and Watanabe, Shinji and Chen, Nanxin and Ogawa, Tetsuji and Kobayashi, Tetsunori},
  arxiv={2005.08700},
  year={2020},
  code={https://github.com/espnet/espnet}
}

@inproceedings{tsunoo2019transformer,
  abbr={ASR},
  abbr_publisher={ASRU},
  title={Transformer ASR with contextual block processing},
  author={Tsunoo, Emiru and Kashiwagi, Yosuke and Kumakura, Toshiyuki and Watanabe, Shinji},
  booktitle=ASRU,
  pages={427--433},
  year={2019},
  organization={IEEE}
}

@inproceedings{chang2019mimo,
  abbr={ASR},
  abbr_publisher={ASRU},
  title={MIMO-Speech: End-to-end multi-channel multi-speaker speech recognition},
  author={Chang, Xuankai and Zhang, Wangyou and Qian, Yanmin and Le Roux, Jonathan and Watanabe, Shinji},
  booktitle=ASRU,
  pages={237--244},
  year={2019},
  organization={IEEE}
}

@inproceedings{inaguma2019multilingual,
  abbr={ST},
  abbr_publisher={ASRU},
  title={Multilingual end-to-end speech translation},
  author={Inaguma, Hirofumi and Duh, Kevin and Kawahara, Tatsuya and Watanabe, Shinji},
  booktitle=ASRU,
  pages={570--577},
  year={2019},
  organization={IEEE}
}

@inproceedings{kanda2019simultaneous,
  abbr={ASR+SD},
  abbr_publisher={ASRU},
  title={Simultaneous speech recognition and speaker diarization for monaural dialogue recordings with target-speaker acoustic models},
  author={Kanda, Naoyuki and Horiguchi, Shota and Fujita, Yusuke and Xue, Yawen and Nagamatsu, Kenji and Watanabe, Shinji},
  booktitle=ASRU,
  pages={31--38},
  year={2019},
  organization={IEEE}
}

@inproceedings{wang2019espresso,
  abbr={ASR},
  abbr_publisher={ASRU},
  title={Espresso: A fast end-to-end neural speech recognition toolkit},
  author={Wang, Yiming and Chen, Tongfei and Xu, Hainan and Ding, Shuoyang and Lv, Hang and Shao, Yiwen and Peng, Nanyun and Xie, Lei and Watanabe, Shinji and Khudanpur, Sanjeev},
  booktitle=ASRU,
  pages={136--143},
  year={2019},
  organization={IEEE}
}

@inproceedings{karita2019comparative,
  abbr={ASR},
  abbr_publisher={ASRU},
  title={A comparative study on transformer vs rnn in speech applications},
  author={Karita, Shigeki and Chen, Nanxin and Hayashi, Tomoki and Hori, Takaaki and Inaguma, Hirofumi and Jiang, Ziyan and Someki, Masao and Soplin, Nelson Enrique Yalta and Yamamoto, Ryuichi and Wang, Xiaofei and others},
  booktitle=ASRU,
  pages={449--456},
  year={2019},
  organization={IEEE},
  selected={True},
  html={https://ieeexplore.ieee.org/abstract/document/9003750},
  arxiv={1909.06317},
}

@inproceedings{fujita2019end,
  abbr={SD},
  abbr_publisher={ASRU},
  title={End-to-end neural speaker diarization with self-attention},
  author={Fujita, Yusuke and Kanda, Naoyuki and Horiguchi, Shota and Xue, Yawen and Nagamatsu, Kenji and Watanabe, Shinji},
  booktitle=ASRU,
  pages={296--303},
  year={2019},
  organization={IEEE}
}

@article{li2019multi,
  abbr={ASR},
  abbr_publisher={ASRU},
  title={Multi-stream end-to-end speech recognition},
  author={Li, Ruizhi and Wang, Xiaofei and Mallidi, Sri Harish and Watanabe, Shinji and Hori, Takaaki and Hermansky, Hynek},
  journal=ASRU,
  volume={28},
  pages={646--655},
  year={2019},
  publisher={IEEE}
}


@inproceedings{maciejewski2019analysis,
  abbr={SS},
  abbr_publisher={WASPAA},
  title={Analysis of robustness of deep single-channel speech separation using corpora constructed from multiple domains},
  author={Maciejewski, Matthew and Sell, Gregory and Fujita, Yusuke and Garcia-Perera, Leibny Paola and Watanabe, Shinji and Khudanpur, Sanjeev},
  booktitle=WASPAA,
  pages={165--169},
  year={2019},
  organization={IEEE}
}

@inproceedings{taniguchi2019generalized,
  abbr={ASR},
  abbr_publisher={WASPAA},
  title={Generalized weighted-prediction-error dereverberation with varying source priors for reverberant speech recognition},
  author={Taniguchi, Toru and Subramanian, Aswin Shanmugam and Wang, Xiaofei and Tran, Dung and Fujita, Yuya and Watanabe, Shinji},
  booktitle=WASPAA,
  pages={293--297},
  year={2019},
  organization={IEEE}
}

@inproceedings{subramanian2019speech,
  abbr={ASR},
  abbr_publisher={WASPAA},
  title={Speech enhancement using end-to-end speech recognition objectives},
  author={Subramanian, Aswin Shanmugam and Wang, Xiaofei and Baskar, Murali Karthick and Watanabe, Shinji and Taniguchi, Toru and Tran, Dung and Fujita, Yuya},
  booktitle=WASPAA,
  pages={234--238},
  year={2019},
  organization={IEEE}
}

@inproceedings{seki19inter,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={End-to-End Multilingual Multi-Speaker Speech Recognition},
  author={Hiroshi Seki, Takaaki Hori, Shinji Watanabe, Jonathan Le Roux and John Hershey},
  booktitle=Interspeech,
  year={2019}
}

@inproceedings{wiesner19inter,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Pretraining by Backtranslation for End-to-end ASR in Low-Resource Settings},
  author={Matthew Wiesner, Adithya Renduchintala, Shinji Watanabe, Chunxi Liu, Najim Dehak and Sanjeev Khudanpur},
  booktitle=Interspeech,
  year={2019}
}

@inproceedings{hayashi19inter,
  abbr={TTS},
  abbr_publisher={Interspeech},
  title={Pre-trained Text Embeddings for Enhanced Text-to-Speech Synthesis},
  author={Tomoki Hayashi, Shinji Watanabe, Tomoki Toda, Kazuya Takeda, Shubham Toshniwal and Karen Livescu},
  booktitle=Interspeech,
  year={2019}
}

@inproceedings{fujita19inter,
  abbr={SD},
  abbr_publisher={Interspeech},
  title={End-to-End Neural Speaker Diarization with Permutation-Free Objectives},
  author={Yusuke Fujita, Naoyuki Kanda, Shota Horiguchi, Kenji Nagamatsu and Shinji Watanabe},
  booktitle=Interspeech,
  year={2019}
}

@inproceedings{kerafiat19inter,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Analysis of Multilingual Sequence-to-Sequence speech recognition systems},
  author={Martin Karafiat, Murali Karthick Baskar, Shinji Watanabe, Takaaki Hori, Matthew Wiesner and Jan Černocký},
  booktitle=Interspeech,
  year={2019}
}

@inproceedings{delcroix10inter,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={End-to-end SpeakerBeam for single channel target speech recognition},
  author={Marc Delcroix, Shinji Watanabe, Tsubasa Ochiai, Keisuke Kinoshita, Shigeki Karita, Atsunori Ogawa and Tomohiro Nakatani},
  booktitle=Interspeech,
  year={2019}
}


@inproceedings{baskar19inter,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Semi-supervised Sequence-to-sequence ASR using Unpaired Speech and Text},
  author={Murali Karthick Baskar, Shinji Watanabe, Ramón Astudillo, Takaaki Hori, Lukas Burget and Jan Černocký},
  booktitle=Interspeech,
  year={2019}
}

@inproceedings{velazquez19inter,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Study of the performance of automatic speech recognition systems in speakers with Parkinson's Disease},
  author={Laureano Moro Velazquez, Jaejin Cho, Shinji Watanabe, Mark Hasegawa-Johnson, Odette Scharenborg, Kim Heejin and Najim Dehak},
  booktitle=Interspeech,
  year={2019}
}

@inproceedings{seki19inter,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Vectorized Beam Search for CTC-Attention-based Speech Recognition},
  author={Hiroshi Seki, Takaaki Hori, Shinji Watanabe, Niko Moritz and Jonathan Le Roux},
  booktitle=Interspeech,
  year={2019}
}

@inproceedings{garcia19inter,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Speaker recognition benchmark using the CHiME-5 corpus},
  author={Daniel Garcia-Romero, David Snyder, Shinji Watanabe, Gregory Sell, Alan McCree, Dan Povey and Sanjeev Khudanpur},
  booktitle=Interspeech,
  year={2019}
}

@inproceedings{karita19inter,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Improving Transformer Based End-to-End Speech Recognition with Connectionist Temporal Classification and Language Model Integration},
  author={Shigeki Karita, Nelson Yalta, Shinji Watanabe, Marc Delcroix, Atsunori Ogawa and Tomohiro Nakatani},
  booktitle=Interspeech,
  year={2019}
}

@inproceedings{naoyuki19inter,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Interference Speaker Loss for Target-Speaker Speech Recognition},
  author={Naoyuki Kanda, Shota Horiguchi, Ryoichi Takashima, Yusuke Fujita, Kenji Nagamatsu and Shinji Watanabe},
  booktitle=Interspeech,
  year={2019}
}

@inproceedings{yalta2019cnn,
  abbr={ASR},
  abbr_publisher={EUSIPCO},
  title={CNN-based multichannel end-to-end speech recognition for everyday home environments},
  author={Yalta, Nelson and Watanabe, Shinji and Hori, Takaaki and Nakadai, Kazuhiro and Ogata, Tetsuya},
  booktitle={2019 27th European Signal Processing Conference (EUSIPCO)},
  pages={1--5},
  year={2019},
  organization={IEEE}
}

@inproceedings{arora2019using,
  abbr={OCR},
  abbr_publisher={ICDAR},
  title={Using ASR methods for OCR},
  author={Arora, Ashish and Chang, Chun Chieh and Rekabdar, Babak and BabaAli, Bagher and Povey, Daniel and Etter, David and Raj, Desh and Hadian, Hossein and Trmal, Jan and Garcia, Paola and others},
  booktitle={2019 International Conference on Document Analysis and Recognition (ICDAR)},
  pages={663--668},
  year={2019},
  organization={IEEE}
}

@inproceedings{yalta2019weakly,
  abbr={Music},
  abbr_publisher={IJCNN},
  title={Weakly-supervised deep recurrent neural networks for basic dance step generation},
  author={Yalta, Nelson and Watanabe, Shinji and Nakadai, Kazuhiro and Ogata, Tetsuya},
  booktitle={2019 International Joint Conference on Neural Networks (IJCNN)},
  pages={1--8},
  year={2019},
  organization={IEEE}
}

@inproceedings{adams2019massively,
  abbr={ASR},
  abbr_publisher={NAACL},
  title={Massively Multilingual Adversarial Speech Recognition},
  author={Adams, Oliver and Wiesner, Matthew and Watanabe, Shinji and Yarowsky, David},
  booktitle=NAACL,
  pages={96--108},
  year={2019}
}

@inproceedings{baskar2019promising,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Promising accurate prefix boosting for sequence-to-sequence ASR},
  author={Baskar, Murali Karthick and Burget, Luk{\'a}{\v{s}} and Watanabe, Shinji and Karafi{\'a}t, Martin and Hori, Takaaki and {\v{C}}ernock{\`y}, Jan Honza},
  booktitle=ICASSP,
  pages={5646--5650},
  year={2019},
  organization={IEEE}
}

@inproceedings{inaguma2019transfer,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Transfer learning of language-independent end-to-end asr with language model fusion},
  author={Inaguma, Hirofumi and Cho, Jaejin and Baskar, Murali Karthick and Kawahara, Tatsuya and Watanabe, Shinji},
  booktitle=ICASSP,
  pages={6096--6100},
  year={2019},
  organization={IEEE}
}

@inproceedings{xu2019improving,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Improving end-to-end speech recognition with pronunciation-assisted sub-word modeling},
  author={Xu, Hainan and Ding, Shuoyang and Watanabe, Shinji},
  booktitle=ICASSP,
  pages={7110--7114},
  year={2019},
  organization={IEEE}
}

@inproceedings{cho2019language,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Language model integration based on memory control for sequence to sequence speech recognition},
  author={Cho, Jaejin and Watanabe, Shinji and Hori, Takaaki and Baskar, Murali Karthick and Inaguma, Hirofumi and Villalba, Jesus and Dehak, Najim},
  booktitle=ICASSP,
  pages={6191--6195},
  year={2019},
  organization={IEEE}
}

@inproceedings{wang2019stream,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Stream attention-based multi-array end-to-end speech recognition},
  author={Wang, Xiaofei and Li, Ruizhi and Mallidi, Sri Harish and Hori, Takaaki and Watanabe, Shinji and Hermansky, Hynek},
  booktitle=ICASSP,
  pages={7105--7109},
  year={2019},
  organization={IEEE}
}

@inproceedings{manohar2019acoustic,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Acoustic modeling for overlapping speech recognition: JHU CHiME-5 challenge system},
  author={Manohar, Vimal and Chen, Szu-Jui and Wang, Zhiqi and Fujita, Yusuke and Watanabe, Shinji and Khudanpur, Sanjeev},
  booktitle=ICASSP,
  pages={6665--6669},
  year={2019},
  organization={IEEE}
}

@inproceedings{hori2019cycle,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Cycle-consistency training for end-to-end speech recognition},
  author={Hori, Takaaki and Astudillo, Ramon and Hayashi, Tomoki and Zhang, Yu and Watanabe, Shinji and Le Roux, Jonathan},
  booktitle=ICASSP,
  pages={6271--6275},
  year={2019},
  organization={IEEE}
}

@inproceedings{kothinti2019joint,
  abbr={AED},
  abbr_publisher={ICASSP},
  title={Joint acoustic and class inference for weakly supervised sound event detection},
  author={Kothinti, Sandeep and Imoto, Keisuke and Chakrabarty, Debmalya and Sell, Gregory and Watanabe, Shinji and Elhilali, Mounya},
  booktitle=ICASSP,
  pages={36--40},
  year={2019},
  organization={IEEE}
}

@inproceedings{le2019phasebook,
  abbr={SE},
  abbr_publisher={ICASSP},
  title={The phasebook: Building complex masks via discrete representations for source separation},
  author={Le Roux, Jonathan and Wichern, Gordon and Watanabe, Shinji and Sarroff, Andy and Hershey, John R},
  booktitle=ICASSP,
  pages={66--70},
  year={2019},
  organization={IEEE}
}

@inproceedings{chang2019end,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={End-to-end monaural multi-speaker ASR system without pretraining},
  author={Chang, Xuankai and Qian, Yanmin and Yu, Kai and Watanabe, Shinji},
  booktitle=ICASSP,
  pages={6256--6260},
  year={2019},
  organization={IEEE}
}

@inproceedings{karita2019semi,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Semi-supervised end-to-end speech recognition using text-to-speech and autoencoders},
  author={Karita, Shigeki and Watanabe, Shinji and Iwata, Tomoharu and Delcroix, Marc and Ogawa, Atsunori and Nakatani, Tomohiro},
  booktitle=ICASSP,
  pages={6166--6170},
  year={2019},
  organization={IEEE}
}

@inproceedings{kanda2019acoustic,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Acoustic modeling for distant multi-talker speech recognition with single-and multi-channel branches},
  author={Kanda, Naoyuki and Fujita, Yusuke and Horiguchi, Shota and Ikeshita, Rintaro and Nagamatsu, Kenji and Watanabe, Shinji},
  booktitle=ICASSP,
  pages={6630--6634},
  year={2019},
  organization={IEEE}
}

@article{lin2018model,
  abbr={ML},
  abbr_publisher={Physica},
  title={Model parameter learning using Kullback--Leibler divergence},
  author={Lin, Chungwei and Marks, Tim K and Pajovic, Milutin and Watanabe, Shinji and Tung, Chih-kuan},
  journal={Physica A: Statistical Mechanics and its Applications},
  volume={491},
  pages={549--559},
  year={2018},
  publisher={Elsevier}
}

@inproceedings{hori2018end,
  abbr={ASR},
  abbr_publisher={SLT},
  title={End-to-end speech recognition with word-based RNN language models},
  author={Hori, Takaaki and Cho, Jaejin and Watanabe, Shinji},
  booktitle=SLT,
  pages={389--396},
  year={2018},
  organization={IEEE}
}

@inproceedings{liu2018low,
  abbr={ASR},
  abbr_publisher={SLT},
  title={Low-resource contextual topic identification on speech},
  author={Liu, Chunxi and Wiesner, Matthew and Watanabe, Shinji and Harman, Craig and Trmal, Jan and Dehak, Najim and Khudanpur, Sanjeev},
  booktitle=SLT,
  pages={656--663},
  year={2018},
  organization={IEEE}
}

@inproceedings{hayashi2018back,
  abbr={ASR},
  abbr_publisher={SLT},
  title={Back-translation-style data augmentation for end-to-end ASR},
  author={Hayashi, Tomoki and Watanabe, Shinji and Zhang, Yu and Toda, Tomoki and Hori, Takaaki and Astudillo, Ramon and Takeda, Kazuya},
  booktitle=SLT,
  pages={426--433},
  year={2018},
  organization={IEEE}
}

@inproceedings{cho2018multilingual,
  abbr={ASR},
  abbr_publisher={SLT},
  title={Multilingual sequence-to-sequence speech recognition: architecture, transfer learning, and language modeling},
  author={Cho, Jaejin and Baskar, Murali Karthick and Li, Ruizhi and Wiesner, Matthew and Mallidi, Sri Harish and Yalta, Nelson and Karafiat, Martin and Watanabe, Shinji and Hori, Takaaki},
  booktitle=SLT,
  pages={521--527},
  year={2018},
  organization={IEEE}
}

@article{watanabe2018espnet,
  abbr={ASR},
  abbr_publisher={Interspeech},
  author={Shinji Watanabe and Takaaki Hori and Shigeki Karita and Tomoki Hayashi and Jiro Nishitoba and Yuya Unno and Nelson {Enrique Yalta Soplin} and Jahn Heymann and Matthew Wiesner and Nanxin Chen and Adithya Renduchintala and Tsubasa Ochiai},
  abstract={This paper introduces a new open source platform for end-to-end speech processing named ESPnet. ESPnet mainly focuses on end-to-end automatic speech recognition (ASR), and adopts widely-used dynamic neural network toolkits, Chainer and PyTorch, as a main deep learning engine. ESPnet also follows the Kaldi ASR toolkit style for data processing, feature extraction/format, and recipes to provide a complete setup for speech recognition and other speech processing experiments. This paper explains a major architecture of this software platform, several important functionalities, which differentiate ESPnet from other open source ASR toolkits, and experimental results with major ASR benchmarks.},
  title={{ESPnet}: End-to-End Speech Processing Toolkit},
  year={2018},
  journal=interspeech,
  pages={2207--2211},
  doi={10.21437/Interspeech.2018-1456},
  html={https://www.isca-speech.org/archive/interspeech_2018/watanabe18_interspeech.html},
  pdf={https://www.isca-speech.org/archive/pdfs/interspeech_2018/watanabe18_interspeech.pdf},
  code={https://github.com/espnet/espnet},
  arxiv={1804.00015},
  selected={true}
}

@article{chen2018building,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Building State-of-the-art Distant Speech Recognition Using the CHiME-4 Challenge with a Setup of Speech Enhancement Baseline},
  author={Chen, Szu-Jui and Subramanian, Aswin Shanmugam and Xu, Hainan and Watanabe, Shinji},
  journal=interspeech,
  pages={1571--1575},
  year={2018}
}

@article{hayashi2018multi,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Multi-Head Decoder for End-to-End Speech Recognition},
  author={Hayashi, Tomoki and Watanabe, Shinji and Toda, Tomoki and Takeda, Kazuya},
  journal=interspeech,
  pages={801--805},
  year={2018}
}

@article{karita2018semi,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Semi-Supervised End-to-End Speech Recognition},
  author={Karita, Shigeki and Watanabe, Shinji and Iwata, Tomoharu and Ogawa, Atsunori and Delcroix, Marc},
  journal=interspeech,
  pages={2--6},
  year={2018}
}


@article{barker2018fifth,
  abbr={SE&ASR},
  abbr_publisher={Interspeech},
  title={The Fifth 'CHiME' Speech Separation and Recognition Challenge: Dataset, Task and Baselines},
  author={Barker, Jon and Watanabe, Shinji and Vincent, Emmanuel and Trmal, Jan},
  journal=interspeech,
  pages={1561--1565},
  year={2018},
  selected={true},
  pdf={https://www.isca-speech.org/archive/pdfs/interspeech_2018/barker18_interspeech.pdf},
  arxiv={1803.10609},
  html={https://www.isca-speech.org/archive/interspeech_2018/barker18_interspeech.html},
}

@article{subramanian2018student,
  abbr={SE},
  abbr_publisher={Interspeech},
  title={Student-Teacher Learning for BLSTM Mask-based Speech Enhancement},
  author={Subramanian, Aswin Shanmugam and Chen, Szu-Jui and Watanabe, Shinji},
  journal=interspeech,
  pages={3249--3253},
  year={2018}
}

@article{renduchintala2018multi,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Multi-Modal Data Augmentation for End-to-end ASR},
  author={Renduchintala, Adithya and Ding, Shuoyang and Wiesner, Matthew and Watanabe, Shinji},
  journal=interspeech,
  pages={2394--2398},
  year={2018}
}

@inproceedings{frederiksen2018effectiveness,
  abbr={LID},
  abbr_publisher={Interspeech},
  title={Effectiveness of single-channel blstm enhancement for language identification},
  author={Frederiksen, Peter Sibbern and Villalba, Jes{\'u}s and Watanabe, Shinji and Tan, Zheng-Hua and Dehak, Najim},
  booktitle={Interspeech 2018},
  pages={1823--1827},
  year={2018},
  organization={ISCA}
}

@inproceedings{sell2018diarization,
  abbr={SD},
  abbr_publisher={Interspeech},
  title={Diarization is Hard: Some Experiences and Lessons Learned for the JHU Team in the Inaugural DIHARD Challenge.},
  author={Sell, Gregory and Snyder, David and McCree, Alan and Garcia-Romero, Daniel and Villalba, Jes{\'u}s and Maciejewski, Matthew and Manohar, Vimal and Dehak, Najim and Povey, Daniel and Watanabe, Shinji and others},
  abstract={We describe in this paper the experiences of the Johns Hopkins University team during the inaugural DIHARD diarization evaluation. This new task provided microphone recordings in a variety of difficult conditions and challenged researchers to fully consider all speaker activity, without the currently typical practices of unscored collars or ignored overlapping speaker segments. This paper explores several key aspects of currently state-of-the-art diarization methods, such as training data selection, signal bandwidth for feature extraction, representations of speech segments (i-vector versus x-vector) and domain-adaptive processing. In the end, our best system clustered x-vector embeddings trained on wideband microphone data followed by Variational-Bayesian refinement and a speech activity detector specifically trained for this task with in-domain data was found to be the best performing. After presenting these decisions and their final result, we discuss lessons learned and remaining challenges within the lens of this new approach to diarization performance measurement.},
  booktitle={Interspeech},
  pages={2808--2812},
  year={2018},
  selected={true},
  html={https://www.isca-speech.org/archive/interspeech_2018/sell18_interspeech.html},
  pdf={https://www.isca-speech.org/archive/pdfs/interspeech_2018/sell18_interspeech.pdf},
}

@article{delcroix2018auxiliary,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Auxiliary Feature Based Adaptation of End-to-end ASR Systems},
  author={Delcroix, Marc and Watanabe, Shinji and Ogawa, Atsunori and Karita, Shigeki and Nakatani, Tomohiro},
  journal=interspeech,
  pages={2444--2448},
  year={2018}
}

@inproceedings{seki2018purely,
  abbr={ASR},
  abbr_publisher={ACL},
  title={A Purely End-to-End System for Multi-speaker Speech Recognition},
  author={Seki, Hiroshi and Hori, Takaaki and Watanabe, Shinji and Le Roux, Jonathan and Hershey, John R},
  booktitle=ACL,
  pages={2620--2630},
  year={2018}
}

@inproceedings{ochiai2018speaker,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Speaker adaptation for multichannel end-to-end speech recognition},
  author={Ochiai, Tsubasa and Watanabe, Shinji and Katagiri, Shigeru and Hori, Takaaki and Hershey, John},
  booktitle=ICASSP,
  pages={6707--6711},
  year={2018},
  organization={IEEE}
}

@inproceedings{seki2018end,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={An end-to-end language-tracking speech recognizer for mixed-language speech},
  author={Seki, Hiroshi and Watanabe, Shinji and Hori, Takaaki and Le Roux, Jonathan and Hershey, John R},
  booktitle=ICASSP,
  pages={4919--4923},
  year={2018},
  organization={IEEE}
}

@inproceedings{settle2018end,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={End-to-end multi-speaker speech recognition},
  author={Settle, Shane and Le Roux, Jonathan and Hori, Takaaki and Watanabe, Shinji and Hershey, John R},
  booktitle=ICASSP,
  pages={4819--4823},
  year={2018},
  organization={IEEE}
}


@inproceedings{lu2022towards,
  abbr={SE},
  abbr_publisher={ICASSP},
  title={Towards Low-distortion Multi-channel Speech Enhancement: The ESPNet-SE Submission to The L3DAS22 Challenge},
  author={Lu, Yen-Ju and Cornell, Samuele and Chang, Xuankai and Zhang, Wangyou and Li, Chenda and Ni, Zhaoheng and Wang, Zhong-Qiu and Watanabe, Shinji},
  booktitle=ICASSP,
  year={2022},
  organization={IEEE}
}