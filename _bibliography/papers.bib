---
@string{interspeech = {Proceedings of Interspeech}}
@string{ICASSP = {Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}}
@string{SLT = {Proceedings of IEEE Spoken Language Technology Workshop (SLT)}}
@string{ACL = {Proceedings of the Annual Meeting of the Association for Computational Linguistics}}
@string{ACLFindings = {Proceedings of Findings of the Annual Meeting of the Association for Computational Linguistics}}
@string{EACL = {Proceedings of the Conference of the European Chapter of the Association for Computational Linguistics}}
@string{NAACL = {Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies}}
@string{TASLP = {IEEE/ACM Transactions on Audio, Speech, and Language Processing}}
@string{IWSLT = {Proceedings of the 18th International Conference on Spoken Language Translation (IWSLT)}}
@string{VCC = {Voice Conversion Challenge}}
@string{ASRU = {IEEE Automatic Speech Recogiton and Understanding Workshop (ASRU)}}
@string{WASPAA = {IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)}}
@string{APSIPA = {Asia Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)}}
@string{ICML = {Proceedings of the International Conference on Machine Learning (ICML)}}
@string{ICLR = {Proceedings of the International Conference on Learning Representations (ICLR)}}
@string{NeurIPS = {Proceedings of the Conference on Neural Information Processing Systems}}


@inproceedings{chou2023evaluating,
    abbr={ASR},
    abbr_publisher={ASRU},
    title={Evaluating Self-supervised Speech Models on a Taiwanese Hokkien Corpus},
    author={Yi-Hui Chou and Kalvin Chang and Meng-Ju Wu and Winston Ou and Alice Wen-Hsin Bi and Carol Yang and Bryan Y. Chen and Rong-Wei Pai and Po-Yen Yeh and Jo-Peng Chiang and Lu-Tshiann Phoann and Winnie Chang and Chenxuan Cui and Noel Chen and Jiatong Shi},
    booktitle=ASRU,
    year={2023},
    publisher={IEEE},
  
}

@inproceedings{huang2023singing,
    abbr={SVC},
    abbr_publisher={ASRU},
    title={The Singing Voice Conversion Challenge 2023},
    author={Wen-Chin Huang and Lester Phillip Violeta and Songxiang Liu and Jiatong Shi and Tomoki Toda},
    booktitle=ASRU,
    year={2023},
    publisher={IEEE},
}

@inproceedings{shiohara2023domain,
    abbr={ASR},
    abbr_publisher={ASRU},
    title={Domain Adaptation by Data Distribution Matching via Submodularity for Speech Recognition},
    author={Yusuke Shinohara and Shinji Watanabe},
    booktitle=ASRU,
    year={2023},
    publisher={IEEE},
}

@inproceedings{kano2023summarize,
    abbr={Summarization&ST},
    abbr_publisher={ASRU},
    title={Summarize while Translating: Universal Model with Parallel Decoding for Summarization and Translation},
    author={Takatomo Kano and Atsunori Ogawa and Marc Delcroix and Kohei Matsuura and Takanori Ashihara and William Chen and Shinji Watanabe},
    booktitle=ASRU,
    year={2023},
    publisher={IEEE},
}

@inproceedings{li2023yodas,
    abbr={ASR},
    abbr_publisher={ASRU},
    title={YODAS: Youtube-Oriented Dataset for Audio and Speech},
    author={Xinjian Li and Shinnosuke Takamichi and Takaaki Saeki and William Chen and Sayaka Shiota and Shinji Watanabe},
    booktitle=ASRU,
    year={2023},
    publisher={IEEE},
}

@inproceedings{kohei2023single,
    abbr={SE&SS},
    abbr_publisher={ASRU},
    title={A Single Speech Enhancement Model Unifying Dereverberation, Denoising, Speaker Counting, Separation, and Extraction},
    author={Kohei Saijo and Wangyou Zhang and Zhong-Qiu Wang and Shinji Watanabe and Tetsunori Kobayashi and Tetsuji Ogawa},
    booktitle=ASRU,
    year={2023},
    publisher={IEEE},
}

@inproceedings{wang2023torchaudio,
    abbr={ASR&SSL},
    abbr_publisher={ASRU},
    title={TorchAudio 2.1: Advancing speech recognition, self-supervised learning, and audio processing components for PyTorch},
    author={Jeff Hwang and Moto Hira and Caroline Chen and Xiaohui Zhang and Zhaoheng Ni and Guangzhi Sun and Pingchuan Ma and Ruizhe Huang and Vineel Pratap and Yuekai Zhang and Anurag Kumar and Chin-Yun Yu and Chuang Zhu and Chunxi Liu and Jacob Kahn and Mirco Ravanelli and Peng Sun and Shinji Watanabe and Yangyang Shi and Yumeng Tao},
    booktitle=ASRU,
    year={2023},
    publisher={IEEE},
}

@inproceedings{zhang2023toward,
    abbr={SE},
    abbr_publisher={ASRU},
    title={Toward Universal Speech Enhancement For Diverse Input Conditions},
    author={Wangyou Zhang and Kohei Saijo and Zhong-Qiu Wang and Shinji Watanabe and Yanmin Qian},
    booktitle=ASRU,
    year={2023},
    publisher={IEEE},
}

@inproceedings{shi2023findings,
    abbr={ASR},
    abbr_publisher={ASRU},
    title={Findings of the 2023 ML-SUPERB Challenge: Pre-Training and Evaluation over More Languages and Beyond},
    author={Jiatong Shi and William Chen and Dan Berrebbi and Hsiu-Hsuan Wang and Wei Ping Huang and En Pei Hu and ho lam Chung and Xuankai Chang and Yuxun Tang and Shang-Wen Li and Abdelrahman Mohamed and Hung-yi Lee and Shinji Watanabe},
    booktitle=ASRU,
    year={2023},
    publisher={IEEE},
}

@inproceedings{chen2023joint,
    abbr={SSL},
    abbr_publisher={ASRU},
    title={Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning},
    author={William Chen and Jiatong Shi and Brian Yan and Dan Berrebbi and Wangyou Zhang and Yifan Peng and Xuankai Chang and Soumi Maiti and Shinji Watanabe},
    booktitle=ASRU,
    year={2023},
    publisher={IEEE},
}

@inproceedings{someki2023segment,
    abbr={ASR},
    abbr_publisher={ASRU},
    title={Segment-Level Vectorized Beam Search Based on Partially Autoregressive Inference},
    author={Masao Someki and Nicholas Eng and Yosuke Higuchi and Shinji Watanabe},
    booktitle=ASRU,
    year={2023},
    publisher={IEEE},
}

@inproceedings{peng2023reproducing,
    abbr={ASR&ST},
    abbr_publisher={ASRU},
    title={Reproducing Whisper-Style Training Using an Open-Source Toolkit and Publicly Available Data},
    author={Yifan Peng and Jinchuan Tian and Brian Yan and Dan Berrebbi and Xuankai Chang and Xinjian Li and Jiatong Shi and Siddhant Arora and William Chen and Roshan Sharma and Wangyou Zhang and Yui Sudo and Muhammad Shakeel and Jee-weon Jung and Soumi Maiti and Shinji Watanabe},
    booktitle=ASRU,
    year={2023},
    publisher={IEEE},
    code={https://github.com/espnet/espnet},
    blog={https://www.wavlab.org/activities/2023/foundations/},
    img={../assets/img/blog/owsm_pipeline.png}
}

@inproceedings{roshan2023espnet,
    abbr={Summarization},
    abbr_publisher={ASRU},
    title={ESPNet-SUMM: Introducing a novel large dataset, toolkit, and a cross-corpora evaluation of speech summarization systems},
    author={Roshan Sharma and William Chen and Takatomo Kano and Ruchira Sharma and Atsunori Ogawa and Siddhant Arora and Marc Delcroix and Rita Singh and Shinji Watanabe and Bhiksha Raj},
    booktitle=ASRU,
    year={2023},
    publisher={IEEE},
}


@inproceedings{fujita2023lvctc,
    abbr={ASR},
    abbr_publisher={ASRU},
    title={LV-CTC: Non-autoregressive ASR with CTC and latent variable models},
    author={Yuya Fujita and Shinji Watanabe and Xuankai Chang and Takashi Maekaku},
    booktitle=ASRU,
    year={2023},
    publisher={IEEE},
}

@inproceedings{wang2023unssor,
    abbr={SS},
    abbr_publisher={NeurIPS},
    title={UNSSOR: Unsupervised Neural Speech Separation by Leveraging Over-determined Training Mixtures},
    author={Zhong-Qiu Wang and Shinji Watanabe},
    booktitle=NeurIPS,
    year={2023},
}

@inproceedings{masuyama2023exploring,
    abbr={SS},
    abbr_publisher={WASPAA},
    title={Exploring the Integration of Speech Separation and Recognition with Self-Supervised Learning Representation},
    author={Yoshiki Masuyama and Xuankai Chang and Wangyou Zhang and Samuele Cornell and Zhong-Qiu Wang and Nobutaka Ono and Yanmin Qian and Shinji Watanabe},
    booktitle=WASPAA,
    year={2023},
}


@article{maciejewski2023adilemma,
  abbr={SS},
  abbr_publisher={CSL},
  title={Dilemma of Ground Truth in Noisy Speech Separation and an Approach to Lessen the Impact of Imperfect Training Data},
  author={Matthew Maciejewski and Jing Shi and Shinji Watanabe and Sanjeev Khudanpur},
  journal=TASLP,
  year={2023},
  publisher={IEEE},
}

@article{horiguchi2023online,
  abbr={SD},
  abbr_publisher={TASLP},
  title={Online Neural Diarization of Unlimited Numbers of Speakers Using Global and Local Attractors},
  author={Shota Horiguchi and Shinji Watanabe and Paola Garcia and Yuki Takashima and Yohei Kawaguchi},
  journal=TASLP,
  year={2023},
  publisher={IEEE},
}

@article{dalmia2023legonn,
  abbr={MT&ASR},
  abbr_publisher={TASLP},
  title={LegoNN: Building Modular Encoder-Decoder Models},
  author={Siddharth Dalmia and Dmytro Okhonko and Mike Lewis and Sergey Edunov and Shinji Watanabe and Florian Metze and Luke Zettlemoyer and Abdelrahman Mohamed},
  journal=TASLP,
  year={2023},
  publisher={IEEE},
}

@inproceedings{yan20203espnet-st-v2,
  abbr={ST},
  abbr_publisher={ACL(demo)},
  title={ESPnet-ST-v2: Multipurpose Spoken Language Translation Toolkit},
  author={Brian Yan and Jiatong Shi and Yun Tang and Hirofumi Inaguma and Yifan Peng and Siddharth Dalmia and Peter Polak and Patrick Fernandes and Dan Berrebbi and Tomoki Hayashi and Xiaohui Zhang and Zhaoheng Ni and Moto Hira and Soumi Maiti and Juan Pino and Shinji Watanabe},
  booktitle=ACL,
  year={2023},
}

@inproceedings{inaguma2023unity,
  abbr={ST},
  abbr_publisher={ACL},
  title={UnitY: Two-pass Direct Speech-to-speech Translation with Discrete Units},
  author={Hirofumi Inaguma and Sravya Popuri and Ilia Kulikov and Peng-Jen Chen and Changhan Wang and Yu-An Chung and Yun Tang and Ann Lee and Shinji Watanabe and Juan Pino},
  booktitle=ACL,
  year={2023},
}

@inproceedings{xu2023efficient,
  abbr={ASR},
  abbr_publisher={ICML},
  title={Efficient Sequence Transduction by Jointly Predicting Tokens and Durations},
  author={Hainan Xu and Fei Jia and Somshubra Majumdar and He Huang and Shinji Watanabe and Boris Ginsburg},
  booktitle=ICML,
  year={2023},
}

@inproceedings{saeki2023learning,
  abbr={TTS},
  abbr_publisher={IJCAI},
  title={Learning to Speak from Text: Zero-Shot Multilingual Text-to-Speech with Unsupervised Text Pretraining},
  author={Takaaki Saeki and Soumi Maiti and Xinjian Li and Shinji Watanabe and Shinnosuke Takamichi and Hiroshi Saruwatari},
  booktitle={IJCAI},
  year={2023},
}


@inproceedings{Wu_is2023,
  abbr={TTS},
  abbr_publisher={Interspeech},
  title={Deep Speech Synthesis from MRI-Based Articulatory Representations},
  author={Peter Wu and Tingle Li and Yijing Lu and Yubin Zhang and Jiachen Lian and Alan Black and Louis Goldstein and Shinji Watanabe and Gopala Krishna Anumanchipalli},
  booktitle=interspeech,
  year={2023},
}

@inproceedings{Tang_is2023,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={A New Benchmark of Aphasia Speech Recognition and Detection Based on E-Branchformer and Multi-task Learning},
  author={Jiyang Tang and William Chen and Xuankai Chang and Shinji Watanabe and Brian MacWhinney},
  booktitle=interspeech,
  year={2023},
}

@inproceedings{Xuankai_is2023,
  abbr={ASR&SSL},
  abbr_publisher={Interspeech},
  title={Exploration of Efficient End-to-End ASR using Discretized Input from Self-Supervised Learning},
  author={Xuankai Chang and Brian Yan and Yuya Fujita and Takashi Maekaku and Shinji Watanabe},
  booktitle=interspeech,
  year={2023},
}

@inproceedings{Peng_is2023_3,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization},
  author={Puyuan Peng and Brian Yan and Shinji Watanabe and David Harwath},
  booktitle=interspeech,
  year={2023},
}

@inproceedings{Arora_is2023,
  abbr={ASR&SLU},
  abbr_publisher={Interspeech},
  title={Integrating Pretrained ASR and LM to perform Sequence Generation for Spoken Language Understanding},
  author={Siddhant Arora and Hayato Futami and Yosuke Kashiwagi and Emiru Tsunoo and  Brian Yan and Shinji Watanabe},
  booktitle=interspeech,
  year={2023},
}

@inproceedings{Tsunoo_is2023,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Integration of Frame- and Label-synchronous Beam Search for Streaming Encoder--decoder Speech Recognition},
  author={Emiru Tsunoo and Hayato Futami and Yosuke Kashiwagi and Siddhant Arora and Shinji Watanabe},
  booktitle=interspeech,
  year={2023},
}

@inproceedings{Tian_is2023,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Bayes Risk Transducer: Transducer with Controllable Alignment Prediction},
  author={Jinchuan Tian and Jianwei Yu and Hangting Chen and Brian Yan and Chao Weng andDong Yu and Shinji Watanabe},
  booktitle=interspeech,
  year={2023},
}

@inproceedings{Jiatong_is2023_2,
  abbr={SSL},
  abbr_publisher={Interspeech},
  title={Exploration on HuBERT with Multiple Resolution},
  author={Jiatong Shi and Yun Tang and HIrofumi Inaguma and Hongyu Gong and Juan Pino and Shinji Watanabe},
  booktitle=interspeech,
  year={2023},
}

@inproceedings{Sudo_is2023_2,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Time-synchronous one-pass Beam Search for Parallel Online and Offline Transducers with Dynamic Block Training},
  author={Yui Sudo and Muhammad Shakeel and Yifan Peng and Shinji Watanabe},
  booktitle=interspeech,
  year={2023},
}

@inproceedings{Jiatong_is2023,
  abbr={ASR&SSL},
  abbr_publisher={Interspeech},
  title={ML-SUPERB: Multilingual Speech Universal PERformance Benchmark},
  author={Jiatong Shi and Dan Berrebbi and William Chen and En Pei Hu and Wei-Ping Huang and ho lam Chung and Xuankai Chang and Shang-Wen Li and, Abdelrahman Mohamed and Hung-yi Lee and Shinji Watanabe},
  booktitle=interspeech,
  year={2023},
}

@inproceedings{Kashiwagi_is2023,
  abbr={SLU},
  abbr_publisher={Interspeech},
  title={Tensor Decomposition for Minimization of E2E SLU Model Toward On-Device Processing},
  author={Yosuke Kashiwagi and Siddhant Arora and Hayato Futami and Jessica Huynh and Shih-Lun Wu and Yifan Peng and Brian Yan and Emiru Tsunoo and Shinji Watanabe},
  booktitle=interspeech,
  year={2023},
}

@inproceedings{Sudo_is2023,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={4D: Joint modeling of CTC, Attention, Transducer, and Mask-Predict decoders},
  author={Yui Sudo and Muhammad Shakeel and Brian Yan and Jiatong Shi and Shinji Watanabe},
  booktitle=interspeech,
  year={2023},
}

@inproceedings{Peng_is2023,
  abbr={SSL},
  abbr_publisher={Interspeech},
  title={DPHuBERT: Joint Distillation and Pruning of Self-Supervised Speech Models},
  author={Yifan Peng and Yui Sudo and Muhammad Shakeel and Shinji Watanabe},
  booktitle=interspeech,
  year={2023},
}

@inproceedings{Pend_is2023_2,
  abbr={ASR&ST},
  abbr_publisher={Interspeech},
  title={lA Comparative Study on E-Branchformer vs Conformer in Speech Recognition, Translation, and Understanding Tasks},
  author={Yifan Peng andKwangyoun Kim and Felix Wu and Brian Yan and Siddhant Arora and William Chen and Jiyang Tang and Suwon Shon and Prashant Sridhar and Shinji Watanabe},
  booktitle=interspeech,
  year={2023},
}

@inproceedings{Chen_is2023,
  abbr={SSL},
  abbr_publisher={Interspeech},
  title={Reducing Barriers to Self-Supervised Learning: HuBERT Pre-training with Academic Compute},
  author={William Chen and Xuankai Chang and Yifan Peng and Zhaoheng Ni and Soumi Maiti and Shinji Watanabe},
  booktitle=interspeech,
  year={2023},
}

@inproceedings{Sharma_is2023,
  abbr={Summarization},
  abbr_publisher={Interspeech},
  title={BASS: Block-wise Adaptation for Speech Summarization},
  author={Roshan Sharma and Siddhant Arora and Kenneth Zheng and Shinji Watanabe and Rita Singh and Bhiksha Raj},
  booktitle=interspeech,
  year={2023},
}

@inproceedings{yan_eacl2023,
  abbr={ST},
  abbr_publisher={EACL},
  title={CTC Alignments Improve Autoregressive Translation},
  author={Brian Yan and Siddharth Dalmia and Yosuke Higuchi and Graham Neubig and Florian Metze and Alan W Black and Shinji Watanabe},
  booktitle=EACL,
  year={2023},
}

@inproceedings{dan_iclr2023,
  abbr={ASR},
  abbr_publisher={ICLR},
  title={Continuous Pseudo-Labeling from the Start},
  author={Dan Berrebbi and Ronan Collobert and Samy Bengio and Navdeep Jaitly and Tatiana Likhomanenko},
  booktitle=ICLR,
  year={2023},
}


@inproceedings{hainan_icassp2023,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Multi-blank Transducers for Speech Recognition},
  author={Hainan Xu and Fei Jia and Somshubra Majumdar and Shinji Watanabe and and Boris Ginsburg},
  booktitle=ICASSP,
  year={2023}
}

@inproceedings{muqiao_icassp2023,
  abbr={SE},
  abbr_publisher={ICASSP},
  title={PAAPLoss: A Phonetic-Aligned Acoustic Parameter Loss for Speech Enhancement},
  author={Muqiao Yang and Joseph Konan and David Bick and Yunyang Zeng and Shuo Han and Anurag Kumar and Shinji Watanabe and and Bhiksha Raj},
  booktitle=ICASSP,
  year={2023}
}

@inproceedings{jee_icassp2023,
  abbr={SD},
  abbr_publisher={ICASSP},
  title={In search of strong embedding extractors for speaker diarisation},
  author={Jee-weon Jung and Hee-Soo Heo and Bong-Jin Lee and Jaesung Huh and Andrew Brown and Youngki Kwon and Shinji Watanabe and and Joon Son Chung},
  booktitle=ICASSP,
  year={2023}
}

@inproceedings{felix_icassp2023,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Wav2Seq: Pre-training Speech-to-Text Encoder-Decoder Models Using Pseudo Languages},
  author={Felix Wu and Kwangyoun Kim and Shinji Watanabe and Kyu J. Han and Ryan McDonald and Kilian Q. Weinberger and and Yoav Artzi},
  booktitle=ICASSP,
  year={2023}
}

@inproceedings{yosuke_icassp2023,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={BECTRA: Transducer-based End-to-End ASR with BERT-Enhanced Encoder},
  author={Yosuke Higuchi and Tetsuji Ogawa and Tetsunori Kobayashi and and Shinji Watanabe},
  booktitle=ICASSP,
  year={2023}
}

@inproceedings{yousuke_icassp2023,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={InterMPL: Momentum Pseudo-Labeling with Intermediate CTC Loss},
  author={Yosuke Higuchi and Tetsuji Ogawa and Tetsunori Kobayashi and and Shinji Watanabe},
  booktitle=ICASSP,
  year={2023}
}

@inproceedings{liwei_icassp2023,
  abbr={TTS&SSL},
  abbr_publisher={ICASSP},
  title={A Unified One-Shot Prosody and Speaker Conversion System with Self-Supervised Discrete Speech Units},
  author={Li-Wei Chen and Shinji Watanabe and and Alexander Rudnicky},
  booktitle=ICASSP,
  year={2023}
}

@inproceedings{yunyang_icassp2023,
  abbr={SE},
  abbr_publisher={ICASSP},
  title={TAPLoss: A Temporal Acoustic Parameter Loss for Speech Enhancement},
  author={Yunyang Zeng and Joseph Konan and Shuo Han and David Bick and Muqiao Yang and Anurag Kumar and Shinji Watanabe and and Bhiksha Raj},
  booktitle=ICASSP,
  year={2023}
}

@inproceedings{jiatong2_icassp2023,
  abbr={SSL&SLU},
  abbr_publisher={ICASSP},
  title={Bridging Speech and Text Pre-trained Models with Unsupervised ASR},
  author={Jiatong Shi and Chan-Jan Hsu and Holam Chung and Dongji Gao and Paola Garcia and Shinji Watanabe and Ann Lee and and Hung-yi Lee},
  booktitle=ICASSP,
  year={2023}
}

@inproceedings{jiatong3_icassp2023,
  abbr={Music},
  abbr_publisher={ICASSP},
  title={PHONEix: Acoustic Feature Processing Strategy for Enhanced Singing Pronunciation with Phoneme Distribution Predictor},
  author={Yuning Wu and Jiatong Shi and Tao Qian and and Qin Jin},
  booktitle=ICASSP,
  year={2023}
}

@inproceedings{takatomo_icassp2023,
  abbr={SLU},
  abbr_publisher={ICASSP},
  title={Speech summarization of long spoken document: Improving memory efficiency of speech/text encoders},
  author={Takatomo Kano and Atsunori Ogawa and Marc Delcroix and Roshan Sharma and Kohei Matsuura and and Shinji Watanabe},
  booktitle=ICASSP,
  year={2023}
}

@inproceedings{suwon_icassp2023,
  abbr={SSL},
  abbr_publisher={ICASSP},
  title={Context-Aware Fine-Tuning of Self-Supervised Speech Models},
  author={Suwon Shon and Felix Wu and Kwangyoun Kim and Prashant Sridhar and Karen Livescu and and Shinji Watanabe},
  booktitle=ICASSP,
  year={2023}
}

@inproceedings{jiatong1_icassp2023,
  abbr={S2ST},
  abbr_publisher={ICASSP},
  title={Enhancing Speech-To-Speech Translation with Multiple TTS Targets},
  author={Jiatong Shi and Yun Tang and Ann Lee and Hirofumi Inaguma and Changhan Wang and Juan Pino and and Shinji Watanabe},
  booktitle=ICASSP,
  year={2023}
}

@inproceedings{_icassp2023,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Streaming Joint Speech Recognition and Disfluency Detection},
  author={Hayato Futami and Emiru Tsunoo and Kentaro Shibata and Yosuke Kashiwagi and Takao Okuda and Siddhant Arora and and Shinji Watanabe},
  booktitle=ICASSP,
  year={2023}
}

@inproceedings{brian_icassp2023,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Towards Zero-Shot Code-Switched Speech Recognition},
  author={Brian Yan and Matthew Wiesner and Ondrej Klejch and Preethi Jyothi and and Shinji Watanabe},
  booktitle=ICASSP,
  year={2023}
}

@inproceedings{motoi_icassp2023,
  abbr={ST},
  abbr_publisher={ICASSP},
  title={Align and Write and Re-order: Explainable End-to-End Speech Translation via Operation Sequence Generation},
  author={Motoi Omachi and Brian Yan and Siddharth Dalmia and Yuya Fujita and and Shinji Watanabe},
  booktitle=ICASSP,
  year={2023}
}

@inproceedings{william_icassp2023,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Improving Massively Multilingual ASR With Auxiliary CTC Objectives},
  author={William Chen and Brian Yan and Jiatong Shi and Yifan Peng and Soumi Maiti and and Shinji Watanabe},
  booktitle=ICASSP,
  year={2023}
}

@inproceedings{soumi_icassp2023,
  abbr={SSL},
  abbr_publisher={ICASSP},
  title={SpeechLMScore: Evaluating Speech Generation Using Speech Language Model},
  author={Soumi Maiti and Yifan Peng and Takaaki Saeki and and Shinji Watanabe},
  booktitle=ICASSP,
  year={2023}
}

@inproceedings{peter_icassp2023,
  abbr={TTS},
  abbr_publisher={ICASSP},
  title={Speaker-Independent Acoustic-to-Articulatory Speech Inversion},
  author={Peter Wu and Li-Wei Chen and Cheol Jun Cho and Shinji Watanabe and Louis Goldstein and Alan W. Black and and Gopala K. Anumanchipalli},
  booktitle=ICASSP,
  year={2023}
}

@inproceedings{siddhant_icassp2023,
  abbr={SLU},
  abbr_publisher={ICASSP},
  title={Joint Modelling of Spoken Language Understanding Tasks with Integrated Dialog History},
  author={Siddhant Arora and Hayato Futami and Emiru Tsunoo and Brian Yan and and Shinji Watanabe},
  booktitle=ICASSP,
  year={2023}
}

@inproceedings{zhongqiu2_icassp2023,
  abbr={SS},
  abbr_publisher={ICASSP},
  title={TF-GridNet: Making Time-Frequency Domain Models Great Again for Monaural Speaker Separation},
  author={Zhong-Qiu Wang and Samuele Cornell and Shukjae Choi and Younglo Lee and Byeong-Yeol Kim and and Shinji Watanabe},
  booktitle=ICASSP,
  year={2023}
}

@inproceedings{dongji_icassp2023,
  abbr={ASR&SSL},
  abbr_publisher={ICASSP},
  title={EURO: ESPnet Unsupervised ASR Open-Source Toolkit},
  author={Dongji Gao and Jiatong Shi and Shun-Po Chuang and Leibny Paola Garcia and Hung-yi Lee and Shinji Watanabe and and Sanjeev Khudanpur},
  booktitle=ICASSP,
  year={2023}
}

@inproceedings{zhongqiu_icassp2023,
  abbr={SE},
  abbr_publisher={ICASSP},
  title={Neural Speech Enhancement with Very Low Algorithmic Latency and Complexity via Integrated Full- and Sub-Band Modeling},
  author={Zhong-Qiu Wang and Samuele Cornell and Shukjae Choi and Younglo Lee and Byeong-Yeol Kim and and Shinji Watanabe},
  booktitle=ICASSP,
  year={2023}
}

@inproceedings{dan_icassp2023,
  abbr={ASR&SSL},
  abbr_publisher={ICASSP},
  title={Avoid Overthinking in Self-Supervised Models for Speech Recognition},
  author={Dan Berrebbi and Brian Yan and and Shinji Watanabe},
  booktitle=ICASSP,
  year={2023}
}

@inproceedings{jianchen_icassp2023,
  abbr={TTS},
  abbr_publisher={ICASSP},
  title={Articulatory Representation Learning Via Joint Factor Analysis and Neural Matrix Factorization},
  author={Jiachen Lian and Alan W Black and Yijing Lu and Louis Goldstein and Shinji Watanabe and and Gopala K. Anumanchipalli},
  booktitle=ICASSP,
  year={2023}
}

@inproceedings{yifan_icassp2023,
  abbr={ASR&SLU&SSL},
  abbr_publisher={ICASSP},
  title={Structured Pruning of Self-Supervised Pre-trained Models for Speech Recognition and Understanding},
  author={Yifan Peng and Kwangyoun Kim and Felix Wu and Prashant Sridhar and and Shinji Watanabe},
  booktitle=ICASSP,
  year={2023}
}

@inproceedings{takashi_icassp2023,
  abbr={SSL},
  abbr_publisher={ICASSP},
  title={Fully Unsupervised Topic Clustering of Unlabelled Spoken Audio Using Self-Supervised Representation Learning and Topic Model},
  author={Takashi Maekaku and Yuya Fujita and Xuankai Chang and and Shinji Watanabe},
  booktitle=ICASSP,
  year={2023}
}

@inproceedings{zhe_icassp2023,
  abbr={MultiModal},
  abbr_publisher={ICASSP},
  title={The Multimodal Information Based Speech Processing (MISP) 2022 Challenge: Audio-Visual Diarization and Recognition},
  author={Zhe Wang and Shilong Wu and Hang Chen and Mao-Kui He and Jun Du and Chin-Hui Lee and Jingdong Chen and Shinji Watanabe and Sabato Siniscalchi and Odette Scharenborg and Diyuan Liu and Baocai Yin and Jia Pan and Jianqing Gao and and Cong Liu},
  booktitle=ICASSP,
  year={2023}
}

@inproceedings{junwei_icassp2023,
  abbr={SSL&ASR},
  abbr_publisher={ICASSP},
  title={FINDADAPTNET: Find and Insert Adapters by Learned Layer Importance},
  author={Junwei Huang and Karthik Ganesan and Soumi Maiti and Young Min Kim and Xuankai Chang and Paul Liang and and Shinji Watanabe},
  booktitle=ICASSP,
  year={2023}
}

@inproceedings{yifan_icassp2023,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={I3D: Transformer architectures with input-dependent dynamic depth for speech recognition},
  author={Yifan Peng and Jaesong Lee and and Shinji Watanabe},
  booktitle=ICASSP,
  year={2023}
}


@inproceedings{liwei_aaai2022,
  abbr={TTS},
  abbr_publisher={AAAI},
  title={A Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech},
  author={Li-Wei Chen and Alexander Rudnicky and Shinji Watanabe},
  booktitle={Proceedings of AAAI},
  year={2022},
}

@inproceedings{yosuke_emnlp2022,
  abbr={ASR},
  abbr_publisher={EMNLP},
  title={BERT Meets CTC: New Formulation of End-to-End Speech Recognition with Pre-trained Masked Language Model},
  author={Yosuke Higuchi and Brian Yan and Siddhant Arora and Tetsuji Ogawa and Tetsunori Kobayashi and Shinji Watanabe},
  booktitle={Proceedings of Findings of EMNLP},
  year={2022},
}

@inproceedings{siddhant_emnlp2022,
  abbr={SLU},
  abbr_publisher={EMNLP},
  title={Token-level Sequence Labeling for Spoken Language Understanding using Compositional End-to-End Models},
  author={Siddhant Arora and Siddharth Dalmia and Brian Yan and Florian Metze and Alan W Black and Shinji Watanabe},
  booktitle={Proceedings of Findings of EMNLP},
  year={2022},
}

@inproceedings{shota_taslp2022-2,
  abbr={SD},
  abbr_publisher={TASLP},
  title={Online Neural Diarization of Unlimited Numbers of Speakers Using Global and Local Attractors},
  author={Shota Horiguchi and Shinji Watanabe and Paola Garcia and Yuki Takashima and Yohei Kawaguchi},
  booktitle=TASLP,
  year={2022},
}

@inproceedings{matthew_csl2022,
  abbr={SE},
  abbr_publisher={CSL},
  title={A Dilemma of Ground Truth in Noisy Speech Separation and an Approach to Lessen the Impact of Imperfect Training Data},
  author={Matthew Maciejewski and Jing Shi and Shinji Watanabe and Sanjeev Khudanpur},
  booktitle={Computer Speech & Language},
  year={2022},
}

@inproceedings{wangyou_taslp2022,
  abbr={SE},
  abbr_publisher={TASLP},
  title={End-to-End Dereverberation, Beamforming, and Speech Recognition in A Cocktail Party},
  author={Wangyou Zhang and Xuankai Chang and Christoph Boeddeker and Tomohiro Nakatani and Shinji Watanabe and Yanmin Qian},
  booktitle=TASLP,
  year={2022},
}

@inproceedings{zhongqiu_spl2022,
  abbr={SE},
  abbr_publisher={SPL},
  title={Improving Frame-Online Neural Speech Enhancement with Overlapped-Frame Prediction},
  author={Zhong-Qiu Wang and Shinji Watanabe},
  booktitle={IEEE Signal Processing Letters},
  year={2022},
}

@inproceedings{shota_taslp2022,
  abbr={SD},
  abbr_publisher={TASLP},
  title={Encoder-Decoder Based Attractors for End-to-End Neural Diarization},
  author={Shota Horiguchi and Yusuke Fujita and Shinji Watanabe and Yawen Xue and Paola Garcia},
  booktitle=TASLP,
  year={2022},
}

@inproceedings{abdel_jstsp2022,
  abbr={ASR},
  abbr_publisher={JSTSP},
  title={Self-Supervised Speech Representation Learning: A Review},
  author={Abdelrahman Mohamed and Hung-yi Lee and Lasse Borgholt and Jakob D. Havtorn and Joakim Edin and Christian Igel and Katrin Kirchhoff and Shang-Wen Li and Karen Livescu and Lars Maaløe and Tara N. Sainath and Shinji Watanabe},
  booktitle={IEEE Journal of Selected Topics in Signal Processing},
  year={2022},
}

@inproceedings{antonios_iwslt2022,
  abbr={ST},
  abbr_publisher={IWSLT},
  title={Findings of the IWSLT 2022 Evaluation Campaign},
  author={Antonios Anastasopoulos and Loïc Barrault and Luisa Bentivogli and Marcely Zanon Boito and Ondřej Bojar and Roldano Cattoni and Anna Currey and Georgiana Dinu and Kevin Duh and Maha Elbayad and Clara Emmanuel and Yannick Estève and Marcello Federico and Christian Federmann and Souhir Gahbiche and Hongyu Gong and Roman Grundkiewicz and Barry Haddow and Benjamin Hsu and Dávid Javorský and Vĕra Kloudová and Surafel Lakew and Xutai Ma and Prashant Mathur and Paul McNamee and Kenton Murray and Maria Nǎdejde and Satoshi Nakamura and Matteo Negri and Jan Niehues and Xing Niu and John Ortega and Juan Pino and Elizabeth Salesky and Jiatong Shi and Matthias Sperber and Sebastian Stüker and Katsuhito Sudoh and Marco Turchi and Yogesh Virkar and Alexander Waibel and Changhan Wang and Shinji Watanabe},
  booktitle=IWSLTT,
  year={2022},
}

@inproceedings{yushi_slt2022,
  abbr={SD&SS},
  abbr_publisher={SLT},
  title={EEND-SS: Joint End-to-End Neural Speaker Diarization and Speech Separation for Flexible Number of Speakers},
  author={Yushi Ueda and Soumi Maiti and Shinji Watanabe and Chunlei Zhang and Meng Yu and Shi-Xiong Zhang and Yong Xu},
  booktitle=SLT,
  year={2022},
}

@inproceedings{tzuhsun_slt2022,
  abbr={ASR&SD&SLU&ER},
  abbr_publisher={SLT},
  title={SUPERB @ SLT 2022: Challenge on Generalization and Efficiency of Self-Supervised Speech Representation Learning},
  author={Tzu-hsun Feng and Annie Dong and Ching-Feng Yeh and Shu-wen Yang and Tzu-Quan Lin and Jiatong Shi and Kai-Wei Chang and Zili Huang and Haibin Wu and Xuankai Chang and Shinji Watanabe and Abdel-rahman Mohamed and Shang-Wen Li and Hung-yi Lee},
  booktitle=SLT,
  year={2022},
}

@inproceedings{kwangyoun_slt2022,
  abbr={ASR},
  abbr_publisher={SLT},
  title={E-Branchformer: Branchformer with Enhanced merging for speech recognition},
  author={Kwangyoun Kim and Felix Wu and Yifan Peng and Jing Pan and Prashant Sridhar and Kyu Jeong Han and Shinji Watanabe},
  booktitle=SLT,
  year={2022},
}

@inproceedings{yifan_slt2022,
  abbr={ASR&SLU},
  abbr_publisher={SLT},
  title={A Study on the Integration of Pre-Trained SSL and ASR and LM and SLU Models for Spoken Language Understanding},
  author={Yifan Peng and Siddhant Arora and Yosuke Higuchi and Yushi Ueda and Sujay Kumar and Karthik Ganesan and Siddharth Dalmia and Xuankai Chang and Shinji Watanabe},
  booktitle=SLT,
  year={2022},
}

@inproceedings{yen_slt2022,
  abbr={ASR&SSL},
  abbr_publisher={SLT},
  title={On Compressing Sequences for Self-Supervised Speech Models},
  author={Yen Meng and Hsuan-Jui Chen and Jiatong Shi and Shinji Watanabe and Paola Garcia and Hung-yi Lee and Hao Tang},
  booktitle=SLT,
  year={2022},
}

@inproceedings{yoshiki_slt2022,
  abbr={ASR&SE&SSL},
  abbr_publisher={SLT},
  title={End-to-End Integration of Speech Recognition and Dereverberation and Beamforming and Self-Supervised Learning Representation},
  author={Yoshiki Masuyama and Xuankai Chang and Samuele Cornell and Shinji Watanabe and Nobutaka Ono},
  booktitle=SLT,
  year={2022},
}

@inproceedings{shota_slt2022,
  abbr={SE},
  abbr_publisher={SLT},
  title={Mutual Learning of Single- and Multi-Channel End-to-End Neural Diarization},
  author={Shota Horiguchi and Yuki Takashima and Shinji Watanabe and Paola Garcia},
  booktitle=SLT,
  year={2022},
}

@inproceedings{robin_slt2022,
  abbr={ASR},
  abbr_publisher={SLT},
  title={End-to-End Multi-speaker ASR with Independent Vector Analysis},
  author={Robin Scheibler and Wangyou Zhang and Xuankai Chang and Shinji Watanabe and Yanmin Qian},
  booktitle=SLT,
  year={2022},
}

@inproceedings{jiatong_a_interspeech2022,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={VQ-T: RNN Transducers using Vector-Quantized Prediction Network States},
  author={Jiatong Shi and George Saon and David Haws and Shinji Watanabe and Brian Kingsbury},
  booktitle=interspeech,
  year={2022},
}

@inproceedings{jaesong_interspeech2022,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Memory-Efficient Training of RNN-Transducer with Sampled Softmax},
  author={Jaesong Lee and Lukas Lee and Shinji Watanabe},
  booktitle=interspeech,
  year={2022},
}

@inproceedings{keqi_interspeech2022,
  abbr={SLU&ST},
  abbr_publisher={Interspeech},
  title={Blockwise Streaming Transformer for Spoken Language Understanding and Simultaneous Speech Translation},
  author={Keqi Deng and Shinji Watanabe and Jiatong Shi and Siddhant Arora},
  booktitle=interspeech,
  year={2022},
}

@inproceedings{shuai_interspeech2022,
  abbr={Music},
  abbr_publisher={Interspeech},
  title={SingAug: Data Augmentation for Singing Voice Synthesis with Cycle-consistent Training Strategy},
  author={Shuai Guo and Jiatong Shi and Tao Qian and Shinji Watanabe and Qin Jin},
  booktitle=interspeech,
  year={2022},
}

@inproceedings{jiatong_b_interspeech2022,
  abbr={Music},
  abbr_publisher={Interspeech},
  title={Muskits: an End-to-end Music Processing Toolkit for Singing Voice Synthesis},
  author={Jiatong Shi and Shuai Guo and Tao Qian and Tomoki Hayashi and Yuning Wu and Fangzheng Xu and Xuankai Chang and Huazhe Li and Peter Wu and Shinji Watanabe and Qin Jin},
  booktitle=interspeech,
  year={2022},
}

@inproceedings{hang_interspeech2022,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Audio-Visual Speech Recognition in MISP2021 Challenge: Dataset Release and Deep Analysis},
  author={Hang Chen and Jun Du and Yusheng Dai and Chin-Hui Lee and Sabato Marco Siniscalchi and Shinji Watanabe and Odette Scharenborg and Jingdong Chen and Baocai Yin and Jia Pan},
  booktitle=interspeech,
  year={2022},
}

@inproceedings{hengshun_interspeech2022,
  abbr={KWS},
  abbr_publisher={Interspeech},
  title={Audio-Visual Wake Word Spotting in MISP2021 Challenge: Dataset Release and Deep Analysis},
  author={Hengshun Zhou and Jun Du and Gongzhen Zou and Zhaoxu Nian and Chin-Hui Lee and Sabato Marco Siniscalchi and Shinji Watanabe and Odette Scharenborg and Jingdong Chen and Shifu Xiong and Jian-Qing Gao},
  booktitle=interspeech,
  year={2022},
}

@inproceedings{xijian_interspeech2022,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={ASR2K: Speech Recognition for Around 2000 Languages without Audio},
  author={Xinjian Li and Florian Metze and David R. Mortensen and Alan W Black and Shinji Watanabe},
  booktitle=interspeech,
  year={2022},
}

@inproceedings{yenju_interspeech2022,
  abbr={SE},
  abbr_publisher={Interspeech},
  title={ESPnet-SE++: Speech Enhancement for Robust Speech Recognition and Translation and and Understanding},
  author={Yen-Ju Lu and Xuankai Chang and Chenda Li and Wangyou Zhang and Samuele Cornell and Zhaoheng Ni and Yoshiki Masuyama and Brian Yan and Robin Scheibler and Zhong-Qiu Wang and Yu Tsao and Yanmin Qian and Shinji Watanabe},
  booktitle=interspeech,
  year={2022},
}

@inproceedings{siddhant_interspeech2022,
  abbr={SLU},
  abbr_publisher={Interspeech},
  title={Two-Pass Low Latency End-to-End Spoken Language Understanding},
  author={Siddhant Arora and Siddharth Dalmia and Xuankai Chang and Brian Yan and Alan W Black and Shinji Watanabe},
  booktitle=interspeech,
  year={2022},
}

@inproceedings{peter_interspeech2022,
  abbr={TTS},
  abbr_publisher={Interspeech},
  title={Deep Speech Synthesis from Articulatory Representations},
  author={Peter Wu and Shinji Watanabe and Louis Goldstein and Alan W Black and Gopala Krishna Anumanchipalli},
  booktitle=interspeech,
  year={2022},
}

@inproceedings{yusuke_interspeech2022,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Minimum latency training of sequence transducers for streaming end-to-end speech recognition},
  author={Yusuke Shinohara and Shinji Watanabe},
  booktitle=interspeech,
  year={2022},
}

@inproceedings{yui_interspeech2022,
  abbr={ASR},
  abbr_publisher={Interspeech},
  author={Yui Sudo and Shakeel Muhammad and Kazuhiro Nakadai and Jiatong Shi and Shinji Watanabe},
  title={Streaming Automatic Speech Recognition with Re-blocking Processing Based on Integrated Voice Activity Detection},
  booktitle=interspeech,
  year={2022},
}

@inproceedings{tatsuya_interspeech2022,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Better Intermediates Improve CTC Inference},
  author={Tatsuya Komatsu and Yusuke Fujita and Jaesong Lee and Lukas Lee and Shinji Watanabe and Yusuke Kida},
  booktitle=interspeech,
  year={2022},
}

@inproceedings{yuki_interspeech2022,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Updating Only Encoders Prevents Catastrophic Forgetting of End-to-End ASR Models},
  author={Yuki Takashima and Shota Horiguchi and Shinji Watanabe and Leibny Paola Garcia Perera and Yohei Kawaguchi},
  booktitle=interspeech,
  year={2022},
}

@inproceedings{takashi_interspeech2022,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Attention Weight Smoothing Using Prior Distributions for Transformer-Based End-to-End ASR},
  author={Takashi Maekaku and Yuya Fujita and Yifan Peng and Shinji Watanabe},
  booktitle=interspeech,
  year={2022},
}

@inproceedings{emiru_interspeech2022,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Residual Language Model for End-to-end Speech Recognition},
  author={Emiru Tsunoo and Yosuke Kashiwagi and Chaitanya Prasad Narisetty and Shinji Watanabe},
  booktitle=interspeech,
  year={2022},
}

@inproceedings{nathaniel_interspeech2022,
  abbr={TTS},
  abbr_publisher={Interspeech},
  title={When Is TTS Augmentation Through a Pivot Language Useful?},
  author={Nathaniel Romney Robinson and Perez Ogayo and Swetha R. Gangu and David R. Mortensen and Shinji Watanabe},
  booktitle=interspeech,
  year={2022},
}

@inproceedings{yooncheol_interspeech2022,
  abbr={TTS},
  abbr_publisher={Interspeech},
  title={TriniTTS: Pitch-controllable End-to-end TTS without External Aligner},
  author={Yooncheol Ju and Ilhwan Kim and Hongsun Yang and Ji-Hoon Kim and Byeongyeol Kim and Soumi Maiti and Shinji Watanabe},
  booktitle=interspeech,
  year={2022},
}

@inproceedings{muqiao_interspeech2022,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Online Continual Learning of End-to-End Speech Recognition Models},
  author={Muqiao Yang and Ian Lane and Shinji Watanabe},
  booktitle=interspeech,
  year={2022},
}

@inproceedings{muqiao_interspeech2022,
  abbr={SE},
  abbr_publisher={Interspeech},
  title={Improving Speech Enhancement through Fine-Grained Speech Characteristics},
  author={Muqiao Yang and Joseph Konan and David Bick and Anurag Kumar and Shinji Watanabe and Bhiksha Raj},
  booktitle=interspeech,
  year={2022},
}

@inproceedings{xuankai_interspeech2022,
  abbr={ASR&SE&SSL},
  abbr_publisher={Interspeech},
  title={End-to-End Integration of Speech Recognition, Speech Enhancement, and Self-Supervised Learning Representation},
  author={Xuankai Chang and Takashi Maekaku and Yuya Fujita and Shinji Watanabe},
  booktitle=interspeech,
  year={2022},
}

@inproceedings{dan_interspeech2022,
  abbr={ASR&SSL},
  abbr_publisher={Interspeech},
  title={Combining Spectral and Self-Supervised Features for Low Resource Speech Recognition and Translation},
  author={Dan Berrebbi and Jiatong Shi and Brian Yan and Osbel López-Francisco and Jonathan Amith and Shinji Watanabe},
  booktitle=interspeech,
  year={2022},
}

@inproceedings{peng2022icml,
  abbr={ASR&SLU&MT},
  abbr_publisher={ICML},
  title={Branchformer: Parallel MLP-Attention Architectures to Capture Local and Global Context for Speech Recognition and Understanding},
  author={Peng, Yifan and Dalmia, Siddharth and Lane, Ian and Watanabe, Shinji},
  booktitle=ICML,
  year={2022},
}

@inproceedings{li2022aclfindings,
  abbr={Linguistic},
  abbr_publisher={ACL},
  title={Zero-shot Learning for Grapheme to Phoneme Conversion with Language Ensemble},
  author={Xinjian Li and Florian Metze and David R Mortensen and Shinji Watanabe and Alan Black},
  booktitle=ACLFindings,
  year={2022}
}

@inproceedings{tsai2022acl,
  abbr={SE&VC&ST},
  abbr_publisher={ACL},
  title={SUPERB-SG: Enhanced Speech processing Universal PERformance Benchmark for Semantic and Generative Capabilities},
  author={Hsiang-Sheng Tsai and Heng-Jui Chang and Wen-Chin Huang and Zili Huang and Kushal Lakhotia and  Shu-wen Yang and  Shuyan Dong and  Andy T. Liu and  Cheng-I Lai and  Jiatong Shi and  Xuankai Chang and  Phil Hall and  Hsuan-Jui Chen and  Shang-Wen Li and  Shinji Watanabe and  Abdelrahman Mohamed and Hung-yi Lee},
  booktitle=ACL,
  year={2022}
}

@article{subramanian2022deep,
  abbr={SE&ASR},
  abbr_publisher={CSL},
  title={Deep learning based multi-source localization with source splitting and its effectiveness in multi-talker speech recognition},
  author={Subramanian, Aswin Shanmugam and Weng, Chao and Watanabe, Shinji and Yu, Meng and Yu, Dong},
  journal={Computer Speech \& Language},
  volume={75},
  pages={101360},
  year={2022},
  publisher={Elsevier}
}

@article{park2022review,
  abbr={SD},
  abbr_publisher={CSL},
  title={A review of speaker diarization: Recent advances with deep learning},
  author={Park, Tae Jin and Kanda, Naoyuki and Dimitriadis, Dimitrios and Han, Kyu J and Watanabe, Shinji and Narayanan, Shrikanth},
  journal={Computer Speech \& Language},
  volume={72},
  pages={101317},
  year={2022},
  publisher={Elsevier},
  selected={true},
}

@article{huang2022joint,
  abbr={SE&ASR},
  abbr_publisher={CSL},
  title={Joint speaker diarization and speech recognition based on region proposal networks},
  author={Huang, Zili and Delcroix, Marc and Garcia, Leibny Paola and Watanabe, Shinji and Raj, Desh and Khudanpur, Sanjeev},
  journal={Computer Speech \& Language},
  volume={72},
  pages={101316},
  year={2022},
  publisher={Elsevier}
}

@article{hussein2022arabic,
  abbr={ASR},
  abbr_publisher={CSL},
  title={Arabic speech recognition by end-to-end, modular systems and human},
  author={Hussein, Amir and Watanabe, Shinji and Ali, Ahmed},
  journal={Computer Speech \& Language},
  volume={71},
  pages={101272},
  year={2022},
  publisher={Elsevier}
}


@inproceedings{lu2022icassp,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={TOWARDS LOW-DISTORTION MULTI-CHANNEL SPEECH ENHANCEMENT: THE ESPNET-SE SUBMISSION TO THE L3DAS22 CHALLENGE},
  author={Jen-Ju Lu and Samuele Cornell and Xuankai Chang and Wangyou Zhang and Chenda Li and Zhaoheng Ni and Zhong-Qiu Wang and Shinji Watanabe},
  booktitle=ICASSP,
  year={2022}
}

@inproceedings{lu2022icassp,
  abbr={Multimodal},
  abbr_publisher={ICASSP},
  title={THE FIRST MULTIMODAL INFORMATION BASED SPEECH PROCESSING (MISP) CHALLENGE: DATA, TASKS, BASELINES AND RESULTS},
  author={Hang Chen and Hengshun Zhou and Jun Du and Chin-Hui Lee and Jingdong Chen and Shinji Watanabe and Sabato Marco Siniscalchi and Odette Scharenborg and Di-Yuan Liu and Bao-Cai Yin and Jia Pan and Jian-Qing Gao and Cong Liu},
  booktitle=ICASSP,
  year={2022}
}

@inproceedings{motoi2022icassp,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={NON-AUTOREGRESSIVE END-TO-END AUTOMATIC SPEECH RECOGNITION INCORPORATING DOWNSTREAM NATURAL LANGUAGE PROCESSING},
  author={Motoi Omachi and Yuya Fujita and Shinji Watanabe and Tianzi Wang},
  booktitle=ICASSP,
  year={2022}
}

@inproceedings{takeshi2022icassp,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={AN EXPLORATION OF HUBERT WITH LARGE NUMBER OF CLUSTER UNITS AND MODEL ASSESSMENT USING BAYESIAN INFORMATION CRITERION},
  author={Takashi Maekaku and Xuankai Chang and Yuya Fujita and Shinji Watanabe},
  booktitle=ICASSP,
  year={2022}
}

@inproceedings{zili2022icassp,
  abbr={SE&SSL},
  abbr_publisher={ICASSP},
  title={INVESTIGATING SELF-SUPERVISED LEARNING FOR SPEECH ENHANCEMENT AND SEPARATION},
  author={Zili Huang and Shinji Watanabe and Shu-wen Yang and Paola Garcia and Sanjeev Khudanpur},
  booktitle=ICASSP,
  year={2022}
}

@inproceedings{yenju2022icassp,
  abbr={SE},
  abbr_publisher={ICASSP},
  title={CONDITIONAL DIFFUSION PROBABILISTIC MODEL FOR SPEECH ENHANCEMENT},
  author={Yen-Ju Lu and Zhong-Qiu Wang and Shinji Watanabe and Alexander Richard and Cheng Yu and Yu Tsao},
  booktitle=ICASSP,
  year={2022}
}

@inproceedings{keqi2022icassp,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={IMPROVING NON-AUTOREGRESSIVE END-TO-END SPEECH RECOGNITION WITH PRE-TRAINED ACOUSTIC AND LANGUAGE MODELS},
  author={Keqi Deng and Zehui Yang and Shinji Watanabe and Yosuke Higuchi and Gaofeng Cheng and Pengyuan Zhang},
  booktitle=ICASSP,
  year={2022}
}

@inproceedings{jingpan2022icassp,
  abbr={ASR},
  abbr_publisher={ICASSP},
  author={Jing Pan and Tao Lei and Kwangyoun Kim and Kyu Han and Shinji Watanabe},
  title={SRU++: PIONEERING FAST RECURRENCE WITH ATTENTION FOR SPEECH RECOGNITION},
  booktitle=ICASSP,
  year={2022}
}

@inproceedings{taketomo2022icassp,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Integrating multiple ASR systems into NLP backend with attention fusion},
  author={Takatomo Kano and Atsunori Ogawa and Marc Delcroix and Shinji Watanabe},
  booktitle=ICASSP,
  year={2022}
}

@inproceedings{siddhant2022icassp,
  abbr={SLU},
  abbr_publisher={ICASSP},
  title={ESPNET-SLU: ADVANCING SPOKEN LANGUAGE UNDERSTANDING THROUGH ESPNET},
  author={Siddhant Arora and Siddharth Dalmia and Pavel Denisov and Xuankai Chang and Yushi Ueda and Yifan Peng and Yuekai Zhang and Sujay Kumar and Karthik Ganesan and Brian Yan and Ngoc Thang Vu and Alan W Black and Shinji Watanabe},
  booktitle=ICASSP,
  year={2022}
}

@inproceedings{brian2022icassp,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={JOINT MODELING OF CODE-SWITCHED AND MONOLINGUAL ASR VIA CONDITIONAL FACTORIZATION},
  author={Brian Yan and Chunlei Zhang and Meng Yu and Shi-Xiong Zhang and Siddharth Dalmia and Dan Berrebbi and Chao Weng and Shinji Watanabe and Dong Yu},
  booktitle=ICASSP,
  year={2022}
}

@inproceedings{xuankai2022icassp,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={EXTENDED GRAPH TEMPORAL CLASSIFICATION FOR MULTI-SPEAKER END-TO-END ASR},
  author={Xuankai Chang and Niko Moritz and Takaaki Hori and Shinji Watanabe and Jonathan Le Roux},
  booktitle=ICASSP,
  year={2022}
}

@inproceedings{niko2022icassp,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Sequence Transduction with Graph-based Supervision},
  author={Niko Moritz and Takaaki Hori and Shinji Watanabe and Jonathan Le Roux},
  booktitle=ICASSP,
  year={2022}
}

@inproceedings{emiru2022icassp,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={RUN-AND-BACK STITCH SEARCH: NOVEL BLOCK SYNCHRONOUS DECODING FOR STREAMING ENCODER-DECODER ASR},
  author={Emiru Tsunoo and Chaitanya Narisetty and Michael Hentschel and Yosuke Kashiwagi and Shinji Watanabe},
  booktitle=ICASSP,
  year={2022}
}

@inproceedings{whenchin2022icassp,
  abbr={VC&SSL},
  abbr_publisher={ICASSP},
  title={S3PRL-VC: OPEN-SOURCE VOICE CONVERSION FRAMEWORK WITH SELF-SUPERVISED SPEECH REPRESENTATIONS},
  author={Wen-Chin Huang and Shu-wen Yang and Tomoki Hayashi and Hung-yi Lee and Shinji Watanabe and Tomoki Toda},
  booktitle=ICASSP,
  year={2022}
}


@inproceedings{chaitanya2022icassp,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={JOINT SPEECH RECOGNITION AND AUDIO CAPTIONING},
  author={Chaitanya Narisetty and Emiru Tsunoo and Xuankai Chang and Yosuke Kashiwagi and Michael Hentschel and Shinji Watanabe},
  booktitle=ICASSP,
  year={2022}
}

@inproceedings{shota2022icassp,
  abbr={SD},
  abbr_publisher={ICASSP},
  title={MULTI-CHANNEL END-TO-END NEURAL DIARIZATION WITH DISTRIBUTED MICROPHONES},
  author={Shota Horiguchi and Yuki Takashima and Paola Garcia and Shinji Watanabe and Yohei Kawaguchi},
  booktitle=ICASSP,
  year={2022}
}

@inproceedings{yaoyuan2022icassp,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={TORCHAUDIO: BUILDING BLOCKS FOR AUDIO AND SPEECH PROCESSING},
  author={Yao-Yuan Yang and Moto Hira and Zhaoheng Ni and Artyom Astafurov and Caroline Chen and Christian Puhrsch and David Pollack and Dmitriy Genzel and Donny Greenberg and Edward Yang and Jason Lian and Jeff Hwang and Ji Chen and Peter Goldsborough and Sean Narenthiran and Shinji Watanabe and Soumith Chintala and Vincent Quenneville-Bélair},
  booktitle=ICASSP,
  year={2022}
}

@inproceedings{chunlei2022icassp,
  abbr={SD},
  abbr_publisher={ICASSP},
  title={Towards End-to-End Speaker Diarization with Generalized Neural Speaker Clustering},
  author={Chunlei Zhang and Jiatong Shi and Chao Weng and Meng Yu and Dong Yu},
  booktitle=ICASSP,
  year={2022}
}


@inproceedings{tao2022icassp,
  abbr={Music},
  abbr_publisher={ICASSP},
  title={TRAINING STRATEGIES FOR AUTOMATIC SONG WRITING: A UNIFIED FRAMEWORK PERSPECTIVE},
  author={Tao Qian and Jiatong Shi and Shuai Guo and Peter Wu and Qin Jin},
  booktitle=ICASSP,
  year={2022}
}


@article{SHI2022101327,
  abbr={SE+ASR},
  abbr_publisher={CSL},
  title = {An investigation of neural uncertainty estimation for target speaker extraction equipped RNN transducer},
  journal = {Computer Speech & Language},
  volume = {73},
  pages = {101327},
  year = {2022},
  issn = {0885-2308},
  doi = {https://doi.org/10.1016/j.csl.2021.101327},
  url = {https://www.sciencedirect.com/science/article/pii/S0885230821001200},
  author = {Jiatong Shi and Chunlei Zhang and Chao Weng and Shinji Watanabe and Meng Yu and Dong Yu},
  keywords = {Target-speaker speech recognition, Target-speaker speech extraction, Uncertainty estimation},
  abstract = {Target-speaker speech recognition aims to recognize the speech of an enrolled speaker from an environment with background noise and interfering speakers. This study presents a joint framework that combines time-domain target speaker extraction and recurrent neural network transducer (RNN-T) for speech recognition. To alleviate the adverse effects of residual noise and artifacts introduced by the target speaker extraction module to the speech recognition back-end, we explore to training the target speaker extraction and RNN-T jointly. We find a multi-stage training strategy that pre-trains and fine-tunes each module before joint training is crucial in stabilizing the training process. In addition, we propose a novel neural uncertainty estimation that leverages useful information from the target speaker extraction module to further improve the back-end speech recognizer (i.e., speaker identity uncertainty and speech enhancement uncertainty). Compared to a recognizer with target speech extraction front-end, our experiments show that joint-training and the neural uncertainty module reduce 7% and 17% relative character error rate (CER) on multi-talker simulation data, respectively. The multi-condition experiments indicate that our method can reduce 9% relative CER in the noisy condition without losing performance in the clean condition. We also observe consistent improvements in further evaluation of real-world data based on vehicular speech.}
}

@inproceedings{huang_asru2021,
  abbr={ASR+TTS},
  abbr_publisher={ASRU},
  title={On Prosody Modeling for ASR+TTS based Voice Conversion},
  author={Wen-Chin Huang and Tomoki Hayashi and Xinjian Li and Shinji Watanabe and Tomoki Toda},
  booktitle=ASRU,
  year={2021}
}

@inproceedings{kano_asru2021,
  abbr={SLU},
  abbr_publisher={ASRU},
  title={Attention-based Multi-hypothesis Fusion for Speech Summarization},
  author={Takatomo Kano and Atsunori Ogawa and Marc Delcroix and Shinji Watanabe},
  booktitle=ASRU,
  year={2021}
}

@inproceedings{inaguma_asru2021,
  abbr={ST},
  abbr_publisher={ASRU},
  title={Fast-MD: Fast Multi-Decoder End-to-End Speech Translation with Non-Autoregressive Hidden Intermediates},
  author={Hirofumi Inaguma and Siddharth Dalmia and Brian Yan and Shinji Watanabe},
  booktitle=ASRU,
  year={2021}
}

@inproceedings{horiguchi_asru2021,
  abbr={SD},
  abbr_publisher={ASRU},
  title={Towards Neural Diarization for Unlimited Numbers of Speakers using Global and Local Attractors},
  author={Shota Horiguchi and Shinji Watanabe and Paola Garcia and Yawen Xue and Yuki Takashima and Yohei Kawaguchi},
  booktitle=ASRU,
  year={2021}
}

@inproceedings{boyer_asru2021,
  abbr={ASR},
  abbr_publisher={ASRU},
  title={A Study of Transducer based End-to-end ASR with ESPNet: Architecture, Auxiliary Loss and Decoding Strategies},
  author={Florian Boyer and Yusuke Shinohara and Takaaki Ishii and Hirofumi Inaguma and Shinji Watanabe},
  booktitle=ASRU,
  year={2021}
}

@inproceedings{higuchi_asru2021,
  abbr={ASR},
  abbr_publisher={ASRU},
  title={A Comparative Study on Non-autoregressive Modelings for Speech-to-text Generation},
  author={Yosuke Higuchi and Nanxin Chen and Yuya Fujita and Hirofumi Inaguma and Tatsuya Komatsu and Jaesong Lee and Jumon Nozaki and Tianzi Wang and Shinji Watanabe},
  booktitle=ASRU,
  year={2021}
}

@inproceedings{rao_asru2021,
  abbr={SE},
  abbr_publisher={ASRU},
  title={ConferencingSpeech Challenge: Towards Far-field Multi-channel Speech Enhancement for Video Conferencing},
  author={Wei Rao and Yihui Fu and Yanxin Hu and Xin Xu and Yvkai Jv and Jiangyu Han and Zhongjie Jiang and Lei Xie and Yannan Wang and Shinji Watanabe and Zheng-Hua Tan and Hui Bu and Tao Yu and Shidong Shang},
  booktitle=ASRU,
  year={2021}
}

@inproceedings{wu_asru2021,
  abbr={ASR+TTS},
  abbr_publisher={ASRU},
  title={Cross-lingual Transfer for Speech Processing using Acoustic Language Similarity},
  author={Peter Wu and Jiatong Shi and Yifan Zhong and Shinji Watanabe and Alan Black},
  booktitle=ASRU,
  year={2021}
}

@inproceedings{chang_asru2021,
  abbr={ASR&SSL},
  abbr_publisher={ASRU},
  title={An Exploration of Self-supervised Pretrained Representations for End-to-end Speech Recognition},
  author={Xuankai Chang and Takashi Maekaku and Pengcheng Guo and Jing Shi and Yen-Ju Lu and Aswin Shanmugam Subramanian and Tianzi Wang and Shu-wen Yang and Yu Tsao and Hung-yi Lee and Shinji Watanabe},
  booktitle=ASRU,
  year={2021}
}

@inproceedings{wu_apsipa2021,
  abbr={VC},
  abbr_publisher={APSIPA},
  title={Understanding the Tradeoffs in Client-side Privacy for Downstream Speech Tasks},
  author={Peter Wu and Paul Pu Liang and Jiatong Shi and Ruslan Salakhutdinov and Shinji Watanabe and Louis-Philippe Morency},
  booktitle=APSIPA,
  year={2021}
}

@inproceedings{inaguma2021iwslt,
  abbr={ST},
  abbr_publisher={IWSLT},
  title={{ESP}net-{ST} {IWSLT} 2021 Offline Speech Translation System},
  author={Inaguma, Hirofumi and Yan, Brian and Dalmia, Siddharth and Guo, Pengcheng and Shi, Jiatong and Duh, Kevin and Watanabe, Shinji},
  booktitle=IWSLT,
  pages={100--109},
  year={2021}
}

@inproceedings{chen2021giga,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={GigaSpeech: An Evolving, Multi-domain ASR Corpus with 10,000 Hours of Transcribed Audio},
  author={Chen, Guoguo and Chai, Shuzhou and Wang, Guanbo and Du, Jiayu and Zhang, Wei-Qiang and Weng, Chao and Su, Dan and Povey, Daniel and Trmal, Jan and Zhang, Junbo and Jin, Mingjie and Khudanpur, Sanjeev and Watanabe, Shinji and Zhao, Shuaijiang and Zou, Wei and Li, Xiangang and Yao, Xuchen and Wang, Yongqing and You, Zhao and Yan, Zhiyong},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{komatsu2021chains,
  abbr={AED},
  abbr_publisher={Interspeech},
  title={Acoustic Event Detection with Classifier Chains},
  author={Komatsu, Tatsuya and Watanabe, Shinji and Miyazaki, Koichi and Hayashi, Tomoki},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{guo2021combine,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Multi-Speaker ASR Combining Non-Autoregressive Conformer CTC and Conditional Speaker Chain},
  author={Guo, Pengcheng and Chang, Xuankai and Watanabe, Shinji and Xie, Lei},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{kim2021transducer,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Multi-mode Transformer Transducer with Stochastic Future Context},
  author={Kim, Kwangyoun and Wu, Felix and Sridhar, Prashant and Han, Kyu and Watanabe, Shinji},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{yan2021allophone,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Differentiable Allophone Graphs for Language Universal Speech Recognition},
  author={Yan, Brian and Dalmia, Siddharth and Mortensen, David R. and Metze, Florian and Watanabe, Shinji},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{maciejewski2021verification,
  abbr={SE},
  abbr_publisher={Interspeech},
  title={Speaker Verification-Based Evaluation of Single-Channel Speech Separation},
  author={Maciejewski, Matthew and Watanabe, Shinji and Khudanpur, Sanjeev},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{neill2021financial,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={SPGISpeech: 5,000 hours of transcribed financial audio for fully formatted end-to-end speech recognition},
  author={O'Neill, Patrick and Lavrukhin, Vitaly and Majumdar, Somshubra and Noroozi, Vahid and Zhang, Yuekai and Kuchaiev, Oleksii and Balam, Jagadeesh and Dovzhenko, Yuliya and Freyberg, Keenan and Shulman, Michael and Ginsburg, Boris and Watanabe, Shinji and Kucsko, Georg},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{yang2021superb,
  abbr={ASR&SD&SLU&ER},
  abbr_publisher={Interspeech},
  title={SUPERB: Speech processing Universal PERformance Benchmark},
  author={Yang, Shu-wen and Chi, Po-Han and Chuang, Yung-Sung and Lai, Cheng-I and Lakhotia, Kushal and Y., Yist and T., Andy and Shi, Jiatong and Chang, Xuankai and Lin, Guan-Ting and Huang, Tzu-Hsien and Tseng, Wei-Cheng and Lee, Ko-tik and Liu, Da-Rong and Huang, Zili and Dong, Shuyan and Li, Shang-Wen and Watanabe, Shinji and Mohamed, Abdelrahman and Lee, Hung-yi},
  booktitle=interspeech,
  year={2021},
  arxiv={2105.01051},
  selected={true},
  pdf={https://arxiv.org/pdf/2105.01051.pdf},
  html={https://www.isca-speech.org/archive/interspeech_2021/yang21c_interspeech.html},
}

@inproceedings{shon2021sentiment,
  abbr={SSA},
  abbr_publisher={Interspeech},
  title={Leveraging Pre-trained Language Model for Speech Sentiment Analysis},
  author={Shon, Suwon and Brusco, Pablo and Pan, Jing and Han, Kyu and Watanabe, Shinji},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{wong2021E2EASR,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Streaming End-to-End ASR based on Blockwise Non-Autoregressive Models},
  author={Wang, Tianzi and Fujita, Yuya and Chang, Xuankai and Watanabe, Shinji},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{arora2021SLU,
  abbr={SLU},
  abbr_publisher={Interspeech},
  title={Rethinking End-to-End Evaluation of Decomposable Tasks: A Case Study on Spoken Language Understanding},
  author={Arora, Siddhant and Ostapenko, Alissa and Viswanathan, Vijay and Dalmia, Siddharth and Metze, Florian and Watanabe, Shinji and Black, Alan W.},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{meekaku2021ZeroSpeech,
  abbr={ASR & SpeDialog},
  abbr_publisher={Interspeech},
  title={Speech Representation Learning Combining Conformer CPC with Deep Cluster for the ZeroSpeech Challenge 2021},
  author={Maekaku, Takashi and Chang, Xuankai and Fujita, Yuya and Chen, Li-Wei and Watanabe, Shinji and Rudnicky, Alexander},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{lee2021CTC,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Layer Pruning on Demand with Intermediate CTC},
  author={Lee, Jaesong and Kang, Jingu and Watanabe, Shinji},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{fujita2021insertion,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Toward Streaming ASR with Non-autoregressive Insertion-based Model},
  author={Fujita, Yuya and Wang, Tianzi and Watanabe, Shinji and Omachi, Motoi},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{zmolikova2021weaksupervision,
  abbr={SE&ASR},
  abbr_publisher={Interspeech},
  title={Auxiliary loss function for target speech extraction and recognition with weak supervision based on speaker characteristics},
  author={Zmolikova, Katerina and Delcroix, Marc and Raj, Desh and Watanabe, Shinji and Honza Černocký, Jan},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{tsunoo2021DataAug,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Data Augmentation Methods for End-to-end Speech Recognition on Distant-talk Scenarios},
  author={Tsunoo, Emiru and Shibata, Kentaro and Narisetty, Chaitanya and Kashiwagi, Yosuke and Watanabe, Shinji},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{he2021TSVAD,
  abbr={SD},
  abbr_publisher={Interspeech},
  title={Target-Speaker Voice Activity Detection with Improved I-Vector Estimation for Unknown Number of Speaker},
  author={He, Mao-Kui and Raj, Desh and Huang, Zili and Du, Jun and Chen, Zhuo and Watanabe, Shinji},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{watanabe2021espnet,
  abbr={SE&ASR&ST},
  abbr_publisher={DSLW},
  title={The 2020 ESPnet update: new features, broadened applications, performance improvements, and future plans},
  author={Shinji Watanabe and Florian Boyer and Xuankai Chang and Pengcheng Guo and Tomoki Hayashi and Yosuke Higuchi and Takaaki Hori and Wen-Chin Huang and Hirofumi Inaguma and Naoyuki Kamo and Shigeki Karita and Chenda Li and Jing Shi and Aswin Shanmugam Subramanian and Wangyou Zhang},
  booktitle={Proceedings of 2021 IEEE Data Science and Learning Workshop},
  year={2021},
  organization={IEEE}
}

@inproceedings{li2021dual,
  abbr={SE},
  abbr_publisher={SLT},
  title={Dual-path RNN for long recording speech separation},
  author={Li, Chenda and Luo, Yi and Han, Cong and Li, Jinyu and Yoshioka, Takuya and Zhou, Tianyan and Delcroix, Marc and Kinoshita, Keisuke and Boeddeker, Christoph and Qian, Yanmin and Watanabe, Shinji and Chen, Zhuo},
  booktitle=SLT,
  pages={865--872},
  year={2021},
  organization={IEEE}
}

@inproceedings{takashima2021end,
  abbr={SD},
  abbr_publisher={SLT},
  title={End-to-End Speaker Diarization Conditioned on Speech Activity and Overlap Detection},
  author={Takashima, Yuki and Fujita, Yusuke and Watanabe, Shinji and Horiguchi, Shota and Garc{\'\i}a, Paola and Nagamatsu, Kenji},
  booktitle=SLT,
  pages={849--856},
  year={2021},
  organization={IEEE}
}

@inproceedings{tsunoo2021streaming,
  abbr={ASR},
  abbr_publisher={SLT},
  title={Streaming Transformer ASR with blockwise synchronous beam search},
  author={Tsunoo, Emiru and Kashiwagi, Yosuke and Watanabe, Shinji},
  booktitle=SLT,
  pages={22--29},
  year={2021},
  organization={IEEE}
}

@inproceedings{wang2021sequential,
  abbr={SE},
  abbr_publisher={SLT},
  title={Sequential multi-frame neural beamforming for speech separation and enhancement},
  author={Wang, Zhong-Qiu and Erdogan, Hakan and Wisdom, Scott and Wilson, Kevin and Raj, Desh and Watanabe, Shinji and Chen, Zhuo and Hershey, John R},
  booktitle=SLT,
  pages={905--911},
  year={2021},
  organization={IEEE}
}

@inproceedings{raj2021dover,
  abbr={SD},
  abbr_publisher={SLT},
  title={DOVER-Lap: A Method for Combining Overlap-aware Diarization Outputs},
  author={Raj, Desh and Garcia-Perera, Leibny Paola and Huang, Zili and Watanabe, Shinji and Povey, Daniel and Stolcke, Andreas and Khudanpur, Sanjeev},
  booktitle=SLT,
  pages={881--888},
  year={2021},
  organization={IEEE}
}

@inproceedings{raj2021integration,
  abbr={SE&SE&ASR},
  abbr_publisher={SLT},
  title={Integration of speech separation, diarization, and recognition for multi-speaker meetings: System description, comparison, and analysis},
  author={Raj, Desh and Denisov, Pavel and Chen, Zhuo and Erdogan, Hakan and Huang, Zili and He, Maokui and Watanabe, Shinji and Du, Jun and Yoshioka, Takuya and Luo, Yi and others},
  booktitle=SLT,
  pages={897--904},
  year={2021},
  organization={IEEE}
}

@inproceedings{xue2021online,
  abbr={SD},
  abbr_publisher={SLT},
  title={Online end-to-end neural diarization with speaker-tracing buffer},
  author={Xue, Yawen and Horiguchi, Shota and Fujita, Yusuke and Watanabe, Shinji and Garc{\'\i}a, Paola and Nagamatsu, Kenji},
  booktitle=SLT,
  pages={841--848},
  year={2021},
  organization={IEEE}
}

@inproceedings{shi2021highland,
  abbr={ST},
  abbr_publisher={AmericasNLP},
  title={Highland Puebla Nahuatl Speech Translation Corpus for Endangered Language Documentation},
  author={Shi, Jiatong and Amith, Jonathan D and Chang, Xuankai and Dalmia, Siddharth and Yan, Brian and Watanabe, Shinji},
  booktitle={Proceedings of the First Workshop on Natural Language Processing for Indigenous Languages of the Americas},
  pages={53--63},
  year={2021}
}

@inproceedings{amith2021end,
  abbr={ASR},
  abbr_publisher={AmericasNLP},
  title={End-to-End Automatic Speech Recognition: Its Impact on the Workflowin Documenting Yolox{\'o}chitl Mixtec},
  author={Amith, Jonathan D and Shi, Jiatong and Garc{\'\i}a, Rey Castillo},
  booktitle={Proceedings of the First Workshop on Natural Language Processing for Indigenous Languages of the Americas},
  pages={64--80},
  year={2021}
}

@inproceedings{omachi2021end,
  abbr={ASR},
  abbr_publisher={NAACL},
  title={End-to-end ASR to jointly predict transcriptions and linguistic annotations},
  author={Omachi, Motoi and Fujita, Yuya and Watanabe, Shinji and Wiesner, Matthew},
  booktitle=NAACL,
  pages={1861--1871},
  year={2021}
}

@inproceedings{dalmia2021searchable,
  abbr={ST},
  abbr_publisher={NAACL},
  title={Searchable Hidden Intermediates for End-to-End Models of Decomposable Sequence Tasks},
  author={Dalmia, Siddharth and Yan, Brian and Raunak, Vikas and Metze, Florian and Watanabe, Shinji},
  booktitle=NAACL,
  pages={1882--1896},
  year={2021}
}

@inproceedings{inaguma2021source,
  abbr={ST},
  abbr_publisher={NAACL},
  title={Source and Target Bidirectional Knowledge Distillation for End-to-end Speech Translation},
  author={Inaguma, Hirofumi and Kawahara, Tatsuya and Watanabe, Shinji},
  booktitle=NAACL,
  pages={1872--1881},
  year={2021}
}

@inproceedings{shi2021leveraging,
  abbr={ASR},
  abbr_publisher={EACL},
  title={Leveraging End-to-End ASR for Endangered Language Documentation: An Empirical Study on Yol{\'o}xochitl Mixtec},
  author={Shi, Jiatong and Amith, Jonathan D and Garc{\'\i}a, Rey Castillo and Sierra, Esteban Guadalupe and Duh, Kevin and Watanabe, Shinji},
  booktitle=EACL,
  pages={1134--1145},
  year={2021}
}


@inproceedings{xue2021Online,
  abbr={SD},
  abbr_publisher={Interspeech},
  title={Online Streaming End-to-End Neural Diarization Handling Overlapping Speech and Flexible Numbers of Speakers},
  author={Xue, Yawen and Horiguchi, Shota and Fujita, Yusuke and Takashima, Yuki and Watanabe, Shinji and Paola Garcia Perera, Leibny and Namagatsu, Kenji},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{takashima2021SemiSup,
  abbr={SD},
  abbr_publisher={Interspeech},
  title={Semi-Supervised Training with Pseudo-Labeling for End-to-End Neural Diarization},
  author={Takashima, Yuki and Fujita, Yusuke and Horiguchi, Shota and Watanabe, Shinji and Paola, Leibny and Nagamatsu, Kenji},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{han2021Cont,
  abbr={SE},
  abbr_publisher={Interspeech},
  title={Continuous speech separation using speaker inventory for long recording},
  author={Han, Cong and Luo, Yi and Li, Chenda and Zhou, Tianyan and Kinoshita, Keisuke and Watanabe, Shinji and Delcroix, Marc and Erdogan, Hakan and Hershey, John and Mesgarani, Nima and Chen, Zhuo},
  booktitle=interspeech,
  year={2021}
}

@inproceedings{maiti2021end,
  abbr={SD},
  abbr_publisher={ICASSP},
  title={End-To-End Diarization for Variable Number of Speakers with Local-Global Networks and Discriminative Speaker Embeddings},
  author={Maiti, Soumi and Erdogan, Hakan and Wilson, Kevin and Wisdom, Scott and Watanabe, Shinji and Hershey, John R},
  booktitle=ICASSP,
  pages={7183--7187},
  year={2021},
  organization={IEEE}
}

@inproceedings{li2021dual,
  abbr={SE},
  abbr_publisher={ICASSP},
  title={Dual-Path Modeling for Long Recording Speech Separation in Meetings},
  author={Li, Chenda and Chen, Zhuo and Luo, Yi and Han, Cong and Zhou, Tianyan and Kinoshita, Keisuke and Delcroix, Marc and Watanabe, Shinji and Qian, Yanmin},
  booktitle=ICASSP,
  year={2021},
  organization={IEEE}
}

@inproceedings{guo2021recent,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Recent developments on espnet toolkit boosted by conformer},
  author={Guo, Pengcheng and Boyer, Florian and Chang, Xuankai and Hayashi, Tomoki and Higuchi, Yosuke and Inaguma, Hirofumi and Kamo, Naoyuki and Li, Chenda and Garcia-Romero, Daniel and Shi, Jiatong and others},
  booktitle=ICASSP,
  pages={5874--5878},
  year={2021},
  organization={IEEE}
}

@inproceedings{zhang2021end,
  abbr={SE&ASR},
  abbr_publisher={ICASSP},
  title={End-to-end dereverberation, beamforming, and speech recognition with improved numerical stability and advanced frontend},
  author={Zhang, Wangyou and Boeddeker, Christoph and Watanabe, Shinji and Nakatani, Tomohiro and Delcroix, Marc and Kinoshita, Keisuke and Ochiai, Tsubasa and Kamo, Naoyuki and Haeb-Umbach, Reinhold and Qian, Yanmin},
  booktitle=ICASSP,
  pages={6898--6902},
  year={2021},
  organization={IEEE}
}

@inproceedings{horiguchi2021end,
  abbr={SD},
  abbr_publisher={ICASSP},
  title={End-to-end speaker diarization as post-processing},
  author={Horiguchi, Shota and Garc{\'\i}a, Paola and Fujita, Yusuke and Watanabe, Shinji and Nagamatsu, Kenji},
  booktitle=ICASSP,
  pages={7188--7192},
  year={2021},
  organization={IEEE}
}

@inproceedings{higuchi2021improved,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Improved Mask-CTC for Non-Autoregressive End-to-End ASR},
  author={Higuchi, Yosuke and Inaguma, Hirofumi and Watanabe, Shinji and Ogawa, Tetsuji and Kobayashi, Tetsunori},
  booktitle=ICASSP,
  pages={8363--8367},
  year={2021},
  organization={IEEE}
}

@inproceedings{lee2021intermediate,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Intermediate Loss Regularization for CTC-Based Speech Recognition},
  author={Lee, Jaesong and Watanabe, Shinji},
  booktitle=ICASSP,
  pages={6224--6228},
  year={2021},
  organization={IEEE}
}

@inproceedings{inaguma2021orthros,
  abbr={ST},
  abbr_publisher={ICASSP},
  title={Orthros: Non-autoregressive end-to-end speech translation with dual-decoder},
  author={Inaguma, Hirofumi and Higuchi, Yosuke and Duh, Kevin and Kawahara, Tatsuya and Watanabe, Shinji},
  booktitle=ICASSP,
  pages={7503--7507},
  year={2021},
  organization={IEEE}
}

@inproceedings{subramanian2021directional,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Directional ASR: A new paradigm for E2E multi-speaker speech recognition with source localization},
  author={Subramanian, Aswin Shanmugam and Weng, Chao and Watanabe, Shinji and Yu, Meng and Xu, Yong and Zhang, Shi-Xiong and Yu, Dong},
  booktitle=ICASSP,
  pages={8433--8437},
  year={2021},
  organization={IEEE}
}

@inproceedings{baskar2021eat,
  abbr={ASR&TTS&SSL},
  abbr_publisher={ICASSP},
  title={Eat: Enhanced ASR-TTS for Self-Supervised Speech Recognition},
  author={Baskar, Murali Karthick and Burget, Luk{\'a}{\v{s}} and Watanabe, Shinji and Astudillo, Ramon Fernandez and others},
  booktitle=ICASSP,
  pages={6753--6757},
  year={2021},
  organization={IEEE}
}

@inproceedings{kashiwagi2021gaussian,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Gaussian Kernelized Self-Attention for Long Sequence Data and its Application to CTC-Based Speech Recognition},
  author={Kashiwagi, Yosuke and Tsunoo, Emiru and Watanabe, Shinji},
  booktitle=ICASSP,
  pages={6214--6218},
  year={2021},
  organization={IEEE}
}

@inproceedings{shi2021improving,
  abbr={SE&ASR},
  abbr_publisher={ICASSP},
  title={Improving RNN Transducer with Target Speaker Extraction and Neural Uncertainty Estimation},
  author={Shi, Jiatong and Zhang, Chunlei and Weng, Chao and Watanabe, Shinji and Yu, Meng and Yu, Dong},
  booktitle=ICASSP,
  pages={6908--6912},
  year={2021},
  organization={IEEE}
}

@inproceedings{maciejewski2021training,
  abbr={SE},
  abbr_publisher={ICASSP},
  title={Training Noisy Single-Channel Speech Separation with Noisy Oracle Sources: A Large Gap and a Small Step},
  author={Maciejewski, Matthew and Shi, Jing and Watanabe, Shinji and Khudanpur, Sanjeev},
  booktitle=ICASSP,
  pages={5774--5778},
  year={2021},
  organization={IEEE}
}

@inproceedings{shi2021sequence,
  abbr={Music},
  abbr_publisher={ICASSP},
  title={Sequence-To-Sequence Singing Voice Synthesis With Perceptual Entropy Loss},
  author={Shi, Jiatong and Guo, Shuai and Huo, Nan and Zhang, Yuekai and Jin, Qin},
  booktitle=ICASSP,
  pages={76--80},
  year={2021},
  organization={IEEE}
}


@inproceedings{hayashi2020espnet,
  abbr={TTS},
  abbr_publisher={ICASSP},
  title={{Espnet-TTS}: Unified, reproducible, and integratable open source end-to-end text-to-speech toolkit},
  author={Hayashi, Tomoki and Yamamoto, Ryuichi and Inoue, Katsuki and Yoshimura, Takenori and Watanabe, Shinji and Toda, Tomoki and Takeda, Kazuya and Zhang, Yu and Tan, Xu},
  booktitle=ICASSP,
  pages={7654--7658},
  year={2020},
  organization={IEEE},
  code={https://github.com/espnet/espnet},
  selected={true},
  pdf={https://arxiv.org/pdf/1910.10909.pdf},
  html={https://ieeexplore.ieee.org/abstract/document/9053512/},
  arxiv={1910.10909}
}

@inproceedings{inaguma-etal-2020-espnet,
    abbr={ST},
    abbr_publisher={ACL},
    title = "{ESP}net-{ST}: All-in-One Speech Translation Toolkit",
    author = "Inaguma, Hirofumi  and
      Kiyono, Shun  and
      Duh, Kevin  and
      Karita, Shigeki  and
      Yalta, Nelson  and
      Hayashi, Tomoki  and
      Watanabe, Shinji",
    booktitle = ACL,
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-demos.34",
    pages = "302--311",
    code={https://github.com/espnet/espnet},
      selected={true},
}
@inproceedings{li2020espnet,
  abbr={SE},
  abbr_publisher={SLT},
  title={{ESPnet-SE}: End-to-End Speech Enhancement and Separation Toolkit Designed for {ASR} Integration},
  author={Chenda Li and Jing Shi and Wangyou Zhang and Aswin Shanmugam Subramanian and Xuankai Chang and Naoyuki Kamo and Moto Hira and Tomoki Hayashi and Christoph Boeddeker and Zhuo Chen and Shinji Watanabe},
  booktitle=SLT,
  pages={785--792},
  year={2021},
  organization={IEEE},
  code={https://github.com/espnet/espnet},
}

@article{huh2020augmentation,
  abbr={SR&SSL},
  abbr_publisher={NeurIPS},
  title={Augmentation adversarial training for self-supervised speaker recognition},
  author={Huh, Jaesung and Heo, Hee Soo and Kang, Jingu and Watanabe, Shinji and Chung, Joon Son},
  arxiv={2007.12085},
  year={2020}
}
@article{miyazaki2020conformer,
  abbr={SED},
  abbr_publisher={DCASE},
  title={Conformer-based sound event detection with semi-supervised learning and data augmentation},
  author={Miyazaki, Koichi and Komatsu, Tatsuya and Hayashi, Tomoki and Watanabe, Shinji and Toda, Tomoki and Takeda, Kazuya},
  html={http://dcase.community/documents/workshop2020/proceedings/DCASE2020Workshop_Miyazaki_92.pdf},
  volume={1},
  pages={4},
  year={2020}
}

@article{arora2020jhu,
  abbr={ASR},
  abbr_publisher={CHiME},
  title={The JHU multi-microphone multi-speaker ASR system for the CHiME-6 challenge},
  author={Arora, Ashish and Raj, Desh and Subramanian, Aswin Shanmugam and Li, Ke and Ben-Yair, Bar and Maciejewski, Matthew and {\.Z}elasko, Piotr and Garcia, Paola and Watanabe, Shinji and Khudanpur, Sanjeev},
  arxiv={2006.07898},
  year={2020}
}
@inproceedings{chang2020end,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={End-to-end multi-speaker speech recognition with transformer},
  author={Chang, Xuankai and Zhang, Wangyou and Qian, Yanmin and Le Roux, Jonathan and Watanabe, Shinji},
  html={https://ieeexplore.ieee.org/abstract/document/9054029},
  pages={6134--6138},
  year={2020}
}
@inproceedings{inoue2020semi,
  abbr={TTS},
  abbr_publisher={ICASSP},
  title={Semi-supervised speaker adaptation for end-to-end speech synthesis with pretrained models},
  author={Inoue, Katsuki and Hara, Sunao and Abe, Masanobu and Hayashi, Tomoki and Yamamoto, Ryuichi and Watanabe, Shinji},
  html={https://ieeexplore.ieee.org/abstract/document/9053371},
  pages={7634--7638},
  year={2020}
}
@inproceedings{yoshimura2020end,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={End-to-end automatic speech recognition integrated with ctc-based voice activity detection},
  author={Yoshimura, Takenori and Hayashi, Tomoki and Takeda, Kazuya and Watanabe, Shinji},
  arxiv={https://ieeexplore.ieee.org/abstract/document/9054358},
  pages={6999--7003},
  year={2020}
}
}
@inproceedings{fujita2020attention,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Attention-based asr with lightweight and dynamic convolutions},
  author={Fujita, Yuya and Subramanian, Aswin Shanmugam and Omachi, Motoi and Watanabe, Shinji},
  arxiv={https://ieeexplore.ieee.org/abstract/document/9053887},
  pages={7034--7038},
  year={2020},
  code={https://github.com/espnet/espnet}
}
@inproceedings{li2020practical,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={A practical two-stage training strategy for multi-stream end-to-end speech recognition},
  author={Li, Ruizhi and Sell, Gregory and Wang, Xiaofei and Watanabe, Shinji and Hermansky, Hynek},
  arxiv={1910.10671},
  pages={7014--7018},
  year={2020}
}
@inproceedings{huang2020speaker,
  abbr={SD},
  abbr_publisher={ICASSP},
  title={Speaker diarization with region proposal network},
  author={Huang, Zili and Watanabe, Shinji and Fujita, Yusuke and Garc{\'\i}a, Paola and Shao, Yiwen and Povey, Daniel and Khudanpur, Sanjeev},
  html={https://ieeexplore.ieee.org/abstract/document/9053760},
  arxiv={2002.06220},
  pages={6514--6518},
  year={2020}
}
@inproceedings{miyazaki2020weakly,
  abbr={SED},
  abbr_publisher={ICASSP},
  title={Weakly-supervised sound event detection with self-attention},
  author={Miyazaki, Koichi and Komatsu, Tatsuya and Hayashi, Tomoki and Watanabe, Shinji and Toda, Tomoki and Takeda, Kazuya},
  html={https://ieeexplore.ieee.org/abstract/document/9053609},
  pages={66--70},
  year={2020},
  code={https://github.com/espnet/espnet}
}
@inproceedings{subramanian2020far,
  abbr={SE},
  abbr_publisher={ICASSP},
  title={Far-field location guided target speech extraction using end-to-end speech recognition objectives},
  html={https://ieeexplore.ieee.org/document/9053692},
  author={Subramanian, Aswin Shanmugam and Weng, Chao and Yu, Meng and Zhang, Shi-Xiong and Xu, Yong and Watanabe, Shinji and Yu, Dong},
  pages={7299--7303},
  year={2020}
}
@incollection{shinozaki2020automated,
  abbr={ASR},
  abbr_publisher={Deep Neural Evolution},
  title={Automated Development of DNN Based Spoken Language Systems Using Evolutionary Algorithms},
  author={Shinozaki, Takahiro and Watanabe, Shinji and Duh, Kevin},
  html={https://link.springer.com/chapter/10.1007/978-981-15-3685-4_4},
  pages={97--129},
  year={2020}
}
@article{huang2020sequence,
  abbr={ASR&TTS},
  abbr_publisher={VCC},
  title={The sequence-to-sequence baseline for the voice conversion challenge 2020: Cascading asr and tts},
  author={Huang, Wen-Chin and Hayashi, Tomoki and Watanabe, Shinji and Toda, Tomoki},
  arxiv={2010.02434},
  year={2020},
  code={https://github.com/espnet/espnet/tree/master/egs/vcc20}
}
@article{shi2020sequence,
  abbr={SE&ASR},
  abbr_publisher={NeurIPS},
  title={Sequence to multi-sequence learning via conditional chain mapping for mixture signals},
  author={Shi, Jing and Chang, Xuankai and Guo, Pengcheng and Watanabe, Shinji and Fujita, Yusuke and Xu, Jiaming and Xu, Bo and Xie, Lei},
  arxiv={2006.14150},
  year={2020},
  code={https://demotoshow.github.io/}
}
@inproceedings{chang2020end,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={End-to-End ASR with Adaptive Span Self-Attention.},
  author={Chang, Xuankai and Subramanian, Aswin Shanmugam and Guo, Pengcheng and Watanabe, Shinji and Fujita, Yuya and Omachi, Motoi},
  arxiv={http://www.interspeech2020.org/uploadfile/pdf/Thu-1-2-4.pdf},
  pages={3595--3599},
  year={2020}
}
@article{cho2020learning,
  abbr={TTS},
  abbr_publisher={Interspeech},
  title={Learning speaker embedding from text-to-speech},
  author={Cho, Jaejin and Zelasko, Piotr and Villalba, Jes{\'u}s and Watanabe, Shinji and Dehak, Najim},
  arxiv={2010.11221},
  year={2020},
  code={https://github.com/JaejinCho/espnet spkidtts.git}
}
@article{shi2020speaker,
  abbr={SE},
  abbr_publisher={Interspeech},
  title={Speaker-conditional chain model for speech separation and extraction},
  author={Shi, Jing and Xu, Jiaming and Fujita, Yusuke and Watanabe, Shinji and Xu, Bo},
  arxiv={2006.14149},
  year={2020}
}
@article{fujita2020insertion,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Insertion-based modeling for end-to-end automatic speech recognition},
  author={Fujita, Yuya and Watanabe, Shinji and Omachi, Motoi and Chan, Xuankai},
  arxiv={2005.13211},
  year={2020}
}
@article{horiguchi2020end,
  abbr={SD},
  abbr_publisher={Interspeech},
  title={End-to-end speaker diarization for an unknown number of speakers with encoder-decoder based attractors},
  author={Horiguchi, Shota and Fujita, Yusuke and Watanabe, Shinji and Xue, Yawen and Nagamatsu, Kenji},
  arxiv={2005.09921},
  year={2020},
  code={https://github.com/hitachi-speech/EEND},
  selected={true},

}
@article{zhang2020end,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={End-to-end far-field speech recognition with unified dereverberation and beamforming},
  author={Zhang, Wangyou and Subramanian, Aswin Shanmugam and Chang, Xuankai and Watanabe, Shinji and Qian, Yanmin},
  arxiv={2005.10479},
  year={2020},
  code={https://github.com/Emrys365/espnet/blob/wsj1_mix_spatialized/egs/wsj1_mix_spatialized/asr1/}
}
@article{higuchi2020mask,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Mask CTC: Non-autoregressive end-to-end ASR with CTC and mask predict},
  author={Higuchi, Yosuke and Watanabe, Shinji and Chen, Nanxin and Ogawa, Tetsuji and Kobayashi, Tetsunori},
  arxiv={2005.08700},
  year={2020},
  code={https://github.com/espnet/espnet}
}

@inproceedings{tsunoo2019transformer,
  abbr={ASR},
  abbr_publisher={ASRU},
  title={Transformer ASR with contextual block processing},
  author={Tsunoo, Emiru and Kashiwagi, Yosuke and Kumakura, Toshiyuki and Watanabe, Shinji},
  booktitle=ASRU,
  pages={427--433},
  year={2019},
  organization={IEEE}
}

@inproceedings{chang2019mimo,
  abbr={ASR},
  abbr_publisher={ASRU},
  title={MIMO-Speech: End-to-end multi-channel multi-speaker speech recognition},
  author={Chang, Xuankai and Zhang, Wangyou and Qian, Yanmin and Le Roux, Jonathan and Watanabe, Shinji},
  booktitle=ASRU,
  pages={237--244},
  year={2019},
  organization={IEEE}
}

@inproceedings{inaguma2019multilingual,
  abbr={ST},
  abbr_publisher={ASRU},
  title={Multilingual end-to-end speech translation},
  author={Inaguma, Hirofumi and Duh, Kevin and Kawahara, Tatsuya and Watanabe, Shinji},
  booktitle=ASRU,
  pages={570--577},
  year={2019},
  organization={IEEE}
}

@inproceedings{kanda2019simultaneous,
  abbr={ASR+SD},
  abbr_publisher={ASRU},
  title={Simultaneous speech recognition and speaker diarization for monaural dialogue recordings with target-speaker acoustic models},
  author={Kanda, Naoyuki and Horiguchi, Shota and Fujita, Yusuke and Xue, Yawen and Nagamatsu, Kenji and Watanabe, Shinji},
  booktitle=ASRU,
  pages={31--38},
  year={2019},
  organization={IEEE}
}

@inproceedings{wang2019espresso,
  abbr={ASR},
  abbr_publisher={ASRU},
  title={Espresso: A fast end-to-end neural speech recognition toolkit},
  author={Wang, Yiming and Chen, Tongfei and Xu, Hainan and Ding, Shuoyang and Lv, Hang and Shao, Yiwen and Peng, Nanyun and Xie, Lei and Watanabe, Shinji and Khudanpur, Sanjeev},
  booktitle=ASRU,
  pages={136--143},
  year={2019},
  organization={IEEE}
}

@inproceedings{karita2019comparative,
  abbr={ASR},
  abbr_publisher={ASRU},
  title={A comparative study on transformer vs rnn in speech applications},
  author={Karita, Shigeki and Chen, Nanxin and Hayashi, Tomoki and Hori, Takaaki and Inaguma, Hirofumi and Jiang, Ziyan and Someki, Masao and Soplin, Nelson Enrique Yalta and Yamamoto, Ryuichi and Wang, Xiaofei and others},
  booktitle=ASRU,
  pages={449--456},
  year={2019},
  organization={IEEE},
  selected={True},
  html={https://ieeexplore.ieee.org/abstract/document/9003750},
  arxiv={1909.06317},
}

@inproceedings{fujita2019end,
  abbr={SD},
  abbr_publisher={ASRU},
  title={End-to-end neural speaker diarization with self-attention},
  author={Fujita, Yusuke and Kanda, Naoyuki and Horiguchi, Shota and Xue, Yawen and Nagamatsu, Kenji and Watanabe, Shinji},
  booktitle=ASRU,
  pages={296--303},
  year={2019},
  organization={IEEE},
  selected={true},
  pdf={https://arxiv.org/pdf/1909.06247.pdf},
  html={https://ieeexplore.ieee.org/abstract/document/9003959},
  arxiv={1909.06247}
}

@article{li2019multi,
  abbr={ASR},
  abbr_publisher={ASRU},
  title={Multi-stream end-to-end speech recognition},
  author={Li, Ruizhi and Wang, Xiaofei and Mallidi, Sri Harish and Watanabe, Shinji and Hori, Takaaki and Hermansky, Hynek},
  journal=ASRU,
  volume={28},
  pages={646--655},
  year={2019},
  publisher={IEEE}
}


@inproceedings{maciejewski2019analysis,
  abbr={SS},
  abbr_publisher={WASPAA},
  title={Analysis of robustness of deep single-channel speech separation using corpora constructed from multiple domains},
  author={Maciejewski, Matthew and Sell, Gregory and Fujita, Yusuke and Garcia-Perera, Leibny Paola and Watanabe, Shinji and Khudanpur, Sanjeev},
  booktitle=WASPAA,
  pages={165--169},
  year={2019},
  organization={IEEE}
}

@inproceedings{taniguchi2019generalized,
  abbr={ASR},
  abbr_publisher={WASPAA},
  title={Generalized weighted-prediction-error dereverberation with varying source priors for reverberant speech recognition},
  author={Taniguchi, Toru and Subramanian, Aswin Shanmugam and Wang, Xiaofei and Tran, Dung and Fujita, Yuya and Watanabe, Shinji},
  booktitle=WASPAA,
  pages={293--297},
  year={2019},
  organization={IEEE}
}

@inproceedings{subramanian2019speech,
  abbr={ASR},
  abbr_publisher={WASPAA},
  title={Speech enhancement using end-to-end speech recognition objectives},
  author={Subramanian, Aswin Shanmugam and Wang, Xiaofei and Baskar, Murali Karthick and Watanabe, Shinji and Taniguchi, Toru and Tran, Dung and Fujita, Yuya},
  booktitle=WASPAA,
  pages={234--238},
  year={2019},
  organization={IEEE}
}

@inproceedings{seki19inter,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={End-to-End Multilingual Multi-Speaker Speech Recognition},
  author={Hiroshi Seki, Takaaki Hori, Shinji Watanabe, Jonathan Le Roux and John Hershey},
  booktitle=Interspeech,
  year={2019}
}

@inproceedings{wiesner19inter,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Pretraining by Backtranslation for End-to-end ASR in Low-Resource Settings},
  author={Matthew Wiesner, Adithya Renduchintala, Shinji Watanabe, Chunxi Liu, Najim Dehak and Sanjeev Khudanpur},
  booktitle=Interspeech,
  year={2019}
}

@inproceedings{hayashi19inter,
  abbr={TTS},
  abbr_publisher={Interspeech},
  title={Pre-trained Text Embeddings for Enhanced Text-to-Speech Synthesis},
  author={Tomoki Hayashi, Shinji Watanabe, Tomoki Toda, Kazuya Takeda, Shubham Toshniwal and Karen Livescu},
  booktitle=Interspeech,
  year={2019}
}

@inproceedings{fujita19inter,
  abbr={SD},
  abbr_publisher={Interspeech},
  title={End-to-End Neural Speaker Diarization with Permutation-Free Objectives},
  author={Yusuke Fujita and Naoyuki Kanda and Shota Horiguchi and Kenji Nagamatsu and Shinji Watanabe},
  booktitle=Interspeech,
  year={2019},
  selected={true},
  pdf={https://www.isca-speech.org/archive_v0/Interspeech_2019/pdfs/2899.pdf},
  html={https://www.isca-speech.org/archive_v0/Interspeech_2019/abstracts/2899.html},

}

@inproceedings{kerafiat19inter,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Analysis of Multilingual Sequence-to-Sequence speech recognition systems},
  author={Martin Karafiat, Murali Karthick Baskar and Shinji Watanabe and Takaaki Hori and Matthew Wiesner and Jan Černocký},
  booktitle=Interspeech,
  year={2019}
}

@inproceedings{delcroix10inter,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={End-to-end SpeakerBeam for single channel target speech recognition},
  author={Marc Delcroix and Shinji Watanabe and Tsubasa Ochiai and Keisuke Kinoshita and Shigeki Karita and Atsunori Ogawa and Tomohiro Nakatani},
  booktitle=Interspeech,
  year={2019}
}


@inproceedings{baskar19inter,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Semi-supervised Sequence-to-sequence ASR using Unpaired Speech and Text},
  author={Murali Karthick Baskar and Shinji Watanabe and Ramón Astudillo and Takaaki Hori and Lukas Burget and Jan Černocký},
  booktitle=Interspeech,
  year={2019}
}

@inproceedings{velazquez19inter,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Study of the performance of automatic speech recognition systems in speakers with Parkinson's Disease},
  author={Laureano Moro Velazquez and Jaejin Cho and Shinji Watanabe and Mark Hasegawa-Johnson and Odette Scharenborg and Kim Heejin and Najim Dehak},
  booktitle=Interspeech,
  year={2019}
}

@inproceedings{seki19inter,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Vectorized Beam Search for CTC-Attention-based Speech Recognition},
  author={Hiroshi Seki and Takaaki Hori and Shinji Watanabe and Niko Moritz and Jonathan Le Roux},
  booktitle=Interspeech,
  year={2019}
}

@inproceedings{garcia19inter,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Speaker recognition benchmark using the CHiME-5 corpus},
  author={Daniel Garcia-Romero and David Snyder and Shinji Watanabe and Gregory Sell and Alan McCree and Dan Povey and Sanjeev Khudanpur},
  booktitle=Interspeech,
  year={2019}
}

@inproceedings{karita19inter,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Improving Transformer Based End-to-End Speech Recognition with Connectionist Temporal Classification and Language Model Integration},
  author={Shigeki Karita and Nelson Yalta and Shinji Watanabe and Marc Delcroix and Atsunori Ogawa and Tomohiro Nakatani},
  booktitle=Interspeech,
  year={2019},
  selected={true},
  pdf={https://www.isca-speech.org/archive_v0/Interspeech_2019/pdfs/1938.pdf},
  html={https://www.isca-speech.org/archive_v0/Interspeech_2019/abstracts/1938.html},

}

@inproceedings{naoyuki19inter,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Interference Speaker Loss for Target-Speaker Speech Recognition},
  author={Naoyuki Kanda and Shota Horiguchi and Ryoichi Takashima and Yusuke Fujita and Kenji Nagamatsu and Shinji Watanabe},
  booktitle=Interspeech,
  year={2019}
}

@inproceedings{yalta2019cnn,
  abbr={ASR},
  abbr_publisher={EUSIPCO},
  title={CNN-based multichannel end-to-end speech recognition for everyday home environments},
  author={Yalta, Nelson and Watanabe, Shinji and Hori, Takaaki and Nakadai, Kazuhiro and Ogata, Tetsuya},
  booktitle={2019 27th European Signal Processing Conference (EUSIPCO)},
  pages={1--5},
  year={2019},
  organization={IEEE}
}

@inproceedings{arora2019using,
  abbr={OCR},
  abbr_publisher={ICDAR},
  title={Using ASR methods for OCR},
  author={Arora, Ashish and Chang, Chun Chieh and Rekabdar, Babak and BabaAli, Bagher and Povey, Daniel and Etter, David and Raj, Desh and Hadian, Hossein and Trmal, Jan and Garcia, Paola and others},
  booktitle={2019 International Conference on Document Analysis and Recognition (ICDAR)},
  pages={663--668},
  year={2019},
  organization={IEEE}
}

@inproceedings{yalta2019weakly,
  abbr={Music},
  abbr_publisher={IJCNN},
  title={Weakly-supervised deep recurrent neural networks for basic dance step generation},
  author={Yalta, Nelson and Watanabe, Shinji and Nakadai, Kazuhiro and Ogata, Tetsuya},
  booktitle={2019 International Joint Conference on Neural Networks (IJCNN)},
  pages={1--8},
  year={2019},
  organization={IEEE}
}

@inproceedings{adams2019massively,
  abbr={ASR},
  abbr_publisher={NAACL},
  title={Massively Multilingual Adversarial Speech Recognition},
  author={Adams, Oliver and Wiesner, Matthew and Watanabe, Shinji and Yarowsky, David},
  booktitle=NAACL,
  pages={96--108},
  year={2019}
}

@inproceedings{baskar2019promising,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Promising accurate prefix boosting for sequence-to-sequence ASR},
  author={Baskar, Murali Karthick and Burget, Luk{\'a}{\v{s}} and Watanabe, Shinji and Karafi{\'a}t, Martin and Hori, Takaaki and {\v{C}}ernock{\`y}, Jan Honza},
  booktitle=ICASSP,
  pages={5646--5650},
  year={2019},
  organization={IEEE}
}

@inproceedings{inaguma2019transfer,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Transfer learning of language-independent end-to-end asr with language model fusion},
  author={Inaguma, Hirofumi and Cho, Jaejin and Baskar, Murali Karthick and Kawahara, Tatsuya and Watanabe, Shinji},
  booktitle=ICASSP,
  pages={6096--6100},
  year={2019},
  organization={IEEE}
}

@inproceedings{xu2019improving,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Improving end-to-end speech recognition with pronunciation-assisted sub-word modeling},
  author={Xu, Hainan and Ding, Shuoyang and Watanabe, Shinji},
  booktitle=ICASSP,
  pages={7110--7114},
  year={2019},
  organization={IEEE}
}

@inproceedings{cho2019language,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Language model integration based on memory control for sequence to sequence speech recognition},
  author={Cho, Jaejin and Watanabe, Shinji and Hori, Takaaki and Baskar, Murali Karthick and Inaguma, Hirofumi and Villalba, Jesus and Dehak, Najim},
  booktitle=ICASSP,
  pages={6191--6195},
  year={2019},
  organization={IEEE}
}

@inproceedings{wang2019stream,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Stream attention-based multi-array end-to-end speech recognition},
  author={Wang, Xiaofei and Li, Ruizhi and Mallidi, Sri Harish and Hori, Takaaki and Watanabe, Shinji and Hermansky, Hynek},
  booktitle=ICASSP,
  pages={7105--7109},
  year={2019},
  organization={IEEE}
}

@inproceedings{manohar2019acoustic,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Acoustic modeling for overlapping speech recognition: JHU CHiME-5 challenge system},
  author={Manohar, Vimal and Chen, Szu-Jui and Wang, Zhiqi and Fujita, Yusuke and Watanabe, Shinji and Khudanpur, Sanjeev},
  booktitle=ICASSP,
  pages={6665--6669},
  year={2019},
  organization={IEEE}
}

@inproceedings{hori2019cycle,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Cycle-consistency training for end-to-end speech recognition},
  author={Hori, Takaaki and Astudillo, Ramon and Hayashi, Tomoki and Zhang, Yu and Watanabe, Shinji and Le Roux, Jonathan},
  booktitle=ICASSP,
  pages={6271--6275},
  year={2019},
  organization={IEEE}
}

@inproceedings{kothinti2019joint,
  abbr={AED},
  abbr_publisher={ICASSP},
  title={Joint acoustic and class inference for weakly supervised sound event detection},
  author={Kothinti, Sandeep and Imoto, Keisuke and Chakrabarty, Debmalya and Sell, Gregory and Watanabe, Shinji and Elhilali, Mounya},
  booktitle=ICASSP,
  pages={36--40},
  year={2019},
  organization={IEEE}
}

@inproceedings{le2019phasebook,
  abbr={SE},
  abbr_publisher={ICASSP},
  title={The phasebook: Building complex masks via discrete representations for source separation},
  author={Le Roux, Jonathan and Wichern, Gordon and Watanabe, Shinji and Sarroff, Andy and Hershey, John R},
  booktitle=ICASSP,
  pages={66--70},
  year={2019},
  organization={IEEE}
}

@inproceedings{chang2019end,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={End-to-end monaural multi-speaker ASR system without pretraining},
  author={Chang, Xuankai and Qian, Yanmin and Yu, Kai and Watanabe, Shinji},
  booktitle=ICASSP,
  pages={6256--6260},
  year={2019},
  organization={IEEE}
}

@inproceedings{karita2019semi,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Semi-supervised end-to-end speech recognition using text-to-speech and autoencoders},
  author={Karita, Shigeki and Watanabe, Shinji and Iwata, Tomoharu and Delcroix, Marc and Ogawa, Atsunori and Nakatani, Tomohiro},
  booktitle=ICASSP,
  pages={6166--6170},
  year={2019},
  organization={IEEE}
}

@inproceedings{kanda2019acoustic,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Acoustic modeling for distant multi-talker speech recognition with single-and multi-channel branches},
  author={Kanda, Naoyuki and Fujita, Yusuke and Horiguchi, Shota and Ikeshita, Rintaro and Nagamatsu, Kenji and Watanabe, Shinji},
  booktitle=ICASSP,
  pages={6630--6634},
  year={2019},
  organization={IEEE}
}

@article{lin2018model,
  abbr={ML},
  abbr_publisher={Physica},
  title={Model parameter learning using Kullback--Leibler divergence},
  author={Lin, Chungwei and Marks, Tim K and Pajovic, Milutin and Watanabe, Shinji and Tung, Chih-kuan},
  journal={Physica A: Statistical Mechanics and its Applications},
  volume={491},
  pages={549--559},
  year={2018},
  publisher={Elsevier}
}

@inproceedings{hori2018end,
  abbr={ASR},
  abbr_publisher={SLT},
  title={End-to-end speech recognition with word-based RNN language models},
  author={Hori, Takaaki and Cho, Jaejin and Watanabe, Shinji},
  booktitle=SLT,
  pages={389--396},
  year={2018},
  organization={IEEE}
}

@inproceedings{liu2018low,
  abbr={ASR},
  abbr_publisher={SLT},
  title={Low-resource contextual topic identification on speech},
  author={Liu, Chunxi and Wiesner, Matthew and Watanabe, Shinji and Harman, Craig and Trmal, Jan and Dehak, Najim and Khudanpur, Sanjeev},
  booktitle=SLT,
  pages={656--663},
  year={2018},
  organization={IEEE}
}

@inproceedings{hayashi2018back,
  abbr={ASR},
  abbr_publisher={SLT},
  title={Back-translation-style data augmentation for end-to-end ASR},
  author={Hayashi, Tomoki and Watanabe, Shinji and Zhang, Yu and Toda, Tomoki and Hori, Takaaki and Astudillo, Ramon and Takeda, Kazuya},
  booktitle=SLT,
  pages={426--433},
  year={2018},
  organization={IEEE}
}

@inproceedings{cho2018multilingual,
  abbr={ASR},
  abbr_publisher={SLT},
  title={Multilingual sequence-to-sequence speech recognition: architecture, transfer learning, and language modeling},
  author={Cho, Jaejin and Baskar, Murali Karthick and Li, Ruizhi and Wiesner, Matthew and Mallidi, Sri Harish and Yalta, Nelson and Karafiat, Martin and Watanabe, Shinji and Hori, Takaaki},
  booktitle=SLT,
  pages={521--527},
  year={2018},
  organization={IEEE}
}

@article{watanabe2018espnet,
  abbr={ASR},
  abbr_publisher={Interspeech},
  author={Shinji Watanabe and Takaaki Hori and Shigeki Karita and Tomoki Hayashi and Jiro Nishitoba and Yuya Unno and Nelson {Enrique Yalta Soplin} and Jahn Heymann and Matthew Wiesner and Nanxin Chen and Adithya Renduchintala and Tsubasa Ochiai},
  abstract={This paper introduces a new open source platform for end-to-end speech processing named ESPnet. ESPnet mainly focuses on end-to-end automatic speech recognition (ASR), and adopts widely-used dynamic neural network toolkits, Chainer and PyTorch, as a main deep learning engine. ESPnet also follows the Kaldi ASR toolkit style for data processing, feature extraction/format, and recipes to provide a complete setup for speech recognition and other speech processing experiments. This paper explains a major architecture of this software platform, several important functionalities, which differentiate ESPnet from other open source ASR toolkits, and experimental results with major ASR benchmarks.},
  title={{ESPnet}: End-to-End Speech Processing Toolkit},
  year={2018},
  journal=interspeech,
  pages={2207--2211},
  doi={10.21437/Interspeech.2018-1456},
  html={https://www.isca-speech.org/archive/interspeech_2018/watanabe18_interspeech.html},
  pdf={https://www.isca-speech.org/archive/pdfs/interspeech_2018/watanabe18_interspeech.pdf},
  code={https://github.com/espnet/espnet},
  arxiv={1804.00015},
  selected={true}
}

@article{chen2018building,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Building State-of-the-art Distant Speech Recognition Using the CHiME-4 Challenge with a Setup of Speech Enhancement Baseline},
  author={Chen, Szu-Jui and Subramanian, Aswin Shanmugam and Xu, Hainan and Watanabe, Shinji},
  journal=interspeech,
  pages={1571--1575},
  year={2018}
}

@article{hayashi2018multi,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Multi-Head Decoder for End-to-End Speech Recognition},
  author={Hayashi, Tomoki and Watanabe, Shinji and Toda, Tomoki and Takeda, Kazuya},
  journal=interspeech,
  pages={801--805},
  year={2018}
}

@article{karita2018semi,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Semi-Supervised End-to-End Speech Recognition},
  author={Karita, Shigeki and Watanabe, Shinji and Iwata, Tomoharu and Ogawa, Atsunori and Delcroix, Marc},
  journal=interspeech,
  pages={2--6},
  year={2018}
}


@article{barker2018fifth,
  abbr={SE&ASR},
  abbr_publisher={Interspeech},
  title={The Fifth 'CHiME' Speech Separation and Recognition Challenge: Dataset, Task and Baselines},
  author={Barker, Jon and Watanabe, Shinji and Vincent, Emmanuel and Trmal, Jan},
  journal=interspeech,
  pages={1561--1565},
  year={2018},
  selected={true},
  pdf={https://www.isca-speech.org/archive/pdfs/interspeech_2018/barker18_interspeech.pdf},
  arxiv={1803.10609},
  html={https://www.isca-speech.org/archive/interspeech_2018/barker18_interspeech.html},
}

@article{subramanian2018student,
  abbr={SE},
  abbr_publisher={Interspeech},
  title={Student-Teacher Learning for BLSTM Mask-based Speech Enhancement},
  author={Subramanian, Aswin Shanmugam and Chen, Szu-Jui and Watanabe, Shinji},
  journal=interspeech,
  pages={3249--3253},
  year={2018}
}

@article{renduchintala2018multi,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Multi-Modal Data Augmentation for End-to-end ASR},
  author={Renduchintala, Adithya and Ding, Shuoyang and Wiesner, Matthew and Watanabe, Shinji},
  journal=interspeech,
  pages={2394--2398},
  year={2018}
}

@inproceedings{frederiksen2018effectiveness,
  abbr={LID},
  abbr_publisher={Interspeech},
  title={Effectiveness of single-channel blstm enhancement for language identification},
  author={Frederiksen, Peter Sibbern and Villalba, Jes{\'u}s and Watanabe, Shinji and Tan, Zheng-Hua and Dehak, Najim},
  booktitle={Interspeech 2018},
  pages={1823--1827},
  year={2018},
  organization={ISCA}
}

@inproceedings{sell2018diarization,
  abbr={SD},
  abbr_publisher={Interspeech},
  title={Diarization is Hard: Some Experiences and Lessons Learned for the JHU Team in the Inaugural DIHARD Challenge.},
  author={Sell, Gregory and Snyder, David and McCree, Alan and Garcia-Romero, Daniel and Villalba, Jes{\'u}s and Maciejewski, Matthew and Manohar, Vimal and Dehak, Najim and Povey, Daniel and Watanabe, Shinji and others},
  abstract={We describe in this paper the experiences of the Johns Hopkins University team during the inaugural DIHARD diarization evaluation. This new task provided microphone recordings in a variety of difficult conditions and challenged researchers to fully consider all speaker activity, without the currently typical practices of unscored collars or ignored overlapping speaker segments. This paper explores several key aspects of currently state-of-the-art diarization methods, such as training data selection, signal bandwidth for feature extraction, representations of speech segments (i-vector versus x-vector) and domain-adaptive processing. In the end, our best system clustered x-vector embeddings trained on wideband microphone data followed by Variational-Bayesian refinement and a speech activity detector specifically trained for this task with in-domain data was found to be the best performing. After presenting these decisions and their final result, we discuss lessons learned and remaining challenges within the lens of this new approach to diarization performance measurement.},
  booktitle={Interspeech},
  pages={2808--2812},
  year={2018},
  selected={true},
  html={https://www.isca-speech.org/archive/interspeech_2018/sell18_interspeech.html},
  pdf={https://www.isca-speech.org/archive/pdfs/interspeech_2018/sell18_interspeech.pdf},
}

@article{delcroix2018auxiliary,
  abbr={ASR},
  abbr_publisher={Interspeech},
  title={Auxiliary Feature Based Adaptation of End-to-end ASR Systems},
  author={Delcroix, Marc and Watanabe, Shinji and Ogawa, Atsunori and Karita, Shigeki and Nakatani, Tomohiro},
  journal=interspeech,
  pages={2444--2448},
  year={2018}
}

@inproceedings{seki2018purely,
  abbr={ASR},
  abbr_publisher={ACL},
  title={A Purely End-to-End System for Multi-speaker Speech Recognition},
  author={Seki, Hiroshi and Hori, Takaaki and Watanabe, Shinji and Le Roux, Jonathan and Hershey, John R},
  booktitle=ACL,
  pages={2620--2630},
  year={2018}
}

@inproceedings{ochiai2018speaker,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={Speaker adaptation for multichannel end-to-end speech recognition},
  author={Ochiai, Tsubasa and Watanabe, Shinji and Katagiri, Shigeru and Hori, Takaaki and Hershey, John},
  booktitle=ICASSP,
  pages={6707--6711},
  year={2018},
  organization={IEEE}
}

@inproceedings{seki2018end,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={An end-to-end language-tracking speech recognizer for mixed-language speech},
  author={Seki, Hiroshi and Watanabe, Shinji and Hori, Takaaki and Le Roux, Jonathan and Hershey, John R},
  booktitle=ICASSP,
  pages={4919--4923},
  year={2018},
  organization={IEEE}
}

@inproceedings{settle2018end,
  abbr={ASR},
  abbr_publisher={ICASSP},
  title={End-to-end multi-speaker speech recognition},
  author={Settle, Shane and Le Roux, Jonathan and Hori, Takaaki and Watanabe, Shinji and Hershey, John R},
  booktitle=ICASSP,
  pages={4819--4823},
  year={2018},
  organization={IEEE}
}


@inproceedings{lu2022towards,
  abbr={SE},
  abbr_publisher={ICASSP},
  title={Towards Low-distortion Multi-channel Speech Enhancement: The ESPNet-SE Submission to The L3DAS22 Challenge},
  author={Lu, Yen-Ju and Cornell, Samuele and Chang, Xuankai and Zhang, Wangyou and Li, Chenda and Ni, Zhaoheng and Wang, Zhong-Qiu and Watanabe, Shinji},
  booktitle=ICASSP,
  year={2022},
  organization={IEEE}
}
